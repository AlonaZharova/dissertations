{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lifelines\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from scipy.stats.stats import spearmanr\n",
    "\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "seed = 31415\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### C(t)-INDEX CALCULATION\n",
    "def c_index(Prediction, Time_survival, Death, Time):\n",
    "    '''\n",
    "        Raiber: okay, so it does not make a diffrence if the predictions are scores or risks(softmax probabilities) \n",
    "        This is a cause-specific c(t)-index\n",
    "        - Prediction      : risk at Time (higher --> more risky) <class 'numpy.ndarray'> \n",
    "          shape (7997,)\n",
    "        - Time_survival   : survival/censoring time   <class 'numpy.ndarray'>\n",
    "        shape (7997, 1)\n",
    "        - Death           :   <class 'numpy.ndarray'>\n",
    "            > 1: death\n",
    "            > 0: censored (including death from other cause)\n",
    "        shape (7997,)\n",
    "        - Time            : time of evaluation (time-horizon when evaluating C-index)   <class 'int'>\n",
    "        scalar value \n",
    "    '''\n",
    "    N = len(Prediction)# N = 7997 \n",
    "    #A.shape (7997, 7997) for validation \n",
    "    A = np.zeros((N,N))\n",
    "    Q = np.zeros((N,N))\n",
    "    N_t = np.zeros((N,N))\n",
    "    Num = 0\n",
    "    Den = 0\n",
    "    for i in range(N):\n",
    "        # np.where return the index of the values that fullfil the condition \n",
    "        # let assume i = 0, then np.where(Time_survival[i] < Time_survival) will return the indexes \n",
    "        # from 0 until 7996 (because the length is 7996) that have a bigger time then the index 0\n",
    "        # and the assign to A[0, list of biiger times that the value in 0 ] the value 1 \n",
    "        A[i, np.where(Time_survival[i] < Time_survival)] = 1\n",
    "        Q[i, np.where(Prediction[i] > Prediction)] = 1\n",
    "  \n",
    "        if (Time_survival[i]<=Time and Death[i]==1):\n",
    "            N_t[i,:] = 1\n",
    "\n",
    "    Num  = np.sum(((A)*N_t)*Q)\n",
    "    Den  = np.sum((A)*N_t)\n",
    "\n",
    "    if Num == 0 and Den == 0:\n",
    "        result = -1 # not able to compute c-index!\n",
    "    else:\n",
    "        result = float(Num/Den)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "##### WEIGHTED C-INDEX & BRIER-SCORE\n",
    "def CensoringProb(Y, T):\n",
    "\n",
    "    T = T.reshape([-1]) # (N,) - np array\n",
    "    Y = Y.reshape([-1]) # (N,) - np array\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(T, event_observed=(Y==0).astype(int))  # censoring prob = survival probability of event \"censoring\"\n",
    "    G = np.asarray(kmf.survival_function_.reset_index()).transpose()\n",
    "    G[1, G[1, :] == 0] = G[1, G[1, :] != 0][-1]  #fill 0 with ZoH (to prevent nan values)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def weighted_brier_score(T_train, Y_train, Prediction, T_test, Y_test, Time):\n",
    "    G = CensoringProb(Y_train, T_train)\n",
    "    N = len(Prediction)\n",
    "\n",
    "    W = np.zeros(len(Y_test))\n",
    "    Y_tilde = (T_test > Time).astype(float)\n",
    "\n",
    "    for i in range(N):\n",
    "        tmp_idx1 = np.where(G[0,:] >= T_test[i])[0]\n",
    "        tmp_idx2 = np.where(G[0,:] >= Time)[0]\n",
    "\n",
    "        if len(tmp_idx1) == 0:\n",
    "            G1 = G[1, -1]\n",
    "        else:\n",
    "            G1 = G[1, tmp_idx1[0]]\n",
    "\n",
    "        if len(tmp_idx2) == 0:\n",
    "            G2 = G[1, -1]\n",
    "        else:\n",
    "            G2 = G[1, tmp_idx2[0]]\n",
    "        W[i] = (1. - Y_tilde[i])*float(Y_test[i])/G1 + Y_tilde[i]/G2\n",
    "\n",
    "    y_true = ((T_test <= Time) * Y_test).astype(float)\n",
    "\n",
    "    return np.mean(W*(Y_tilde - (1.-Prediction))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raiber used \n",
    "def f_get_Normalization(X, norm_mode): # raiber added functions \n",
    "    num_Patient, num_Feature = np.shape(X)\n",
    "\n",
    "    if norm_mode == 'standard': #zero mean unit variance\n",
    "        for j in range(num_Feature):\n",
    "            if np.std(X[:,j]) != 0:\n",
    "                X[:,j] = (X[:,j] - np.mean(X[:, j]))/np.std(X[:,j])\n",
    "            else:\n",
    "                X[:,j] = (X[:,j] - np.mean(X[:, j]))\n",
    "    elif norm_mode == 'normal': #min-max normalization\n",
    "        for j in range(num_Feature):\n",
    "            X[:,j] = (X[:,j] - np.min(X[:,j]))/(np.max(X[:,j]) - np.min(X[:,j]))\n",
    "    else:\n",
    "        print(\"INPUT MODE ERROR!\")\n",
    "\n",
    "    return X\n",
    " \n",
    "def formatted_data(x, t, e, idx):\n",
    "    death_time = np.array(t[idx], dtype=float)\n",
    "    censoring = np.array(e[idx], dtype=float)\n",
    "    covariates = np.array(x[idx])\n",
    "\n",
    "    print(\"observed fold:{}\".format(sum(e[idx]) / len(e[idx])))\n",
    "    survival_data = {'x': covariates, 't': death_time, 'e': censoring}\n",
    "    return survival_data\n",
    "\n",
    "\n",
    "def risk_set(data_t):\n",
    "    size = len(data_t)\n",
    "    risk_set = np.zeros(shape=(size, size))\n",
    "    for idx in range(size):\n",
    "        temp = np.zeros(shape=size)\n",
    "        t_i = data_t[idx]\n",
    "        at_risk = data_t > t_i\n",
    "        temp[at_risk] = 1\n",
    "        # temp[idx] = 0\n",
    "        risk_set[idx] = temp\n",
    "    return risk_set\n",
    "\n",
    "def one_hot_encoder(data, encode):\n",
    "    print(\"Encoding data:{}\".format(data.shape))\n",
    "    data_encoded = data.copy()\n",
    "    encoded = pandas.get_dummies(data_encoded, prefix=encode, columns=encode)\n",
    "    print(\"head of data:{}, data shape:{}\".format(data_encoded.head(), data_encoded.shape))\n",
    "    print(\"Encoded:{}, one_hot:{}{}\".format(encode, encoded.shape, encoded[0:5]))\n",
    "    return encoded\n",
    "\n",
    "def get_train_median_mode(x, categorial):\n",
    "    categorical_flat = flatten_nested(categorial)\n",
    "    print(\"categorical_flat:{}\".format(categorical_flat))\n",
    "    imputation_values = []\n",
    "    print(\"len covariates:{}, categorical:{}\".format(x.shape[1], len(categorical_flat)))\n",
    "    median = np.nanmedian(x, axis=0)\n",
    "    mode = []\n",
    "    for idx in np.arange(x.shape[1]):\n",
    "        a = x[:, idx]\n",
    "        (_, idx, counts) = np.unique(a, return_index=True, return_counts=True)\n",
    "        index = idx[np.argmax(counts)]\n",
    "        mode_idx = a[index]\n",
    "        mode.append(mode_idx)\n",
    "    for i in np.arange(x.shape[1]):\n",
    "        if i in categorical_flat:\n",
    "            imputation_values.append(mode[i])\n",
    "        else:\n",
    "            imputation_values.append(median[i])\n",
    "    print(\"imputation_values:{}\".format(imputation_values))\n",
    "    return imputation_values\n",
    "\n",
    "\n",
    "def missing_proportion(dataset):\n",
    "    missing = 0\n",
    "    columns = np.array(dataset.columns.values)\n",
    "    for column in columns:\n",
    "        missing += dataset[column].isnull().sum()\n",
    "    return 100 * (missing / (dataset.shape[0] * dataset.shape[1]))\n",
    "\n",
    "\n",
    "def one_hot_indices(dataset, one_hot_encoder_list):\n",
    "    indices_by_category = []\n",
    "    for colunm in one_hot_encoder_list:\n",
    "        values = dataset.filter(regex=\"{}_.*\".format(colunm)).columns.values\n",
    "        # print(\"values:{}\".format(values, len(values)))\n",
    "        indices_one_hot = []\n",
    "        for value in values:\n",
    "            indice = dataset.columns.get_loc(value)\n",
    "            # print(\"column:{}, indice:{}\".format(colunm, indice))\n",
    "            indices_one_hot.append(indice)\n",
    "        indices_by_category.append(indices_one_hot)\n",
    "    # print(\"one_hot_indices:{}\".format(indices_by_category))\n",
    "    return indices_by_category\n",
    "\n",
    "def flatten_nested(list_of_lists):\n",
    "    flattened = [val for sublist in list_of_lists for val in sublist]\n",
    "    return flattened\n",
    "\n",
    "def get_missing_mask(data, imputation_values=None):\n",
    "    copy = data\n",
    "    for i in np.arange(len(data)):\n",
    "        row = data[i]\n",
    "        indices = np.isnan(row)\n",
    "        # print(\"indices:{}, {}\".format(indices, np.where(indices)))\n",
    "        if imputation_values is None:\n",
    "            copy[i][indices] = 0\n",
    "        else:\n",
    "            for idx in np.arange(len(indices)):\n",
    "                if indices[idx]:\n",
    "                    # print(\"idx:{}, imputation_values:{}\".format(idx, np.array(imputation_values)[idx]))\n",
    "                    copy[i][idx] = imputation_values[idx]\n",
    "    # print(\"copy;{}\".format(copy))\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fontsize = 18\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=MEDIUM_SIZE)  # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)  # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'bold',\n",
    "        'size': 24}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          # 'figure.figsize': (15, 5),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize': 'x-large',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# We'll hack a bit with the t-SNE code in sklearn 0.15.2.\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "sns.set()\n",
    "title_fontsize = 18\n",
    "label_fontsize = 18\n",
    "\n",
    "\n",
    "def plot_cost(training, validation, name, model, epochs, best_epoch):\n",
    "    x = np.arange(start=0, stop=len(training), step=1).tolist()\n",
    "    constant = 1e-10\n",
    "    plt.figure()\n",
    "    plt.xlim(min(x), max(x))\n",
    "    plt.ylim(min(min(training), min(validation), 0) - constant, max(max(training), max(validation)) + constant)\n",
    "    plt.plot(x, training, color='blue', linestyle='-', label='training')\n",
    "    plt.plot(x, validation, color='green', linestyle='-', label='validation')\n",
    "    plt.axvline(x=best_epoch, color='red')\n",
    "    title = 'Training {} {}: epochs={}, best epoch={} '.format(model, name, epochs, best_epoch)\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.ylabel(name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.savefig('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\plots\\\\mort_d\\\\{}_{}'.format(model, name))\n",
    "\n",
    "\n",
    "def box_plots(empirical, predicted, name='data', time='days', log_domain=True):\n",
    "    plt.figure()\n",
    "    if log_domain:\n",
    "        plt.yscale('log')\n",
    "    plt.boxplot(x=predicted, sym='o', notch=0, whis='range')\n",
    "    plt.scatter(x=np.arange(start=1, stop=len(predicted) + 1), y=empirical, color='purple', label='empirical')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.xticks(fontsize=5)\n",
    "    plt.ylabel('t ({})'.format(time))\n",
    "    plt.xlabel('Observation index')\n",
    "    plt.savefig('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\plots\\\\mort_d\\\\{}_box_plot'.format(name))\n",
    "\n",
    "\n",
    "def hist_plots(samples, name, xlabel, empirical=None):\n",
    "    plt.figure()\n",
    "    plt.axvline(x=np.mean(samples), color='grey', label='mean', linestyle='--', )\n",
    "    if empirical:\n",
    "        plt.axvline(x=empirical, color='purple', label='empirical', linestyle='--', )\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.hist(samples, bins=25)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.savefig(\"C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\plots\\\\mort_d\\\\{}_hist\".format(name))\n",
    "    plt.figure()\n",
    "    plt.boxplot(x=samples, sym='o', notch=0, whis='range')\n",
    "    plt.scatter(x=1, y=np.mean(samples), color='purple', label='mean')\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.savefig('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\plots\\\\mort_d\\\\{}_box_plot'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raiber: we draw form the uniform distribution a tensor with shape batch_size (128) and dim(feature dim 17) and values between zero and 1\n",
    "# shape: (128, 17) \n",
    "def uniform(dim, batch_size):\n",
    "    ones = np.ones(shape=dim, dtype=np.float32)\n",
    "    noise = tf.distributions.Uniform(low=0 * ones, high=ones).sample(sample_shape=[batch_size])\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. tf_helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_variables():\n",
    "    model_vars = tf.trainable_variables()\n",
    "    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "\n",
    "\n",
    "def mlp_neuron(layer_input, weights, biases, activation=True): # if activation is set to false from the called function, we stay false\n",
    "    mlp = tf.add(tf.matmul(layer_input, weights), biases)\n",
    "    if activation:\n",
    "        return tf.nn.relu(mlp)\n",
    "    else:\n",
    "        return mlp\n",
    "\n",
    "\n",
    "def normalized_mlp(layer_input, weights, biases, is_training, batch_norm, layer, activation=tf.nn.relu):\n",
    "    mlp = tf.add(tf.matmul(layer_input, weights), biases)\n",
    "    if batch_norm:\n",
    "        norm = batch_norm_wrapper(mlp, is_training, layer=layer)\n",
    "        # norm = tf_batch_norm(is_training=is_training, inputs=mlp, layer=layer)\n",
    "        return activation(norm)\n",
    "    else:\n",
    "        return activation(mlp)\n",
    "\n",
    "\n",
    "def dropout_normalised_mlp(layer_input, weights, biases, is_training, batch_norm, layer, keep_prob=1,\n",
    "                           activation=tf.nn.relu):\n",
    "    mlp = normalized_mlp(layer_input, weights, biases, is_training, batch_norm,\n",
    "                         layer=layer, activation=activation)  # apply DropOut to hidden layer\n",
    "    drop_out = tf.cond(is_training, lambda: tf.nn.dropout(mlp, keep_prob), lambda: mlp)\n",
    "    return drop_out\n",
    "\n",
    "\n",
    "def create_nn_weights(layer, network, shape): # layer: the name of the layer, exp: h0_z hiddem layer 0 \n",
    "                                              # network: string (in this example would be the \"decoder\")\n",
    "                                              # shape: [input_shape, hidden_dim] in one of the examples ][34,50]\n",
    "    # raiber: create the name of the weights and variables\n",
    "    h_vars = {}\n",
    "    w_h = 'W_' + network + '_' + layer\n",
    "    b_h = 'b_' + network + '_' + layer\n",
    "    # get the values of the weights and variables \n",
    "    h_vars[w_h] = create_weights(shape=shape, name=w_h)\n",
    "    h_vars[b_h] = create_biases([shape[1]], name=b_h)\n",
    "    variable_summaries(h_vars[w_h], w_h)\n",
    "    variable_summaries(h_vars[b_h], b_h)\n",
    "\n",
    "    return h_vars[w_h], h_vars[b_h]\n",
    "\n",
    "\n",
    "def create_biases(shape, name):\n",
    "    print(\"name:{}, shape{}\".format(name, shape))\n",
    "    return tf.Variable(tf.constant(shape=shape, value=0.0), name=name)\n",
    "\n",
    "\n",
    "def create_weights(shape, name):\n",
    "    print(\"name:{}, shape{}\".format(name, shape))\n",
    "    # initialize weights using Glorot and Bengio(2010) scheme\n",
    "    a = tf.sqrt(6.0 / (shape[0] + shape[1]))\n",
    "    # return tf.Variable(tf.random_normal(shape, stddev=tf.square(0.0001)), name=name)\n",
    "    return tf.Variable(tf.random_uniform(shape, minval=-a, maxval=a, dtype=tf.float32), name=name)\n",
    "\n",
    "\n",
    "def variable_summaries(var, summary_name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope(summary_name):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "\n",
    "\n",
    "def batch_norm_wrapper(inputs, is_training, layer):\n",
    "    # http://r2rt.com/implementing-batch-normalization-in-tensorflow.html\n",
    "    # raiber: get_shape()[-1]] gives the dim of the cols \n",
    "    pop_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable=False, name='{}_batch_norm_mean'.format(layer))\n",
    "    pop_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable=False, name='{}_batch_norm_var'.format(layer))\n",
    "    print(\"batch inputs {}, shape for var{}\".format(inputs.get_shape(), inputs.get_shape()[-1]))\n",
    "\n",
    "    offset = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), name='{}_batch_norm_offset'.format(layer))\n",
    "    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]), name='{}_batch_norm_scale'.format(layer))\n",
    "    epsilon = 1e-5\n",
    "    alpha = 0.9  # use numbers closer to 1 if you have more data\n",
    "\n",
    "    def batch_norm():\n",
    "        batch_mean, batch_var = tf.nn.moments(inputs, [0])\n",
    "        print(\"batch mean {}, var {}\".format(batch_mean.shape, batch_var.shape))\n",
    "        train_mean = tf.assign(pop_mean,\n",
    "                                pop_mean * alpha + batch_mean * (1 - alpha))\n",
    "        train_var = tf.assign(pop_var,\n",
    "                              pop_var * alpha + batch_var * (1 - alpha))\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs, mean=batch_mean, variance=batch_var, offset=offset, scale=scale,\n",
    "                                              variance_epsilon=epsilon)\n",
    "\n",
    "    def pop_norm():\n",
    "        return tf.nn.batch_normalization(inputs, pop_mean, pop_var, offset=offset, scale=scale,\n",
    "                                          variance_epsilon=epsilon)\n",
    "\n",
    "    return tf.cond(is_training, batch_norm, pop_norm)\n",
    "\n",
    "\n",
    "def hidden_mlp_layers(batch_norm, hidden_dim, is_training, keep_prob, layer_input, size):\n",
    "    tmp = layer_input\n",
    "    for i in np.arange(size):\n",
    "        input_shape = tmp.get_shape().as_list()[1]\n",
    "        print(\"layer input shape:{}\".format(input_shape))\n",
    "        w_hi, b_hi = create_nn_weights('h{}_z'.format(i), 'decoder', [input_shape, hidden_dim[i]])\n",
    "        h_i = dropout_normalised_mlp(layer_input=tmp, weights=w_hi, biases=b_hi,\n",
    "                                     is_training=is_training,\n",
    "                                     batch_norm=batch_norm, keep_prob=keep_prob,\n",
    "                                     layer='h{}_z_decoder'.format(i))\n",
    "\n",
    "        tmp = h_i\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def hidden_mlp_layers_noise(batch_norm, hidden_dim, is_training, keep_prob, layer_input, noise_alpha, size,\n",
    "                            batch_size):\n",
    "    # hidden_dim = [50,50]\n",
    "    # layer input shape is (?,34) 34 = 17 + 17 (x + noise)\n",
    "    # size = len(hiiden_dim) = 2\n",
    "    tmp = layer_input\n",
    "    for i in np.arange(size):\n",
    "        input_shape = tmp.get_shape().as_list()[1] # in the second loop input_shape would be 100\n",
    "        print(\"layer input shape:{}\".format(input_shape))\n",
    "        w_hi, b_hi = create_nn_weights('h{}_z'.format(i), 'decoder', [input_shape, hidden_dim[i]])\n",
    "        h_i = dropout_normalised_mlp(layer_input=tmp, weights=w_hi, biases=b_hi,\n",
    "                                     is_training=is_training,\n",
    "                                     batch_norm=batch_norm, keep_prob=keep_prob,\n",
    "                                     layer='h{}_z_decoder'.format(i)) # h_i shape is (?,50)\n",
    "                                                                      # second loop also (?,50)\n",
    "\n",
    "        # noise = standard_gaussian(dim=hidden_dim[i], batch_size=batch_size) * tf.gather(noise_alpha, i + 1)\n",
    "        noise = uniform(dim=hidden_dim[i], batch_size=batch_size) * tf.gather(noise_alpha, i + 1) # noise shape (350 batch_size),50), the same for the second loop\n",
    "        tmp = tf.concat([h_i, noise], axis=1) # the shape become (?, 100) because 50 (h_i) and 50 (noise)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generated_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_distribution(predicted, empirical, data, time='days', cens=False):\n",
    "    predicted_samples = np.transpose(predicted)\n",
    "    print(\"observed_samples:{}, empirical_observed:{}\".format(predicted_samples.shape,\n",
    "                                                              empirical.shape))\n",
    "\n",
    "    best_samples, diff, worst_samples = get_best_worst_indices(cens, empirical, predicted_samples)\n",
    "\n",
    "    predicted_best = predicted_samples[best_samples]\n",
    "    predicted_worst = predicted_samples[worst_samples]\n",
    "    hist_plots(samples=diff, name='{}_absolute_error'.format(data), xlabel=r'|\\tilde{t}-t|')\n",
    "\n",
    "    box_plots(empirical=empirical[best_samples], predicted=list(predicted_best), name=('%s_best' % data),\n",
    "              time=time)\n",
    "    box_plots(empirical=empirical[worst_samples], predicted=list(predicted_worst), name=('%s_worst' % data),\n",
    "              time=time)\n",
    "\n",
    "\n",
    "def get_best_worst_indices(cens, empirical, predicted, size=50):\n",
    "    diff = compute_relative_error(cens=cens, empirical=empirical, predicted=predicted)\n",
    "    indices = sorted(range(len(abs(diff))), key=lambda k: diff[k])\n",
    "    best_samples = indices[0:size]\n",
    "    worst_samples = indices[len(indices) - size - 1: len(indices) - 1]\n",
    "    return best_samples, diff, worst_samples\n",
    "\n",
    "\n",
    "def compute_relative_error(cens, empirical, predicted, relative=False):\n",
    "    predicted_median = np.median(predicted, axis=1)\n",
    "    if cens:\n",
    "        diff = np.minimum(0, predicted_median - empirical)\n",
    "    else:\n",
    "        diff = predicted_median - empirical\n",
    "    if relative:\n",
    "        return diff\n",
    "    else:\n",
    "        return abs(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_metrics(e, risk_set, predicted, batch_size, empirical):\n",
    "    partial_likelihood = tf.constant(0.0, shape=())\n",
    "    rel_abs_err = tf.constant(0.0, shape=())\n",
    "    total_cens_loss = tf.constant(0.0, shape=())\n",
    "    total_obs_loss = tf.constant(0.0, shape=())\n",
    "    predicted = tf.squeeze(predicted)\n",
    "    observed = tf.reduce_sum(e) # compute sum across the tensor\n",
    "    censored = tf.subtract(tf.cast(batch_size, dtype=tf.float32), observed) # what is left from the batch which is not bserved, it is then censored \n",
    "\n",
    "    def condition(i, likelihood, rae, recon_loss, obs_recon_loss):\n",
    "        return i < batch_size\n",
    "\n",
    "    def body(i, likelihood, rae, cens_recon_loss, obs_recon_loss):\n",
    "        # get edges for observation i\n",
    "        pred_t_i = tf.gather(predicted, i)\n",
    "        emp_t_i = tf.gather(empirical, i)\n",
    "        e_i = tf.gather(e, i)\n",
    "        censored = tf.equal(e_i, 0)\n",
    "        obs_at_risk = tf.gather(risk_set, i)\n",
    "        print(\"obs_at_risk:{}, g_theta:{}\".format(obs_at_risk.shape, predicted.shape))\n",
    "        risk_hazard_list = tf.multiply(predicted, obs_at_risk)\n",
    "        num_adjacent = tf.reduce_sum(obs_at_risk)\n",
    "        # calculate partial likelihood\n",
    "        risk = tf.subtract(pred_t_i, risk_hazard_list)\n",
    "        activated_risk = tf.nn.sigmoid(risk)\n",
    "        # logistic = map((lambda ele: log(1 + exp(ele * -1)) * 1 / log(2)), x)\n",
    "        constant = 1e-8\n",
    "        log_activated_risk = tf.div(tf.log(activated_risk + constant), tf.log(2.0))\n",
    "        obs_likelihood = tf.add(log_activated_risk, num_adjacent)\n",
    "        uncensored_likelihood = tf.cond(censored, lambda: tf.constant(0.0), lambda: obs_likelihood)\n",
    "        cumulative_likelihood = tf.reduce_sum(uncensored_likelihood)\n",
    "        updated_likelihood = tf.add(cumulative_likelihood, likelihood)\n",
    "\n",
    "        # RElative absolute error\n",
    "        abs_error_i = tf.abs(tf.subtract(pred_t_i, emp_t_i))\n",
    "        pred_great_empirical = tf.greater(pred_t_i, emp_t_i)\n",
    "        min_rea_i = tf.minimum(tf.div(abs_error_i, pred_t_i), tf.constant(1.0))\n",
    "        rea_i = tf.cond(tf.logical_and(censored, pred_great_empirical), lambda: tf.constant(0.0), lambda: min_rea_i)\n",
    "        cumulative_rae = tf.add(rea_i, rae)\n",
    "\n",
    "        # Censored generated t loss\n",
    "        diff_time = tf.subtract(pred_t_i, emp_t_i)\n",
    "        # logistic = map((lambda ele: log(1 + exp(ele * -1)) * 1 / log(2)), x)\n",
    "        # logistic = tf.div(tf.nn.sigmoid(diff_time) + constant, tf.log(2.0))\n",
    "        # hinge = map(lambda ele: max(0, 1 - ele), x)\n",
    "        hinge = tf.nn.relu(1.0 - diff_time)\n",
    "        censored_loss_i = tf.cond(censored, lambda: hinge, lambda: tf.constant(0.0))\n",
    "        # Sum over all edges and normalize by number of edges\n",
    "        # L1 recon\n",
    "        observed_loss_i = tf.cond(censored, lambda: tf.constant(0.0),\n",
    "                                  lambda: tf.losses.absolute_difference(labels=emp_t_i, predictions=pred_t_i))\n",
    "        # add observation risk to total risk\n",
    "        cum_cens_loss = tf.add(cens_recon_loss, censored_loss_i)\n",
    "        cum_obs_loss = tf.add(obs_recon_loss, observed_loss_i)\n",
    "        return [i + 1, tf.reshape(updated_likelihood, shape=()), tf.reshape(cumulative_rae, shape=()),\n",
    "                tf.reshape(cum_cens_loss, shape=()), tf.reshape(cum_obs_loss, shape=())]\n",
    "\n",
    "    # Relevant Functions\n",
    "    idx = tf.constant(0, shape=())\n",
    "    _, total_likelihood, total_rel_abs_err, batch_cens_loss, batch_obs_loss = \\\n",
    "        tf.while_loop(condition, body,\n",
    "                      loop_vars=[idx,\n",
    "                                 partial_likelihood,\n",
    "                                 rel_abs_err,\n",
    "                                 total_cens_loss,\n",
    "                                 total_obs_loss],\n",
    "                      shape_invariants=[\n",
    "                          idx.get_shape(),\n",
    "                          partial_likelihood.get_shape(),\n",
    "                          rel_abs_err.get_shape(),\n",
    "                          total_cens_loss.get_shape(),\n",
    "                          total_obs_loss.get_shape()])\n",
    "    square_batch_size = tf.pow(batch_size, tf.constant(2))\n",
    "\n",
    "    def normarlize_loss(cost, size):\n",
    "        cast_size = tf.cast(size, dtype=tf.float32)\n",
    "        norm = tf.cond(tf.greater(cast_size, tf.constant(0.0)), lambda: tf.div(cost, cast_size), lambda: 0.0)\n",
    "        return norm\n",
    "\n",
    "    total_recon_loss = tf.add(normarlize_loss(batch_cens_loss, size=censored),\n",
    "                              normarlize_loss(batch_obs_loss, size=observed))\n",
    "    normalized_log_likelihood = normarlize_loss(total_likelihood, size=square_batch_size)\n",
    "    return normalized_log_likelihood, normarlize_loss(total_rel_abs_err, size=batch_size), total_recon_loss\n",
    "\n",
    "\n",
    "def l2_loss(scale):\n",
    "    l2 = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "    return l2 * scale\n",
    "\n",
    "\n",
    "def l1_loss(scale):\n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(\n",
    "        scale=scale, scope=None\n",
    "    )\n",
    "    weights = tf.trainable_variables()  # all vars of your graph\n",
    "    l1 = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of data:   id  time  duration  orig_time  first_time  mat_time  balance_time  \\\n",
      "0   1    48        24         -7          25       113      29087.21   \n",
      "1   2    26         2         18          25       138     105654.77   \n",
      "2   3    29         5         -6          25       114      44378.60   \n",
      "3   4    60        36         -2          25       119      52686.35   \n",
      "4   5    27         3         18          25       138      52100.71   \n",
      "\n",
      "    LTV_time  interest_rate_time  hpi_time  ...  REtype_SF_orig_time  \\\n",
      "0  26.658065               9.200    146.45  ...                    1   \n",
      "1  65.469851               7.680    225.10  ...                    1   \n",
      "2  31.459735              11.375    217.37  ...                    1   \n",
      "3  34.898842              10.500    189.82  ...                    1   \n",
      "4  66.346343               9.155    222.39  ...                    1   \n",
      "\n",
      "   investor_orig_time  balance_orig_time  FICO_orig_time  LTV_orig_time  \\\n",
      "0                   0            45000.0             715           69.4   \n",
      "1                   0           107200.0             558           80.0   \n",
      "2                   0            48600.0             680           83.6   \n",
      "3                   0            63750.0             587           81.8   \n",
      "4                   0            52800.0             527           80.0   \n",
      "\n",
      "   Interest_Rate_orig_time  hpi_orig_time  default_time  payoff_time  \\\n",
      "0                    9.200          87.03             1            0   \n",
      "1                    7.680         186.91             0            1   \n",
      "2                    8.750          89.58             0            1   \n",
      "3                   10.500          97.99             0            0   \n",
      "4                    9.155         186.91             0            1   \n",
      "\n",
      "   status_time  \n",
      "0            1  \n",
      "1            2  \n",
      "2            2  \n",
      "3            0  \n",
      "4            2  \n",
      "\n",
      "[5 rows x 24 columns], data shape:(49982, 24)\n",
      "missing:0.0\n",
      "head of dataset data:   orig_time  mat_time  balance_time  LTV_time  interest_rate_time  hpi_time  \\\n",
      "0  -3.477627 -1.389979     -1.033823 -2.095055            0.988138 -1.667711   \n",
      "1  -0.303878  0.003805     -0.656808 -0.550770            0.301260  1.324293   \n",
      "2  -3.350677 -1.334228     -0.958529 -1.904001            1.971006  1.030228   \n",
      "3  -2.842878 -1.055471     -0.917622 -1.767162            1.575599 -0.017829   \n",
      "4  -0.303878  0.003805     -0.920506 -0.515895            0.967802  1.221199   \n",
      "\n",
      "   gdp_time  uer_time  balance_orig_time  FICO_orig_time  LTV_orig_time  \\\n",
      "0  0.534808  1.372840          -0.991474        0.737401      -1.039149   \n",
      "1  0.240467 -0.776909          -0.693650       -1.419995       0.029385   \n",
      "2  0.001466 -0.896339          -0.974236        0.256453       0.392283   \n",
      "3  0.597611 -0.179756          -0.901696       -1.021495       0.210834   \n",
      "4  0.350143 -0.956054          -0.954126       -1.845978       0.029385   \n",
      "\n",
      "   Interest_Rate_orig_time  hpi_orig_time  REtype_CO_orig_time  \\\n",
      "0                 1.143066      -3.185900                    0   \n",
      "1                 0.680615      -0.276286                    0   \n",
      "2                 1.006156      -3.111615                    0   \n",
      "3                 1.538583      -2.866623                    0   \n",
      "4                 1.129375      -0.276286                    0   \n",
      "\n",
      "   REtype_PU_orig_time  REtype_SF_orig_time  investor_orig_time  \n",
      "0                    0                    1                   0  \n",
      "1                    0                    1                   0  \n",
      "2                    0                    1                   0  \n",
      "3                    0                    1                   0  \n",
      "4                    0                    1                   0  , data shape:(49982, 17)\n",
      "data description:          orig_time      mat_time  balance_time      LTV_time  \\\n",
      "count  4.998200e+04  4.998200e+04  4.998200e+04  4.998200e+04   \n",
      "mean  -2.047100e-16 -2.536129e-16 -5.572661e-17 -2.115337e-16   \n",
      "std    1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
      "min   -7.666977e+00 -6.686357e+00 -1.177047e+00 -3.155755e+00   \n",
      "25%   -4.308278e-01 -1.076980e-01 -6.554586e-01 -6.046198e-01   \n",
      "50%    2.039221e-01  1.710588e-01 -2.727104e-01 -2.360233e-02   \n",
      "75%    5.847720e-01  3.940642e-01  3.966436e-01  6.538653e-01   \n",
      "max    5.028021e+00  5.077178e+00  4.160276e+01  2.139352e+01   \n",
      "\n",
      "       interest_rate_time      hpi_time      gdp_time      uer_time  \\\n",
      "count        4.998200e+04  4.998200e+04  4.998200e+04  4.998200e+04   \n",
      "mean        -2.729467e-17  8.609193e-16 -2.729467e-17 -2.881222e-16   \n",
      "std          1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
      "min         -3.169282e+00 -3.136894e+00 -3.043250e+00 -1.314346e+00   \n",
      "25%         -5.144079e-01 -1.072734e+00 -2.403500e-01 -7.769087e-01   \n",
      "50%         -6.027861e-03 -1.782909e-02  3.045201e-01 -2.991867e-01   \n",
      "75%          6.040282e-01  1.030228e+00  5.976112e-01  2.979657e-01   \n",
      "max          1.377672e+01  1.369563e+00  1.794764e+00  2.387999e+00   \n",
      "\n",
      "       balance_orig_time  FICO_orig_time  LTV_orig_time  \\\n",
      "count       4.998200e+04    4.998200e+04   4.998200e+04   \n",
      "mean       -2.445147e-17    4.139691e-16  -6.255028e-17   \n",
      "std         1.000010e+00    1.000010e+00   1.000010e+00   \n",
      "min        -1.183999e+00   -3.591133e+00  -2.984686e+00   \n",
      "25%        -6.610904e-01   -6.779607e-01  -4.746403e-01   \n",
      "50%        -2.876136e-01    2.284970e-02   2.938497e-02   \n",
      "75%         3.970938e-01    7.374014e-01   5.334103e-01   \n",
      "max         3.709837e+01    2.455074e+00   1.399089e+01   \n",
      "\n",
      "       Interest_Rate_orig_time  hpi_orig_time  REtype_CO_orig_time  \\\n",
      "count             4.998200e+04   4.998200e+04         49982.000000   \n",
      "mean             -2.365538e-16  -2.604366e-16             0.064983   \n",
      "std               1.000010e+00   1.000010e+00             0.246499   \n",
      "min              -1.655980e+00  -3.515664e+00             0.000000   \n",
      "25%              -7.432477e-01  -4.936038e-01             0.000000   \n",
      "50%               2.835761e-01   4.758790e-01             0.000000   \n",
      "75%               6.638812e-01   7.572854e-01             0.000000   \n",
      "max               4.352841e+00   8.708967e-01             1.000000   \n",
      "\n",
      "       REtype_PU_orig_time  REtype_SF_orig_time  investor_orig_time  \n",
      "count         49982.000000         49982.000000        49982.000000  \n",
      "mean              0.115902             0.623625            0.118443  \n",
      "std               0.320110             0.484481            0.323135  \n",
      "min               0.000000             0.000000            0.000000  \n",
      "25%               0.000000             0.000000            0.000000  \n",
      "50%               0.000000             1.000000            0.000000  \n",
      "75%               0.000000             1.000000            0.000000  \n",
      "max               1.000000             1.000000            1.000000  \n",
      "columns:['orig_time' 'mat_time' 'balance_time' 'LTV_time' 'interest_rate_time'\n",
      " 'hpi_time' 'gdp_time' 'uer_time' 'balance_orig_time' 'FICO_orig_time'\n",
      " 'LTV_orig_time' 'Interest_Rate_orig_time' 'hpi_orig_time'\n",
      " 'REtype_CO_orig_time' 'REtype_PU_orig_time' 'REtype_SF_orig_time'\n",
      " 'investor_orig_time']\n",
      "x:[-3.47762744 -1.38997903 -1.03382322 -2.09505531  0.9881376  -1.66771114\n",
      "  0.5348077   1.37284007 -0.99147372  0.73740143 -1.03914866  1.14306563\n",
      " -3.18589953  0.          0.          1.          0.        ], t:24, e:1, len:49982\n",
      "x_shape:(49982, 17)\n",
      "end_time:60\n",
      "observed percent:0.30308911208034894\n",
      "shuffled x:[ 0.71172201  0.33831283 -0.21521574  0.10943108  0.16343216  1.03022833\n",
      "  0.00146605 -0.89633915 -0.26271517  1.43821178  0.02938497  0.58782017\n",
      "  0.83623068  0.          0.          1.          1.        ], t:4, e:0, len:49982\n",
      "num_examples:39985\n",
      "test:9997, valid:7997, train:39985, all: 57979\n",
      "categorical_flat:[13, 14, 15, 16]\n",
      "len covariates:17, categorical:4\n",
      "imputation_values:[0.20392207819158592, 0.17105877772832692, -0.2710399070327385, -0.023597524056526372, -0.006027861145139642, -0.017829093326131175, 0.3045201165680782, -0.29918672172861266, -0.28681878460652066, 0.022849696519850204, 0.029384971240994304, 0.28357607893547515, 0.47587904145774995, 0.0, 0.0, 1.0, 0.0]\n",
      "imputation_values:[0.20392207819158592, 0.17105877772832692, -0.2710399070327385, -0.023597524056526372, -0.006027861145139642, -0.017829093326131175, 0.3045201165680782, -0.29918672172861266, -0.28681878460652066, 0.022849696519850204, 0.029384971240994304, 0.28357607893547515, 0.47587904145774995, 0.0, 0.0, 1.0, 0.0]\n",
      "observed fold:0.30305114417906714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed fold:0.3061918575572672\n",
      "observed fold:0.2993622608478179\n"
     ]
    }
   ],
   "source": [
    "def generate_data():\n",
    "    import pdb\n",
    "    np.random.seed(31415)\n",
    "    data_frame = pandas.read_csv('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\datasets\\\\mortgage\\\\WideFormatMortgageAfterRemovingNull.csv', sep=',')\n",
    "    print(\"head of data:{}, data shape:{}\".format(data_frame.head(), data_frame.shape))\n",
    "    # x_data = data_frame[['age', 'sex', 'kappa', 'lambda', 'flc.grp', 'creatinine', 'mgus']]\n",
    "    # Preprocess\n",
    "    to_drop = ['id','time', 'duration','first_time', 'default_time', 'payoff_time', 'status_time']\n",
    "    print(\"missing:{}\".format(missing_proportion(data_frame.drop(labels=to_drop, axis=1))))\n",
    "    one_hot_encoder_list = ['REtype_CO_orig_time', 'REtype_PU_orig_time', 'REtype_SF_orig_time', 'investor_orig_time']\n",
    "    #data_frame = one_hot_encoder(data_frame, encode=one_hot_encoder_list)\n",
    "    data_frame = data_frame[['id', 'time', 'duration', 'orig_time', 'first_time', 'mat_time',\n",
    "           'balance_time', 'LTV_time', 'interest_rate_time', 'hpi_time',\n",
    "           'gdp_time', 'uer_time', 'balance_orig_time',\n",
    "           'FICO_orig_time', 'LTV_orig_time', 'Interest_Rate_orig_time',\n",
    "           'hpi_orig_time', 'default_time', 'payoff_time', 'status_time', 'REtype_CO_orig_time', 'REtype_PU_orig_time',\n",
    "           'REtype_SF_orig_time', 'investor_orig_time']]\n",
    "    t_data = data_frame[['duration']]\n",
    "    e_data = data_frame[['default_time']]\n",
    "    dataset1 = data_frame.drop(labels=to_drop, axis=1)\n",
    "    #pdb.set_trace()\n",
    "\n",
    "    ll_n = f_get_Normalization(np.asarray(dataset1.iloc[:,:13]), 'standard')\n",
    "    ll_p = pandas.DataFrame(ll_n, columns=dataset1.iloc[:,:13].columns)\n",
    "    ll = pandas.concat([ll_p, dataset1.iloc[:,13:].reindex(ll_p.index)], axis=1)\n",
    "    dataset = ll\n",
    "\n",
    "    print(\"head of dataset data:{}, data shape:{}\".format(dataset.head(), dataset.shape))\n",
    "    encoded_indices = [[13], [14], [15], [16]]\n",
    "    print(\"data description:{}\".format(dataset.describe()))\n",
    "    covariates = np.array(dataset.columns.values)\n",
    "    print(\"columns:{}\".format(covariates))\n",
    "    x = np.array(dataset).reshape(dataset.shape)\n",
    "    t = np.array(t_data).reshape(len(t_data))\n",
    "    e = np.array(e_data).reshape(len(e_data))\n",
    "\n",
    "    print(\"x:{}, t:{}, e:{}, len:{}\".format(x[0], t[0], e[0], len(t)))\n",
    "    idx = np.arange(0, x.shape[0])\n",
    "    print(\"x_shape:{}\".format(x.shape))\n",
    "\n",
    "    np.random.shuffle(idx)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "    e = e[idx]\n",
    "    end_time = max(t)\n",
    "    print(\"end_time:{}\".format(end_time))\n",
    "    print(\"observed percent:{}\".format(sum(e) / len(e)))\n",
    "    print(\"shuffled x:{}, t:{}, e:{}, len:{}\".format(x[0], t[0], e[0], len(t)))\n",
    "\n",
    "    num_examples = int(0.80 * len(e))\n",
    "    print(\"num_examples:{}\".format(num_examples))\n",
    "    vali_example = int(0.20 * num_examples)\n",
    "    train_idx = idx[0: num_examples - vali_example]\n",
    "    valid_idx = idx[num_examples - vali_example: num_examples]\n",
    "    split = int(len(t) - num_examples)\n",
    "    test_idx = idx[num_examples: num_examples + split]\n",
    "\n",
    "    print(\"test:{}, valid:{}, train:{}, all: {}\".format(len(test_idx), len(valid_idx), num_examples,\n",
    "                                                        len(test_idx) + len(valid_idx) + num_examples))\n",
    "    # print(\"test_idx:{}, valid_idx:{},train_idx:{} \".format(test_idx, valid_idx, train_idx))\n",
    "\n",
    "    imputation_values = get_train_median_mode(x=np.array(x[train_idx]), categorial=encoded_indices)\n",
    "    print(\"imputation_values:{}\".format(imputation_values))\n",
    "    preprocessed = {\n",
    "        'train': formatted_data(x=x, t=t, e=e, idx=train_idx),\n",
    "        'test': formatted_data(x=x, t=t, e=e, idx=test_idx),\n",
    "        'valid': formatted_data(x=x, t=t, e=e, idx=valid_idx),\n",
    "        'end_t': end_time,\n",
    "        'covariates': covariates,\n",
    "        'one_hot_indices': encoded_indices,\n",
    "        'imputation_values': imputation_values\n",
    "    }\n",
    "    return preprocessed\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. risk_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raiber: it return the network output after applying the relu fuction to it\n",
    "def pt_given_x(x, hidden_dim, is_training, batch_norm, batch_size, input_dim, noise_alpha, keep_prob=0.9, reuse=False):\n",
    "    size = len(hidden_dim)\n",
    "    with tf.variable_scope('generate_t_given_x', reuse=reuse):\n",
    "        # Variables\n",
    "        # first we add the noise to the input, then using the function hidden_mlp_layers_noise we add the noise to each hidden layer \n",
    "        noise = uniform(dim=input_dim, batch_size=batch_size) * tf.gather(noise_alpha, 0) # tf.gather give us the value of noise_alpha inside the index 0\n",
    "        x_plus_noise = tf.concat([x, noise], axis=1) # the layer input shape would be 17 + 17 = 34 (17 is the number of features)\n",
    "        hidden_x = hidden_mlp_layers_noise(batch_norm=batch_norm, hidden_dim=hidden_dim,\n",
    "                                           is_training=is_training, keep_prob=keep_prob,\n",
    "                                           layer_input=x_plus_noise, size=size, batch_size=batch_size,\n",
    "                                           noise_alpha=noise_alpha) # hidden_x shape (?,100)\n",
    "\n",
    "        w_t, b_t = create_nn_weights('t', 'encoder', [hidden_x.get_shape().as_list()[1], 1])\n",
    "        # name:W_encoder_t, shape[100, 1]\n",
    "        #name:b_encoder_t, shape[1]\n",
    "        t_mu = mlp_neuron(hidden_x, w_t, b_t, activation=False) # mlp = tf.add(tf.matmul(layer_input, weights), biases)\n",
    "        # no activation is applied \n",
    "        logit = tf.nn.sigmoid(t_mu) \n",
    "        return tf.exp(t_mu), logit\n",
    "\n",
    "def discriminator(pair_one, pair_two, hidden_dim, is_training, batch_norm, scope, keep_prob=1, reuse=False):\n",
    "    size = len(hidden_dim)\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        # Variables\n",
    "        print(\"scope:{}, pair_one:{}, pair_two:{}\".format(scope, pair_one.shape, pair_two.shape))\n",
    "        # create one structure for the input feature \n",
    "        hidden_pair_one = hidden_mlp_layers(batch_norm=batch_norm, hidden_dim=hidden_dim,\n",
    "                                            is_training=is_training, keep_prob=keep_prob,\n",
    "                                            layer_input=pair_one, size=size) # shape=(?, 50)\n",
    "\n",
    "        # this structure is for the time \n",
    "        hidden_pair_two = hidden_mlp_layers(batch_norm=batch_norm, hidden_dim=hidden_dim,\n",
    "                                            is_training=is_training, keep_prob=keep_prob,\n",
    "                                            layer_input=pair_two, size=size) #shape=(?, 50)\n",
    "        hidden_pairs = tf.concat([hidden_pair_one, hidden_pair_two], axis=1) #shape=(?, 100)\n",
    "        print(\"hidden_pairs:{}\".format(hidden_pairs.get_shape()))\n",
    "        #name:W_discriminator_logits, shape[100, 1]\n",
    "        #name:b_discriminator_logits, shape[1]\n",
    "        w_logit, b_logit = create_nn_weights('logits', 'discriminator', [hidden_dim[size - 1] * 2, 1])\n",
    "        f = mlp_neuron(layer_input=hidden_pairs, weights=w_logit, biases=b_logit, activation=False) \n",
    "        logit = tf.nn.sigmoid(f)\n",
    "\n",
    "    return tf.squeeze(logit), tf.squeeze(f)\n",
    "\n",
    "def discriminator_one(pair_one, pair_two, hidden_dim, is_training, batch_norm, keep_prob=1, reuse=False):\n",
    "    score, f = discriminator(pair_one=pair_one, pair_two=pair_two, scope='Discriminator_one', batch_norm=batch_norm,\n",
    "                             is_training=is_training,\n",
    "                             keep_prob=keep_prob, reuse=reuse, hidden_dim=hidden_dim)\n",
    "    return score, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. DATE-AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATE_AE(object):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 learning_rate,\n",
    "                 beta1,\n",
    "                 beta2,\n",
    "                 require_improvement,\n",
    "                 seed,\n",
    "                 num_iterations,\n",
    "                 hidden_dim,\n",
    "                 latent_dim,\n",
    "                 input_dim,\n",
    "                 num_examples,\n",
    "                 keep_prob,\n",
    "                 train_data,\n",
    "                 valid_data,\n",
    "                 test_data,\n",
    "                 end_t,\n",
    "                 gen_updates,\n",
    "                 covariates,\n",
    "                 imputation_values,\n",
    "                 sample_size,\n",
    "                 disc_updates,\n",
    "                 categorical_indices,\n",
    "                 l2_reg,\n",
    "                 max_epochs,\n",
    "                 path_large_data=\"\"\n",
    "                 ):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.disc_updates = disc_updates\n",
    "        self.gen_updates = gen_updates\n",
    "        self.latent_dim = latent_dim\n",
    "        self.path_large_data = path_large_data\n",
    "        self.seed = seed\n",
    "        self.require_improvement = require_improvement\n",
    "        self.num_iterations = num_iterations\n",
    "        self.learning_rate, self.beta1, self.beta2 = learning_rate, beta1, beta2\n",
    "        self.l2_reg = l2_reg\n",
    "        self.log_file = 'model.log'\n",
    "        logging.basicConfig(filename=self.log_file, filemode='w', level=logging.DEBUG)\n",
    "        np.random.seed(seed)\n",
    "        tf.set_random_seed(seed)\n",
    "        self.batch_norm = True\n",
    "        self.covariates = covariates\n",
    "        self.sample_size = sample_size\n",
    "        self.z_sample_size = 10  # num of z_samples\n",
    "\n",
    "        self.config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        # self.config.gpu_options.per_process_gpu_memory_fraction = gpu_memory_fraction\n",
    "        # Load Data\n",
    "        self.train_x, self.train_t, self.train_e = train_data['x'], train_data['t'], train_data['e']\n",
    "        self.valid_x, self.valid_t, self.valid_e = valid_data['x'], valid_data['t'], valid_data['e']\n",
    "\n",
    "        self.test_x, self.test_t, self.test_e = test_data['x'], test_data['t'], test_data['e']\n",
    "        self.end_t = end_t\n",
    "        self.keep_prob = keep_prob\n",
    "        self.input_dim = input_dim\n",
    "        self.imputation_values = imputation_values\n",
    "        self.imputation_values = np.zeros(shape=self.input_dim)\n",
    "        self.num_examples = num_examples\n",
    "        self.categorical_indices = categorical_indices\n",
    "        self.continuous_indices = np.setdiff1d(np.arange(input_dim), flatten_nested(categorical_indices))\n",
    "        print_features = \"input_dim:{}, continuous:{}, size:{}, categorical:{}, \" \\\n",
    "                         \"size{}\".format(self.input_dim,\n",
    "                                         self.continuous_indices,\n",
    "                                         len(\n",
    "                                             self.continuous_indices),\n",
    "                                         self.categorical_indices,\n",
    "                                         len(\n",
    "                                             self.categorical_indices))\n",
    "        print(print_features)\n",
    "        logging.debug(print_features)\n",
    "        print_model = \"model is DATE_AE\"\n",
    "        print(print_model)\n",
    "        logging.debug(\"Imputation values:{}\".format(imputation_values))\n",
    "        logging.debug(print_model)\n",
    "        self.model = 'DATE_AE'\n",
    "\n",
    "        self._build_graph()\n",
    "        self.train_cost, self.train_ci, self.train_t_rae, self.train_gen, self.train_disc, self.train_ranking, \\\n",
    "        self.train_layer_one_recon = [], [], [], [], [], [], []\n",
    "        self.valid_cost, self.valid_ci, self.valid_t_rae, self.valid_gen, self.valid_disc, self.valid_ranking, \\\n",
    "        self.valid_layer_one_recon = [], [], [], [], [], [], []\n",
    "\n",
    "    def _build_graph(self):\n",
    "        self.G = tf.Graph()\n",
    "        with self.G.as_default():\n",
    "            self.x = tf.placeholder(tf.float32, shape=[None, self.input_dim], name='x')\n",
    "            self.e = tf.placeholder(tf.float32, shape=[None], name='e')\n",
    "            self.t = tf.placeholder(tf.float32, shape=[None], name='t')\n",
    "            self.t_lab = tf.placeholder(tf.float32, shape=[None], name='t_lab')\n",
    "            # are used to feed data into our queue\n",
    "            self.batch_size_tensor = tf.placeholder(tf.int32, shape=[], name='batch_size')\n",
    "            self.risk_set = tf.placeholder(tf.float32, shape=[None, None])\n",
    "            self.impute_mask = tf.placeholder(tf.float32, shape=[None, self.input_dim], name='impute_mask')\n",
    "            self.is_training = tf.placeholder(tf.bool)\n",
    "            self.noise_dim = len(self.hidden_dim) + 1\n",
    "            self.noise_alpha = tf.placeholder(tf.float32, shape=[self.noise_dim])\n",
    "\n",
    "            self._objective()\n",
    "            self.session = tf.Session(config=self.config)\n",
    "\n",
    "            self.capacity = 1400\n",
    "            self.coord = tf.train.Coordinator()\n",
    "            enqueue_thread = threading.Thread(target=self.enqueue)\n",
    "            self.queue = tf.RandomShuffleQueue(capacity=self.capacity, dtypes=[tf.float32, tf.float32, tf.float32],\n",
    "                                               shapes=[[self.input_dim], [], []], min_after_dequeue=self.batch_size)\n",
    "            # self.queue = tf.FIFOQueue(capacity=self.capacity, dtypes=[tf.float32, tf.float32, tf.float32],\n",
    "            #                           shapes=[[self.input_dim], [], []])\n",
    "            self.enqueue_op = self.queue.enqueue_many([self.x, self.t, self.e])\n",
    "            # enqueue_thread.isDaemon()\n",
    "            enqueue_thread.start()\n",
    "            dequeue_op = self.queue.dequeue()\n",
    "            self.x_batch, self.t_batch, self.e_batch = tf.train.batch(dequeue_op, batch_size=self.batch_size,\n",
    "                                                                      capacity=self.capacity)\n",
    "            self.threads = tf.train.start_queue_runners(coord=self.coord, sess=self.session)\n",
    "\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.merged = tf.summary.merge_all()\n",
    "            self.current_dir = os.getcwd()\n",
    "            self.save_path = \"C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\summaries\\\\mort_d\\\\{0}_model\".format(self.model)\n",
    "            self.train_writer = tf.summary.FileWriter(self.save_path, self.session.graph)\n",
    "\n",
    "    def _objective(self):\n",
    "        self.num_batches = self.num_examples / self.batch_size\n",
    "        logging.debug(\"num batches:{}, batch_size:{} epochs:{}\".format(self.num_batches, self.batch_size,\n",
    "                                                                       int(self.num_iterations / self.num_batches)))\n",
    "        self._build_model()\n",
    "        self.reg_loss = l2_loss(self.l2_reg) + l1_loss(self.l2_reg)\n",
    "        self.cost = self.t_regularization_loss + self.disc_one_loss + self.disc_two_loss + self.gen_one_loss + \\\n",
    "                    self.gen_two_loss + self.layer_one_recon\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=self.beta1,\n",
    "                                           beta2=self.beta2)\n",
    "\n",
    "        dvars1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"Discriminator_one\")\n",
    "        dvars2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"Discriminator_two\")\n",
    "        genvars1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generate_t_given_x\")\n",
    "        genvars2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generate_t_given_z\")\n",
    "\n",
    "        self.disc_solver = optimizer.minimize(self.disc_one_loss + self.disc_two_loss, var_list=dvars1 + dvars2)\n",
    "        self.gen_solver = optimizer.minimize(\n",
    "            self.gen_one_loss + self.gen_two_loss + self.t_regularization_loss + self.layer_one_recon,\n",
    "            var_list=genvars1 + genvars2)\n",
    "\n",
    "    def _build_model(self):\n",
    "        self._denoising_date()\n",
    "        self._risk_date()\n",
    "\n",
    "    @staticmethod\n",
    "    def log(x):\n",
    "        return tf.log(x + 1e-8)\n",
    "\n",
    "    def _risk_date(self):\n",
    "        def expand_t_dim(t):\n",
    "            return tf.expand_dims(t, axis=1)\n",
    "\n",
    "        indices_lab = tf.where(tf.equal(tf.constant(1.0, dtype=tf.float32), self.e))\n",
    "        z_lab = tf.squeeze(tf.gather(self.z_real, indices_lab), axis=[1])\n",
    "        t_lab_exp = expand_t_dim(self.t_lab)\n",
    "\n",
    "        t_gen = pt_given_z(z=self.z_real, hidden_dim=self.hidden_dim, is_training=self.is_training,\n",
    "                           batch_norm=self.batch_norm, keep_prob=self.keep_prob, batch_size=self.batch_size_tensor,\n",
    "                           latent_dim=self.latent_dim, noise_alpha=self.noise_alpha)\n",
    "\n",
    "        # Discriminator B\n",
    "        d_two_real, f_two_real = discriminator_two(pair_one=z_lab, pair_two=t_lab_exp, hidden_dim=self.hidden_dim,\n",
    "                                                   is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                                   keep_prob=self.keep_prob)  # (z_nc, t_nc)\n",
    "        d_two_fake, f_two_fake = discriminator_two(pair_one=self.z_real, pair_two=t_gen, hidden_dim=self.hidden_dim,\n",
    "                                                   is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                                   reuse=True, keep_prob=self.keep_prob)  # (z, t_gen)\n",
    "\n",
    "        # Discriminator loss\n",
    "        self.disc_two_loss = -tf.reduce_mean(self.log(d_two_real)) - tf.reduce_mean(self.log(1 - d_two_fake))\n",
    "\n",
    "        # Generator loss\n",
    "        self.gen_two_loss = tf.reduce_mean(f_two_real) - tf.reduce_mean(f_two_fake)\n",
    "        self.disc_logit = d_two_fake # added b raiber \n",
    "        self.disc_f = f_two_fake # added by raiber \n",
    "        self.predicted_time = tf.squeeze(t_gen)\n",
    "        self.ranking_partial_lik, self.total_rae, self.total_t_recon_loss = \\\n",
    "            batch_metrics(e=self.e,\n",
    "                          risk_set=self.risk_set,\n",
    "                          predicted=self.predicted_time,\n",
    "                          batch_size=self.batch_size_tensor,\n",
    "                          empirical=self.t)\n",
    "\n",
    "        # self.t_regularization_loss = tf.add(self.ranking_partial_lik, self.total_t_recon_loss)\n",
    "        self.t_regularization_loss = self.total_t_recon_loss\n",
    "        self.t_mse = tf.losses.mean_squared_error(labels=self.t_lab,\n",
    "                                                  predictions=tf.gather(self.predicted_time, indices_lab))\n",
    "\n",
    "    def _denoising_date(self):\n",
    "        self.z_real = generate_z_given_x(latent_dim=self.latent_dim,\n",
    "                                         is_training=self.is_training,\n",
    "                                         batch_norm=self.batch_norm,\n",
    "                                         input_dim=self.input_dim, batch_size=self.batch_size_tensor,\n",
    "                                         hidden_dim=self.hidden_dim, x=self.impute_mask, keep_prob=self.keep_prob,\n",
    "                                         reuse=True, sample_size=self.z_sample_size)\n",
    "\n",
    "        z_ones = np.ones(shape=self.latent_dim, dtype=np.float32)\n",
    "        print(\"z_ones:{}\".format(z_ones.shape))\n",
    "\n",
    "        z_fake = tf.distributions.Uniform(low=-z_ones, high=z_ones).sample(sample_shape=[self.batch_size_tensor])\n",
    "        x_fake = generate_x_given_z(z=z_fake, latent_dim=self.latent_dim,\n",
    "                                    is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                    hidden_dim=self.hidden_dim, keep_prob=self.keep_prob,\n",
    "                                    batch_size=self.batch_size_tensor, input_dim=self.input_dim)\n",
    "\n",
    "        self.x_recon = generate_x_given_z(z=self.z_real, latent_dim=self.latent_dim,\n",
    "                                          is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                          hidden_dim=self.hidden_dim, reuse=True, keep_prob=self.keep_prob,\n",
    "                                          batch_size=self.batch_size_tensor, input_dim=self.input_dim)\n",
    "\n",
    "        z_rec = generate_z_given_x(x=x_fake, latent_dim=self.latent_dim,\n",
    "                                   is_training=self.is_training,\n",
    "                                   batch_norm=self.batch_norm,\n",
    "                                   input_dim=self.input_dim, batch_size=self.batch_size_tensor,\n",
    "                                   hidden_dim=self.hidden_dim, reuse=True, keep_prob=self.keep_prob,\n",
    "                                   sample_size=self.z_sample_size)\n",
    "        # Reconstruction Loss\n",
    "\n",
    "        self.x_recon_loss = x_reconstruction(x_recon=self.x_recon, x=self.x,\n",
    "                                             categorical_indices=self.categorical_indices,\n",
    "                                             continuous_indices=self.continuous_indices,\n",
    "                                             batch_size=self.batch_size_tensor)\n",
    "\n",
    "        self.z_recon_loss = tf.losses.mean_squared_error(z_fake, z_rec)\n",
    "        self.layer_one_recon = tf.add(self.x_recon_loss, self.z_recon_loss)\n",
    "\n",
    "        d_one_real, f_one_real = discriminator_one(pair_one=self.impute_mask, pair_two=self.z_real,\n",
    "                                                   hidden_dim=self.hidden_dim,\n",
    "                                                   is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                                   keep_prob=self.keep_prob)  # real\n",
    "        d_one_fake, f_one_fake = discriminator_one(pair_one=x_fake, pair_two=z_fake, hidden_dim=self.hidden_dim,\n",
    "                                                   is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                                   reuse=True, keep_prob=self.keep_prob)  # fake\n",
    "\n",
    "        self.disc_one_loss = -tf.reduce_mean(self.log(d_one_real)) - tf.reduce_mean(self.log(1 - d_one_fake))\n",
    "\n",
    "        # Generator loss\n",
    "        self.gen_one_loss = tf.reduce_mean(f_one_real) - tf.reduce_mean(f_one_fake)\n",
    "\n",
    "    def predict_concordance_index(self, x, t, e, outcomes=None):\n",
    "        input_size = x.shape[0]\n",
    "        i = 0\n",
    "        num_batches = input_size / self.batch_size\n",
    "        predicted_time = np.zeros(shape=input_size, dtype=np.int)\n",
    "        total_ranking = 0.0\n",
    "        total_rae = 0.0\n",
    "        total_cost = 0.0\n",
    "        total_gen_loss = 0.0\n",
    "        total_disc_loss = 0.0\n",
    "        total_layer_one_recon = 0.0\n",
    "        total_t_reg_loss = 0.0\n",
    "        total_reg = 0.0\n",
    "        total_mse = 0.0\n",
    "        while i < input_size:\n",
    "            # The ending index for the next batch is denoted j.\n",
    "            j = min(i + self.batch_size, input_size)\n",
    "            feed_dict = self.batch_feed_dict(e=e, i=i, j=j, t=t, x=x, outcomes=outcomes)\n",
    "            cost, ranking, gen_loss, rae, reg, disc_loss, layer_one_recon, t_reg_loss, t_mse = self.session.run(\n",
    "                [self.cost, self.ranking_partial_lik, self.gen_one_loss, self.total_rae,\n",
    "                 self.reg_loss,\n",
    "                 self.disc_one_loss, self.layer_one_recon, self.t_regularization_loss, self.t_mse],\n",
    "                feed_dict=feed_dict)\n",
    "\n",
    "            temp_pred_time = []\n",
    "            for p in range(self.sample_size):\n",
    "                gen_time = self.session.run(self.predicted_time, feed_dict=feed_dict)\n",
    "                temp_pred_time.append(gen_time)\n",
    "\n",
    "            temp_pred_time = np.array(temp_pred_time)\n",
    "            # print(\"temp_pred_time:{}\".format(temp_pred_time.shape))\n",
    "            predicted_time[i:j] = np.median(temp_pred_time, axis=0)\n",
    "\n",
    "            total_ranking += ranking\n",
    "            total_cost += cost\n",
    "            total_rae += rae\n",
    "            total_gen_loss += gen_loss\n",
    "            total_reg += reg\n",
    "            total_layer_one_recon += layer_one_recon\n",
    "            total_disc_loss += disc_loss\n",
    "            total_t_reg_loss += t_reg_loss\n",
    "            total_mse += t_mse\n",
    "            i = j\n",
    "\n",
    "        predicted_event_times = predicted_time.reshape(input_size)\n",
    "        #RAIBER NEW CHANGE\n",
    "        ci_index = concordance_index(event_times=t, predicted_scores=predicted_event_times.tolist(),\n",
    "                                    event_observed=e)\n",
    "        \n",
    "        #ci_index = 0\n",
    "        def batch_average(total):\n",
    "            return total / num_batches\n",
    "\n",
    "        return ci_index, batch_average(total_cost), batch_average(total_rae), batch_average(\n",
    "            total_ranking), batch_average(\n",
    "            total_gen_loss), batch_average(total_reg), batch_average(total_disc_loss), batch_average(\n",
    "            total_layer_one_recon), batch_average(total_t_reg_loss), batch_average(total_mse)\n",
    "\n",
    "    def batch_feed_dict(self, e, i, j, t, x, outcomes):\n",
    "        batch_x = x[i:j, :]\n",
    "        batch_t = t[i:j]\n",
    "        batch_risk = risk_set(batch_t)\n",
    "        batch_impute_mask = get_missing_mask(batch_x, self.imputation_values)\n",
    "        batch_e = e[i:j]\n",
    "        idx_observed = batch_e == 1\n",
    "        feed_dict = {self.x: batch_x,\n",
    "                     self.impute_mask: batch_impute_mask,\n",
    "                     self.t: batch_t,\n",
    "                     self.t_lab: batch_t[idx_observed],\n",
    "                     self.e: batch_e,\n",
    "                     self.risk_set: batch_risk,\n",
    "                     self.batch_size_tensor: len(batch_t),\n",
    "                     self.is_training: False,\n",
    "                     self.noise_alpha: np.ones(shape=self.noise_dim)}\n",
    "        # TODO replace with abstract methods\n",
    "\n",
    "        updated_feed_dic = self.outcomes_function(idx=i, j=j, feed_dict=feed_dict, outcomes=outcomes)\n",
    "        return updated_feed_dic\n",
    "\n",
    "    def outcomes_function(self, idx, j, feed_dict, outcomes):\n",
    "        return feed_dict\n",
    "\n",
    "    def train_neural_network(self):\n",
    "        train_print = \"Training {0} Model:\".format(self.model)\n",
    "        params_print = \"Parameters:, l2_reg:{}, learning_rate:{},\" \\\n",
    "                       \" momentum: beta1={} beta2={}, batch_size:{}, batch_norm:{},\" \\\n",
    "                       \" hidden_dim:{}, latent_dim:{}, num_of_batches:{}, keep_prob:{}, disc_update:{}\" \\\n",
    "            .format(self.l2_reg, self.learning_rate, self.beta1, self.beta2, self.batch_size,\n",
    "                    self.batch_norm, self.hidden_dim, self.latent_dim, self.num_batches, self.keep_prob,\n",
    "                    self.disc_updates)\n",
    "        print(train_print)\n",
    "        print(params_print)\n",
    "        logging.debug(train_print)\n",
    "        logging.debug(params_print)\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "        best_ci = 0\n",
    "        best_t_reg = np.inf\n",
    "        best_validation_epoch = 0\n",
    "        last_improvement = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        epochs = 0\n",
    "        show_all_variables()\n",
    "        j = 0\n",
    "\n",
    "        for i in range(self.num_iterations):\n",
    "            # Batch Training\n",
    "            run_options = tf.RunOptions(timeout_in_ms=4000)\n",
    "            x_batch, t_batch, e_batch = self.session.run([self.x_batch, self.t_batch, self.e_batch],\n",
    "                                                         options=run_options)\n",
    "            risk_batch = risk_set(data_t=t_batch)\n",
    "            batch_impute_mask = get_missing_mask(x_batch, self.imputation_values)\n",
    "            batch_size = len(t_batch)\n",
    "            idx_observed = e_batch == 1\n",
    "            # TODO simplify batch processing\n",
    "            feed_dict_train = {self.x: x_batch,\n",
    "                               self.impute_mask: batch_impute_mask,\n",
    "                               self.t: t_batch,\n",
    "                               self.t_lab: t_batch[idx_observed],\n",
    "                               self.e: e_batch,\n",
    "                               self.risk_set: risk_batch, self.batch_size_tensor: batch_size, self.is_training: True,\n",
    "                               self.noise_alpha: np.ones(shape=self.noise_dim)}\n",
    "            for k in range(self.disc_updates):\n",
    "                _ = self.session.run([self.disc_solver], feed_dict=feed_dict_train)\n",
    "\n",
    "            for m in range(self.gen_updates):\n",
    "                _ = self.session.run([self.gen_solver], feed_dict=feed_dict_train)\n",
    "\n",
    "            summary, train_time, train_cost, train_ranking, train_rae, train_reg, train_gen, train_layer_one_recon, \\\n",
    "            train_t_reg, train_t_mse, train_disc = self.session.run(\n",
    "                [self.merged, self.predicted_time, self.cost, self.ranking_partial_lik, self.total_rae,\n",
    "                 self.reg_loss, self.gen_one_loss, self.layer_one_recon, self.t_regularization_loss, self.t_mse,\n",
    "                 self.disc_one_loss],\n",
    "                feed_dict=feed_dict_train)\n",
    "            try:\n",
    "                #RAIBER NEW CHANGE\n",
    "                #train_ci = 0.0\n",
    "                train_ci = concordance_index(event_times=t_batch,\n",
    "                                             predicted_scores=train_time.reshape(t_batch.shape),\n",
    "                                             event_observed=e_batch)\n",
    "            except IndexError:\n",
    "                train_ci = 0.0\n",
    "                print(\"C-Index IndexError\")\n",
    "\n",
    "            tf.verify_tensor_all_finite(train_cost, \"Training Cost has Nan or Infinite\")\n",
    "            if j >= self.num_examples:\n",
    "                epochs += 1\n",
    "                is_epoch = True\n",
    "                # idx = 0\n",
    "                j = 0\n",
    "            else:\n",
    "                # idx = j\n",
    "                j += self.batch_size\n",
    "                is_epoch = False\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                train_print = \"it:{}, trainCI:{}, train_ranking:{}, train_RAE:{},  train_Gen:{}, train_Disc:{}, \" \\\n",
    "                              \"train_reg:{}, train_t_reg:{}, train_t_mse:{}, train_layer_one_recon:{}\".format(\n",
    "                    i, train_ci, train_ranking, train_rae, train_gen, train_disc, train_reg, train_t_reg, train_t_mse,\n",
    "                    train_layer_one_recon)\n",
    "                print(train_print)\n",
    "                logging.debug(train_print)\n",
    "\n",
    "            if is_epoch or (i == (self.num_iterations - 1)):\n",
    "                improved_str = ''\n",
    "                # Calculate  Vaid CI the CI\n",
    "                self.train_ci.append(train_ci)\n",
    "                self.train_cost.append(train_cost)\n",
    "                self.train_t_rae.append(train_rae)\n",
    "                self.train_gen.append(train_gen)\n",
    "                self.train_disc.append(train_disc)\n",
    "                self.train_ranking.append(train_ranking)\n",
    "                self.train_layer_one_recon.append(train_layer_one_recon)\n",
    "\n",
    "                self.train_writer.add_summary(summary, i)\n",
    "                valid_ci, valid_cost, valid_rae, valid_ranking, valid_gen, valid_reg, valid_disc, \\\n",
    "                valid_layer_one_recon, valid_t_reg, valid_t_mse = \\\n",
    "                    self.predict_concordance_index(\n",
    "                        x=self.valid_x,\n",
    "                        e=self.valid_e,\n",
    "                        t=self.valid_t)\n",
    "                self.valid_cost.append(valid_cost)\n",
    "                self.valid_ci.append(valid_ci)\n",
    "                self.valid_t_rae.append(valid_rae)\n",
    "                self.valid_gen.append(valid_gen)\n",
    "                self.valid_disc.append(valid_disc)\n",
    "                self.valid_ranking.append(valid_ranking)\n",
    "                self.valid_layer_one_recon.append(valid_layer_one_recon)\n",
    "                tf.verify_tensor_all_finite(valid_cost, \"Validation Cost has Nan or Infinite\")\n",
    "\n",
    "                if valid_t_reg < best_t_reg:\n",
    "                    self.saver.save(sess=self.session, save_path=self.save_path)\n",
    "                    best_validation_epoch = epochs\n",
    "                    best_t_reg = valid_t_reg\n",
    "                    last_improvement = i\n",
    "                    improved_str = '*'\n",
    "                    # Save  Best Perfoming all variables of the TensorFlow graph to file.\n",
    "                # update best validation accuracy\n",
    "                optimization_print = \"Iteration: {} epochs:{}, Training: RAE:{}, Loss: {},\" \\\n",
    "                                     \" Ranking:{}, Reg:{}, Gen:{}, Disc:{}, Recon_One:{}, T_Reg:{},T_MSE:{},  CI:{}\" \\\n",
    "                                     \" Validation RAE:{} Loss:{}, Ranking:{}, Reg:{}, Gen:{}, Disc:{}, \" \\\n",
    "                                     \"Recon_One:{}, T_Reg:{}, T_MSE:{}, CI:{}, {}\" \\\n",
    "                    .format(i + 1, epochs, train_rae, train_cost, train_ranking, train_reg, train_gen,\n",
    "                            train_disc, train_layer_one_recon, train_t_reg, train_t_mse,\n",
    "                            train_ci, valid_rae, valid_cost, valid_ranking, valid_reg, valid_gen, valid_disc,\n",
    "                            valid_layer_one_recon, valid_t_reg, valid_t_mse, valid_ci, improved_str)\n",
    "\n",
    "                print(optimization_print)\n",
    "                logging.debug(optimization_print)\n",
    "                if i - last_improvement > self.require_improvement or math.isnan(\n",
    "                        train_cost) or epochs >= self.max_epochs:\n",
    "                    # if i - last_improvement > self.require_improvement:\n",
    "                    print(\"No improvement found in a while, stopping optimization.\")\n",
    "                    # Break out from the for-loop.\n",
    "                    break\n",
    "        # Ending time.\n",
    "\n",
    "        end_time = time.time()\n",
    "        time_dif = end_time - start_time\n",
    "        time_dif_print = \"Time usage: \" + str(timedelta(seconds=int(round(time_dif))))\n",
    "        print(time_dif_print)\n",
    "        logging.debug(time_dif_print)\n",
    "        # shutdown everything to avoid zombies\n",
    "        self.session.run(self.queue.close(cancel_pending_enqueues=True))\n",
    "        self.coord.request_stop()\n",
    "        self.coord.join(self.threads)\n",
    "        return best_validation_epoch, epochs\n",
    "\n",
    "    def train_test(self, train=True):\n",
    "\n",
    "        def get_dict(x, t, e):\n",
    "            observed_idx = e == 1\n",
    "            feed_dict = {self.x: x,\n",
    "                         self.impute_mask: get_missing_mask(x, self.imputation_values),\n",
    "                         self.t: t,\n",
    "                         self.t_lab: t[observed_idx],\n",
    "                         self.e: e,\n",
    "                         self.batch_size_tensor: len(t),\n",
    "                         self.is_training: False, self.noise_alpha: np.ones(shape=self.noise_dim)}\n",
    "            return {'feed_dict': feed_dict, 'outcomes': {}}\n",
    "\n",
    "        session_dict = {'Test': get_dict(x=self.test_x, t=self.test_t, e=self.test_e),\n",
    "                        'Train': get_dict(x=self.train_x, t=self.train_t, e=self.train_e),\n",
    "                        'Valid': get_dict(x=self.valid_x, t=self.valid_t, e=self.valid_e)}\n",
    "\n",
    "        if train:\n",
    "            best_epoch, epochs = self.train_neural_network()\n",
    "            self.time_related_metrics(best_epoch, epochs, session_dict=session_dict)\n",
    "        else:\n",
    "            self.generate_statistics(data_x=self.test_x, data_e=self.test_e, data_t=self.test_t, name='Test',\n",
    "                                     session_dict=session_dict['Test'])\n",
    "\n",
    "        self.session.close()\n",
    "\n",
    "    def time_related_metrics(self, best_epoch, epochs, session_dict):\n",
    "        #plot_cost(training=self.train_cost, validation=self.valid_cost, model=self.model, name=\"Cost\",\n",
    "        #          epochs=epochs,\n",
    "        #          best_epoch=best_epoch)\n",
    "        #plot_cost(training=self.train_ci, validation=self.valid_ci, model=self.model, name=\"CI\",\n",
    "        #          epochs=epochs,\n",
    "        #          best_epoch=best_epoch)\n",
    "        #plot_cost(training=self.train_t_rae, validation=self.valid_t_rae, model=self.model, name=\"RAE\",\n",
    "        #          epochs=epochs,\n",
    "        #          best_epoch=best_epoch)\n",
    "        #plot_cost(training=self.train_ranking, validation=self.valid_ranking, model=self.model, name=\"Rank\",\n",
    "        #          epochs=epochs,\n",
    "        #          best_epoch=best_epoch)\n",
    "        #plot_cost(training=self.train_gen, validation=self.valid_gen, model=self.model, name=\"Gen_Loss\",\n",
    "        #          epochs=epochs, best_epoch=best_epoch)\n",
    "\n",
    "        #plot_cost(training=self.train_disc, validation=self.valid_disc, model=self.model, name=\"Disc_Loss\",\n",
    "        #          epochs=epochs, best_epoch=best_epoch)\n",
    "\n",
    "        #plot_cost(training=self.train_layer_one_recon, validation=self.valid_layer_one_recon, model=self.model,\n",
    "        #          name=\"Recon\",\n",
    "        #         epochs=epochs, best_epoch=best_epoch)\n",
    "         # TEST\n",
    "        self.generate_statistics(data_x=self.test_x, data_e=self.test_e, data_t=self.test_t, name='Test',\n",
    "                                 session_dict=session_dict['Test'], t_train_R=self.train_t, y_train_R=self.train_e)\n",
    "\n",
    "        # VALID\n",
    "        self.generate_statistics(data_x=self.valid_x, data_e=self.valid_e, data_t=self.valid_t, name='Valid',\n",
    "                                 session_dict=session_dict['Valid'], t_train_R=self.train_t, y_train_R=self.train_e)\n",
    "        # TRAIN\n",
    "        self.generate_statistics(data_x=self.train_x, data_e=self.train_e, data_t=self.train_t, name='Train',\n",
    "                                 session_dict=session_dict['Train'], t_train_R=self.train_t, y_train_R=self.train_e)\n",
    "      \n",
    "\n",
    "    def generate_statistics(self, data_x, data_e, data_t, name, session_dict, t_train_R, y_train_R, save=True):\n",
    "        self.saver.restore(sess=self.session, save_path=self.save_path)\n",
    "        ci, cost, rae, ranking, gen, reg, disc, layer_one_recon, t_reg, t_mse = \\\n",
    "            self.predict_concordance_index(x=data_x,\n",
    "                                           e=data_e,\n",
    "                                           t=data_t,\n",
    "                                           outcomes=\n",
    "                                           session_dict[\n",
    "                                               'outcomes'])\n",
    "\n",
    "        observed_idx = self.extract_observed_death(name=name, observed_e=data_e, observed_t=data_t, save=save)\n",
    "\n",
    "        median_predicted_time, median_disc_prob, median_disc_score, median_prob_t_gen = self.median_predict_time(session_dict)\n",
    "\n",
    "        if name == 'Test':\n",
    "            self.save_time_samples(x=data_x[observed_idx], e=data_e[observed_idx],\n",
    "                                   t=data_t[observed_idx], name='obs_samples_predicted', cens=False)\n",
    "\n",
    "            self.save_time_samples(x=data_x[np.logical_not(observed_idx)], e=data_e[np.logical_not(observed_idx)],\n",
    "                                   t=data_t[np.logical_not(observed_idx)], name='cen_samples_predicted', cens=True)\n",
    "            \n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_predicted_time'.format(name), median_predicted_time)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_disc_prob'.format(name), median_disc_prob)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_disc_score'.format(name), median_disc_score)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_prob_t_gen'.format(name), median_prob_t_gen)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_empirical_time'.format(name), data_t)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_data_e'.format(name), data_e)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_t_train'.format(name), t_train_R)\n",
    "            np.save('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\{}_y_train'.format(name), y_train_R)\n",
    "        \n",
    "        observed_empirical = data_t[observed_idx]\n",
    "        observed_predicted = median_predicted_time[observed_idx]\n",
    "        #RAIBER NEW CHANGE\n",
    "        observed_ci = concordance_index(event_times=observed_empirical, predicted_scores=observed_predicted,\n",
    "                                        event_observed=data_e[observed_idx])\n",
    "        observed_ci = 0\n",
    "\n",
    "        corr = spearmanr(observed_empirical, observed_predicted)\n",
    "        results = \":{} RAE:{}, Loss:{}, Gen:{}, Disc:{}, Reg:{}, Ranking{}, Recon:{}, T_Reg:{},T_MSE:{},\" \\\n",
    "                  \" CI:{}, Observed: CI:{}, \" \\\n",
    "                  \"Correlation:{}\".format(name, rae, cost, gen, disc, reg, ranking, layer_one_recon, t_reg, t_mse, ci,\n",
    "                                          observed_ci, corr)\n",
    "        logging.debug(results)\n",
    "        print(results)\n",
    "\n",
    "    def median_predict_time(self, session_dict):\n",
    "        #pdb.set_trace()\n",
    "        predicted_time = []\n",
    "        disc_prob = []\n",
    "        disc_score = []\n",
    "        prob_t_gen = []\n",
    "        for p in range(self.sample_size):\n",
    "            gen_time, disc_prob1, disc_score1, prob_t_gen1 = self.session.run([self.predicted_time, self.disc_logit, self.disc_f, self.probability_t_gen], feed_dict=session_dict['feed_dict'])\n",
    "            predicted_time.append(gen_time)\n",
    "            disc_prob.append(disc_prob1)\n",
    "            disc_score.append(disc_score1)\n",
    "            prob_t_gen.append(prob_t_gen1)\n",
    "        predicted_time = np.array(predicted_time)\n",
    "        disc_prob = np.array(disc_prob)\n",
    "        disc_score = np.array(disc_score)\n",
    "        prob_t_gen = np.array(prob_t_gen)\n",
    "        # print(\"predicted_time_shape:{}\".format(predicted_time.shape))\n",
    "        return np.median(predicted_time, axis=0), np.median(disc_prob, axis=0), np.median(disc_score, axis=0), np.median(prob_t_gen, axis=0)\n",
    "\n",
    "    def save_time_samples(self, x, t, e, name, cens=False):\n",
    "        predicted_time = self.generate_time_samples(e, x)\n",
    "        plot_predicted_distribution(predicted=predicted_time, empirical=t, data='Test_' + name, cens=cens)\n",
    "        return\n",
    "\n",
    "    def generate_time_samples(self, e, x):\n",
    "        # observed = e == 1\n",
    "        feed_dict = {self.x: x,\n",
    "                     self.impute_mask: get_missing_mask(x, self.imputation_values),\n",
    "                     # self.t: t,\n",
    "                     # self.t_lab: t[observed],\n",
    "                     self.e: e,\n",
    "                     # self.risk_set: risk_set(t),\n",
    "                     self.batch_size_tensor: len(x),\n",
    "                     self.is_training: False, self.noise_alpha: np.ones(shape=self.noise_dim)}\n",
    "        predicted_time = []\n",
    "        for p in range(self.sample_size):\n",
    "            gen_time = self.session.run(self.predicted_time, feed_dict=feed_dict)\n",
    "            predicted_time.append(gen_time)\n",
    "        predicted_time = np.array(predicted_time)\n",
    "        return predicted_time\n",
    "\n",
    "    def enqueue(self):\n",
    "        \"\"\" Iterates over our data puts small junks into our queue.\"\"\"\n",
    "        # TensorFlow Input Pipelines for Large Data Sets\n",
    "        # ischlag.github.io\n",
    "        # http://ischlag.github.io/2016/11/07/tensorflow-input-pipeline-for-large-datasets/\n",
    "        # http://web.stanford.edu/class/cs20si/lectures/slides_09.pdf\n",
    "        under = 0\n",
    "        max = len(self.train_x)\n",
    "        try:\n",
    "            while not self.coord.should_stop():\n",
    "                # print(\"starting to write into queue\")\n",
    "                upper = under + self.capacity\n",
    "                # print(\"try to enqueue \", under, \" to \", upper)\n",
    "                if upper <= max:\n",
    "                    curr_x = self.train_x[under:upper]\n",
    "                    curr_t = self.train_t[under:upper]\n",
    "                    curr_e = self.train_e[under:upper]\n",
    "                    under = upper\n",
    "                else:\n",
    "                    rest = upper - max\n",
    "                    curr_x = np.concatenate((self.train_x[under:max], self.train_x[0:rest]))\n",
    "                    curr_t = np.concatenate((self.train_t[under:max], self.train_t[0:rest]))\n",
    "                    curr_e = np.concatenate((self.train_e[under:max], self.train_e[0:rest]))\n",
    "                    under = rest\n",
    "\n",
    "                self.session.run(self.enqueue_op,\n",
    "                                 feed_dict={self.x: curr_x, self.t: curr_t, self.e: curr_e})\n",
    "        except tf.errors.CancelledError:\n",
    "            print(\"finished enqueueing\")\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_observed_death(name, observed_e, observed_t, save=False):\n",
    "        idx_observed = observed_e == 1\n",
    "        observed_death = observed_t[idx_observed]\n",
    "        if save:\n",
    "            death_observed_print = \"{} observed_death:{}, percentage:{}\".format(name, observed_death.shape, float(\n",
    "                len(observed_death) / len(observed_t)))\n",
    "            logging.debug(death_observed_print)\n",
    "            print(death_observed_print)\n",
    "        return idx_observed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATE(DATE_AE):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 learning_rate,\n",
    "                 beta1,\n",
    "                 beta2,\n",
    "                 require_improvement,\n",
    "                 seed,\n",
    "                 num_iterations,\n",
    "                 hidden_dim,\n",
    "                 latent_dim,\n",
    "                 input_dim,\n",
    "                 num_examples,\n",
    "                 keep_prob,\n",
    "                 train_data,\n",
    "                 valid_data,\n",
    "                 test_data,\n",
    "                 end_t,\n",
    "                 covariates,\n",
    "                 imputation_values,\n",
    "                 sample_size,\n",
    "                 disc_updates,\n",
    "                 categorical_indices,\n",
    "                 l2_reg,\n",
    "                 gen_updates,\n",
    "                 max_epochs,\n",
    "                 path_large_data=\"\"\n",
    "                 ):\n",
    "        DATE_AE.__init__(self, batch_size=batch_size,\n",
    "                         learning_rate=learning_rate,\n",
    "                         beta1=beta1,\n",
    "                         beta2=beta2,\n",
    "                         require_improvement=require_improvement,\n",
    "                         num_iterations=num_iterations, seed=seed,\n",
    "                         l2_reg=l2_reg,\n",
    "                         hidden_dim=hidden_dim,\n",
    "                         train_data=train_data, test_data=test_data, valid_data=valid_data,\n",
    "                         input_dim=input_dim,\n",
    "                         num_examples=num_examples, keep_prob=keep_prob,\n",
    "                         latent_dim=latent_dim, end_t=end_t,\n",
    "                         path_large_data=path_large_data,\n",
    "                         covariates=covariates,\n",
    "                         categorical_indices=categorical_indices,\n",
    "                         disc_updates=disc_updates,\n",
    "                         sample_size=sample_size, imputation_values=imputation_values,\n",
    "                         max_epochs=max_epochs, gen_updates=gen_updates)\n",
    "\n",
    "        print_model = \"model is DATE\"\n",
    "        print(print_model)\n",
    "        logging.debug(print_model)\n",
    "        self.model = 'DATE'\n",
    "        self.imputation_values = imputation_values\n",
    "\n",
    "    def _objective(self):\n",
    "        self.num_batches = self.num_examples / self.batch_size\n",
    "        logging.debug(\"num batches:{}, batch_size:{} epochs:{}\".format(self.num_batches, self.batch_size,\n",
    "                                                                       int(self.num_iterations / self.num_batches)))\n",
    "        self._build_model()\n",
    "        self.reg_loss = l2_loss(self.l2_reg) + l1_loss(self.l2_reg)\n",
    "        self.layer_one_recon = tf.constant(0.0)\n",
    "        self.cost = self.t_regularization_loss + self.disc_one_loss + self.gen_one_loss\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=self.beta1,\n",
    "                                           beta2=self.beta2)\n",
    "\n",
    "        dvars1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"Discriminator_one\")\n",
    "        genvars1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generate_t_given_x\")\n",
    "        self.disc_solver = optimizer.minimize(self.disc_one_loss, var_list=dvars1)\n",
    "        self.gen_solver = optimizer.minimize(self.gen_one_loss + self.t_regularization_loss, var_list=genvars1)\n",
    "\n",
    "    def _build_model(self):\n",
    "        self._risk_date()\n",
    "\n",
    "    @staticmethod\n",
    "    def log(x):\n",
    "        return tf.log(x + 1e-8)\n",
    "\n",
    "    def _risk_date(self):\n",
    "        def expand_t_dim(t):\n",
    "            return tf.expand_dims(t, axis=1)\n",
    "\n",
    "        indices_lab = tf.where(tf.equal(tf.constant(1.0, dtype=tf.float32), self.e))\n",
    "        x_lab = tf.squeeze(tf.gather(self.x, indices_lab), axis=[1])\n",
    "        t_lab_exp = expand_t_dim(self.t_lab)\n",
    "\n",
    "        t_gen, prob_t_gen = pt_given_x(x=self.x, hidden_dim=self.hidden_dim, is_training=self.is_training,\n",
    "                           batch_norm=self.batch_norm, keep_prob=self.keep_prob, batch_size=self.batch_size_tensor,\n",
    "                           input_dim=self.input_dim, noise_alpha=self.noise_alpha)\n",
    "\n",
    "        # Discriminator B\n",
    "        d_one_real, f_one_real = discriminator_one(pair_one=x_lab, pair_two=t_lab_exp, hidden_dim=self.hidden_dim,\n",
    "                                                   is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                                   keep_prob=self.keep_prob)  # (x_nc, t_nc)\n",
    "        d_one_fake, f_one_fake = discriminator_one(pair_one=self.x, pair_two=t_gen, hidden_dim=self.hidden_dim,\n",
    "                                                   is_training=self.is_training, batch_norm=self.batch_norm,\n",
    "                                                   reuse=True, keep_prob=self.keep_prob)  # (x, t_gen)\n",
    "\n",
    "        # Discriminator loss\n",
    "        self.disc_one_loss = -tf.reduce_mean(self.log(d_one_real)) - tf.reduce_mean(self.log(1 - d_one_fake))\n",
    "\n",
    "        # Generator loss\n",
    "        self.gen_one_loss = tf.reduce_mean(f_one_real) - tf.reduce_mean(f_one_fake)\n",
    "        self.disc_logit = d_one_fake # added b raiber \n",
    "        self.disc_f = f_one_fake # added by raiber\n",
    "        self.probability_t_gen = tf.squeeze(prob_t_gen) # added by raiber\n",
    "        self.predicted_time = tf.squeeze(t_gen)\n",
    "        self.ranking_partial_lik, self.total_rae, self.total_t_recon_loss = \\\n",
    "            batch_metrics(e=self.e,\n",
    "                          risk_set=self.risk_set,\n",
    "                          predicted=self.predicted_time,\n",
    "                          batch_size=self.batch_size_tensor,\n",
    "                          empirical=self.t)\n",
    "\n",
    "        self.t_regularization_loss = self.total_t_recon_loss\n",
    "        self.t_mse = tf.losses.mean_squared_error(labels=self.t_lab,\n",
    "                                                  predictions=tf.gather(self.predicted_time, indices_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of data:   id  time  duration  orig_time  first_time  mat_time  balance_time  \\\n",
      "0   1    48        24         -7          25       113      29087.21   \n",
      "1   2    26         2         18          25       138     105654.77   \n",
      "2   3    29         5         -6          25       114      44378.60   \n",
      "3   4    60        36         -2          25       119      52686.35   \n",
      "4   5    27         3         18          25       138      52100.71   \n",
      "\n",
      "    LTV_time  interest_rate_time  hpi_time  ...  REtype_SF_orig_time  \\\n",
      "0  26.658065               9.200    146.45  ...                    1   \n",
      "1  65.469851               7.680    225.10  ...                    1   \n",
      "2  31.459735              11.375    217.37  ...                    1   \n",
      "3  34.898842              10.500    189.82  ...                    1   \n",
      "4  66.346343               9.155    222.39  ...                    1   \n",
      "\n",
      "   investor_orig_time  balance_orig_time  FICO_orig_time  LTV_orig_time  \\\n",
      "0                   0            45000.0             715           69.4   \n",
      "1                   0           107200.0             558           80.0   \n",
      "2                   0            48600.0             680           83.6   \n",
      "3                   0            63750.0             587           81.8   \n",
      "4                   0            52800.0             527           80.0   \n",
      "\n",
      "   Interest_Rate_orig_time  hpi_orig_time  default_time  payoff_time  \\\n",
      "0                    9.200          87.03             1            0   \n",
      "1                    7.680         186.91             0            1   \n",
      "2                    8.750          89.58             0            1   \n",
      "3                   10.500          97.99             0            0   \n",
      "4                    9.155         186.91             0            1   \n",
      "\n",
      "   status_time  \n",
      "0            1  \n",
      "1            2  \n",
      "2            2  \n",
      "3            0  \n",
      "4            2  \n",
      "\n",
      "[5 rows x 24 columns], data shape:(49982, 24)\n",
      "missing:0.0\n",
      "head of dataset data:   orig_time  mat_time  balance_time  LTV_time  interest_rate_time  hpi_time  \\\n",
      "0  -3.477627 -1.389979     -1.033823 -2.095055            0.988138 -1.667711   \n",
      "1  -0.303878  0.003805     -0.656808 -0.550770            0.301260  1.324293   \n",
      "2  -3.350677 -1.334228     -0.958529 -1.904001            1.971006  1.030228   \n",
      "3  -2.842878 -1.055471     -0.917622 -1.767162            1.575599 -0.017829   \n",
      "4  -0.303878  0.003805     -0.920506 -0.515895            0.967802  1.221199   \n",
      "\n",
      "   gdp_time  uer_time  balance_orig_time  FICO_orig_time  LTV_orig_time  \\\n",
      "0  0.534808  1.372840          -0.991474        0.737401      -1.039149   \n",
      "1  0.240467 -0.776909          -0.693650       -1.419995       0.029385   \n",
      "2  0.001466 -0.896339          -0.974236        0.256453       0.392283   \n",
      "3  0.597611 -0.179756          -0.901696       -1.021495       0.210834   \n",
      "4  0.350143 -0.956054          -0.954126       -1.845978       0.029385   \n",
      "\n",
      "   Interest_Rate_orig_time  hpi_orig_time  REtype_CO_orig_time  \\\n",
      "0                 1.143066      -3.185900                    0   \n",
      "1                 0.680615      -0.276286                    0   \n",
      "2                 1.006156      -3.111615                    0   \n",
      "3                 1.538583      -2.866623                    0   \n",
      "4                 1.129375      -0.276286                    0   \n",
      "\n",
      "   REtype_PU_orig_time  REtype_SF_orig_time  investor_orig_time  \n",
      "0                    0                    1                   0  \n",
      "1                    0                    1                   0  \n",
      "2                    0                    1                   0  \n",
      "3                    0                    1                   0  \n",
      "4                    0                    1                   0  , data shape:(49982, 17)\n",
      "data description:          orig_time      mat_time  balance_time      LTV_time  \\\n",
      "count  4.998200e+04  4.998200e+04  4.998200e+04  4.998200e+04   \n",
      "mean  -2.047100e-16 -2.536129e-16 -5.572661e-17 -2.115337e-16   \n",
      "std    1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
      "min   -7.666977e+00 -6.686357e+00 -1.177047e+00 -3.155755e+00   \n",
      "25%   -4.308278e-01 -1.076980e-01 -6.554586e-01 -6.046198e-01   \n",
      "50%    2.039221e-01  1.710588e-01 -2.727104e-01 -2.360233e-02   \n",
      "75%    5.847720e-01  3.940642e-01  3.966436e-01  6.538653e-01   \n",
      "max    5.028021e+00  5.077178e+00  4.160276e+01  2.139352e+01   \n",
      "\n",
      "       interest_rate_time      hpi_time      gdp_time      uer_time  \\\n",
      "count        4.998200e+04  4.998200e+04  4.998200e+04  4.998200e+04   \n",
      "mean        -2.729467e-17  8.609193e-16 -2.729467e-17 -2.881222e-16   \n",
      "std          1.000010e+00  1.000010e+00  1.000010e+00  1.000010e+00   \n",
      "min         -3.169282e+00 -3.136894e+00 -3.043250e+00 -1.314346e+00   \n",
      "25%         -5.144079e-01 -1.072734e+00 -2.403500e-01 -7.769087e-01   \n",
      "50%         -6.027861e-03 -1.782909e-02  3.045201e-01 -2.991867e-01   \n",
      "75%          6.040282e-01  1.030228e+00  5.976112e-01  2.979657e-01   \n",
      "max          1.377672e+01  1.369563e+00  1.794764e+00  2.387999e+00   \n",
      "\n",
      "       balance_orig_time  FICO_orig_time  LTV_orig_time  \\\n",
      "count       4.998200e+04    4.998200e+04   4.998200e+04   \n",
      "mean       -2.445147e-17    4.139691e-16  -6.255028e-17   \n",
      "std         1.000010e+00    1.000010e+00   1.000010e+00   \n",
      "min        -1.183999e+00   -3.591133e+00  -2.984686e+00   \n",
      "25%        -6.610904e-01   -6.779607e-01  -4.746403e-01   \n",
      "50%        -2.876136e-01    2.284970e-02   2.938497e-02   \n",
      "75%         3.970938e-01    7.374014e-01   5.334103e-01   \n",
      "max         3.709837e+01    2.455074e+00   1.399089e+01   \n",
      "\n",
      "       Interest_Rate_orig_time  hpi_orig_time  REtype_CO_orig_time  \\\n",
      "count             4.998200e+04   4.998200e+04         49982.000000   \n",
      "mean             -2.365538e-16  -2.604366e-16             0.064983   \n",
      "std               1.000010e+00   1.000010e+00             0.246499   \n",
      "min              -1.655980e+00  -3.515664e+00             0.000000   \n",
      "25%              -7.432477e-01  -4.936038e-01             0.000000   \n",
      "50%               2.835761e-01   4.758790e-01             0.000000   \n",
      "75%               6.638812e-01   7.572854e-01             0.000000   \n",
      "max               4.352841e+00   8.708967e-01             1.000000   \n",
      "\n",
      "       REtype_PU_orig_time  REtype_SF_orig_time  investor_orig_time  \n",
      "count         49982.000000         49982.000000        49982.000000  \n",
      "mean              0.115902             0.623625            0.118443  \n",
      "std               0.320110             0.484481            0.323135  \n",
      "min               0.000000             0.000000            0.000000  \n",
      "25%               0.000000             0.000000            0.000000  \n",
      "50%               0.000000             1.000000            0.000000  \n",
      "75%               0.000000             1.000000            0.000000  \n",
      "max               1.000000             1.000000            1.000000  \n",
      "columns:['orig_time' 'mat_time' 'balance_time' 'LTV_time' 'interest_rate_time'\n",
      " 'hpi_time' 'gdp_time' 'uer_time' 'balance_orig_time' 'FICO_orig_time'\n",
      " 'LTV_orig_time' 'Interest_Rate_orig_time' 'hpi_orig_time'\n",
      " 'REtype_CO_orig_time' 'REtype_PU_orig_time' 'REtype_SF_orig_time'\n",
      " 'investor_orig_time']\n",
      "x:[-3.47762744 -1.38997903 -1.03382322 -2.09505531  0.9881376  -1.66771114\n",
      "  0.5348077   1.37284007 -0.99147372  0.73740143 -1.03914866  1.14306563\n",
      " -3.18589953  0.          0.          1.          0.        ], t:24, e:1, len:49982\n",
      "x_shape:(49982, 17)\n",
      "end_time:60\n",
      "observed percent:0.30308911208034894\n",
      "shuffled x:[ 0.71172201  0.33831283 -0.21521574  0.10943108  0.16343216  1.03022833\n",
      "  0.00146605 -0.89633915 -0.26271517  1.43821178  0.02938497  0.58782017\n",
      "  0.83623068  0.          0.          1.          1.        ], t:4, e:0, len:49982\n",
      "num_examples:39985\n",
      "test:9997, valid:7997, train:39985, all: 57979\n",
      "categorical_flat:[13, 14, 15, 16]\n",
      "len covariates:17, categorical:4\n",
      "imputation_values:[0.20392207819158592, 0.17105877772832692, -0.2710399070327385, -0.023597524056526372, -0.006027861145139642, -0.017829093326131175, 0.3045201165680782, -0.29918672172861266, -0.28681878460652066, 0.022849696519850204, 0.029384971240994304, 0.28357607893547515, 0.47587904145774995, 0.0, 0.0, 1.0, 0.0]\n",
      "imputation_values:[0.20392207819158592, 0.17105877772832692, -0.2710399070327385, -0.023597524056526372, -0.006027861145139642, -0.017829093326131175, 0.3045201165680782, -0.29918672172861266, -0.28681878460652066, 0.022849696519850204, 0.029384971240994304, 0.28357607893547515, 0.47587904145774995, 0.0, 0.0, 1.0, 0.0]\n",
      "observed fold:0.30305114417906714\n",
      "observed fold:0.3061918575572672\n",
      "observed fold:0.2993622608478179\n",
      "imputation_values:[0.20392207819158592, 0.17105877772832692, -0.2710399070327385, -0.023597524056526372, -0.006027861145139642, -0.017829093326131175, 0.3045201165680782, -0.29918672172861266, -0.28681878460652066, 0.022849696519850204, 0.029384971240994304, 0.28357607893547515, 0.47587904145774995, 0.0, 0.0, 1.0, 0.0], one_hot_indices:[[13], [14], [15], [16]]\n",
      "end_t:60\n",
      "input_dim:17, continuous:[ 0  1  2  3  4  5  6  7  8  9 10 11 12], size:13, categorical:[[13], [14], [15], [16]], size4\n",
      "model is DATE_AE\n",
      "WARNING:tensorflow:From <ipython-input-13-09dbafe12efb>:81: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-001b2cc10fce>:5: Uniform.__init__ (from tensorflow.python.ops.distributions.uniform) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\tensorflow_core\\python\\ops\\distributions\\uniform.py:131: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "layer input shape:34\n",
      "name:W_decoder_h0_z, shape[34, 50]\n",
      "name:b_decoder_h0_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "WARNING:tensorflow:From <ipython-input-7-c815479674f8>:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "layer input shape:100\n",
      "name:W_decoder_h1_z, shape[100, 50]\n",
      "name:b_decoder_h1_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "name:W_encoder_t, shape[100, 1]\n",
      "name:b_encoder_t, shape[1]\n",
      "scope:Discriminator_one, pair_one:(?, 17), pair_two:(?, 1)\n",
      "layer input shape:17\n",
      "name:W_decoder_h0_z, shape[17, 50]\n",
      "name:b_decoder_h0_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "layer input shape:50\n",
      "name:W_decoder_h1_z, shape[50, 50]\n",
      "name:b_decoder_h1_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "layer input shape:1\n",
      "name:W_decoder_h0_z, shape[1, 50]\n",
      "name:b_decoder_h0_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "layer input shape:50\n",
      "name:W_decoder_h1_z, shape[50, 50]\n",
      "name:b_decoder_h1_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "hidden_pairs:(?, 100)\n",
      "name:W_discriminator_logits, shape[100, 1]\n",
      "name:b_discriminator_logits, shape[1]\n",
      "scope:Discriminator_one, pair_one:(?, 17), pair_two:(?, 1)\n",
      "layer input shape:17\n",
      "name:W_decoder_h0_z, shape[17, 50]\n",
      "name:b_decoder_h0_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "layer input shape:50\n",
      "name:W_decoder_h1_z, shape[50, 50]\n",
      "name:b_decoder_h1_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "layer input shape:1\n",
      "name:W_decoder_h0_z, shape[1, 50]\n",
      "name:b_decoder_h0_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "layer input shape:50\n",
      "name:W_decoder_h1_z, shape[50, 50]\n",
      "name:b_decoder_h1_z, shape[50]\n",
      "batch inputs (?, 50), shape for var50\n",
      "batch mean (50,), var (50,)\n",
      "hidden_pairs:(?, 100)\n",
      "name:W_discriminator_logits, shape[100, 1]\n",
      "name:b_discriminator_logits, shape[1]\n",
      "obs_at_risk:(?,), g_theta:<unknown>\n",
      "WARNING:tensorflow:From <ipython-input-9-011d4144dfda>:28: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From <ipython-input-12-0e847a162361>:118: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\tensorflow_core\\python\\training\\input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-12-0e847a162361>:119: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "model is DATE\n",
      "Training DATE Model:\n",
      "Parameters:, l2_reg:0.001, learning_rate:0.0003, momentum: beta1=0.9 beta2=0.999, batch_size:350, batch_norm:True, hidden_dim:[50, 50], latent_dim:50, num_of_batches:91.39428571428572, keep_prob:0.8, disc_update:1\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "generate_t_given_x/W_decoder_h0_z:0 (float32_ref 34x50) [1700, bytes: 6800]\n",
      "generate_t_given_x/b_decoder_h0_z:0 (float32_ref 50) [50, bytes: 200]\n",
      "generate_t_given_x/h0_z_decoder_batch_norm_offset:0 (float32_ref 50) [50, bytes: 200]\n",
      "generate_t_given_x/h0_z_decoder_batch_norm_scale:0 (float32_ref 50) [50, bytes: 200]\n",
      "generate_t_given_x/W_decoder_h1_z:0 (float32_ref 100x50) [5000, bytes: 20000]\n",
      "generate_t_given_x/b_decoder_h1_z:0 (float32_ref 50) [50, bytes: 200]\n",
      "generate_t_given_x/h1_z_decoder_batch_norm_offset:0 (float32_ref 50) [50, bytes: 200]\n",
      "generate_t_given_x/h1_z_decoder_batch_norm_scale:0 (float32_ref 50) [50, bytes: 200]\n",
      "generate_t_given_x/W_encoder_t:0 (float32_ref 100x1) [100, bytes: 400]\n",
      "generate_t_given_x/b_encoder_t:0 (float32_ref 1) [1, bytes: 4]\n",
      "Discriminator_one/W_decoder_h0_z:0 (float32_ref 17x50) [850, bytes: 3400]\n",
      "Discriminator_one/b_decoder_h0_z:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h0_z_decoder_batch_norm_offset:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h0_z_decoder_batch_norm_scale:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/W_decoder_h1_z:0 (float32_ref 50x50) [2500, bytes: 10000]\n",
      "Discriminator_one/b_decoder_h1_z:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h1_z_decoder_batch_norm_offset:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h1_z_decoder_batch_norm_scale:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/W_decoder_h0_z_2:0 (float32_ref 1x50) [50, bytes: 200]\n",
      "Discriminator_one/b_decoder_h0_z_2:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h0_z_decoder_batch_norm_offset_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h0_z_decoder_batch_norm_scale_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/W_decoder_h1_z_2:0 (float32_ref 50x50) [2500, bytes: 10000]\n",
      "Discriminator_one/b_decoder_h1_z_2:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h1_z_decoder_batch_norm_offset_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/h1_z_decoder_batch_norm_scale_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one/W_discriminator_logits:0 (float32_ref 100x1) [100, bytes: 400]\n",
      "Discriminator_one/b_discriminator_logits:0 (float32_ref 1) [1, bytes: 4]\n",
      "Discriminator_one_1/W_decoder_h0_z:0 (float32_ref 17x50) [850, bytes: 3400]\n",
      "Discriminator_one_1/b_decoder_h0_z:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h0_z_decoder_batch_norm_offset:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h0_z_decoder_batch_norm_scale:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/W_decoder_h1_z:0 (float32_ref 50x50) [2500, bytes: 10000]\n",
      "Discriminator_one_1/b_decoder_h1_z:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h1_z_decoder_batch_norm_offset:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h1_z_decoder_batch_norm_scale:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/W_decoder_h0_z_2:0 (float32_ref 1x50) [50, bytes: 200]\n",
      "Discriminator_one_1/b_decoder_h0_z_2:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h0_z_decoder_batch_norm_offset_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h0_z_decoder_batch_norm_scale_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/W_decoder_h1_z_2:0 (float32_ref 50x50) [2500, bytes: 10000]\n",
      "Discriminator_one_1/b_decoder_h1_z_2:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h1_z_decoder_batch_norm_offset_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/h1_z_decoder_batch_norm_scale_1:0 (float32_ref 50) [50, bytes: 200]\n",
      "Discriminator_one_1/W_discriminator_logits:0 (float32_ref 100x1) [100, bytes: 400]\n",
      "Discriminator_one_1/b_discriminator_logits:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 20303\n",
      "Total bytes of variables: 81212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:0, trainCI:0.5054212853595009, train_ranking:44.277915954589844, train_RAE:0.9398543238639832,  train_Gen:-0.5323433876037598, train_Disc:1.9026119709014893, train_reg:3.2145895957946777, train_t_reg:21.37548828125, train_t_mse:135.15945434570312, train_layer_one_recon:0.0\n",
      "Iteration: 93 epochs:1, Training: RAE:0.3179987967014313, Loss: 14.508081436157227, Ranking:44.13347625732422, Reg:3.2305502891540527, Gen:3.1591458320617676, Disc:0.4756650924682617, Recon_One:0.0, T_Reg:10.873270034790039,T_MSE:155.2769775390625,  CI:0.711461284230406 Validation RAE:0.33243153767390776 Loss:13.652338814076534, Ranking:48.21815695839553, Reg:3.2519607137289137, Gen:3.0970911629664775, Disc:0.43333052761542495, Recon_One:0.0, T_Reg:10.121916985234515, T_MSE:106.46226965696853, CI:0.7942222606935022, *\n",
      "it:100, trainCI:0.7020881916472335, train_ranking:48.92995071411133, train_RAE:0.3277810513973236,  train_Gen:3.5999348163604736, train_Disc:0.40357398986816406, train_reg:3.231377363204956, train_t_reg:11.740514755249023, train_t_mse:191.4081573486328, train_layer_one_recon:0.0\n",
      "Iteration: 186 epochs:2, Training: RAE:0.26847898960113525, Loss: 14.5368013381958, Ranking:50.51691436767578, Reg:3.2362236976623535, Gen:5.571672439575195, Disc:0.17150600254535675, Recon_One:0.0, T_Reg:8.793622970581055,T_MSE:145.32958984375,  CI:0.769468161711758 Validation RAE:0.26131515249440385 Loss:13.250794744020524, Ranking:47.76763842078139, Reg:3.257671722668744, Gen:5.3185441456124884, Disc:0.16775289330316123, Recon_One:0.0, T_Reg:7.764497625540089, T_MSE:104.99697720183124, CI:0.8342379100629348, *\n",
      "it:200, trainCI:0.762985804667978, train_ranking:48.94017791748047, train_RAE:0.2556680142879486,  train_Gen:5.686592102050781, train_Disc:0.15864387154579163, train_reg:3.236778974533081, train_t_reg:8.143271446228027, train_t_mse:122.9645004272461, train_layer_one_recon:0.0\n",
      "Iteration: 279 epochs:3, Training: RAE:0.25321996212005615, Loss: 15.638277053833008, Ranking:48.2386589050293, Reg:3.2386128902435303, Gen:6.880283355712891, Disc:0.09477849304676056, Recon_One:0.0, T_Reg:8.663215637207031,T_MSE:118.9555435180664,  CI:0.777861284088469 Validation RAE:0.2361508954409079 Loss:13.506462264839106, Ranking:47.618145028606, Reg:3.2600767495886482, Gen:6.594039455598423, Disc:0.09187297653083103, Recon_One:0.0, T_Reg:6.8205498897747585, T_MSE:112.08036612820383, CI:0.8487914188564419, *\n",
      "it:300, trainCI:0.7927783016251595, train_ranking:46.36587905883789, train_RAE:0.22350192070007324,  train_Gen:7.157182693481445, train_Disc:0.07974149286746979, train_reg:3.2388112545013428, train_t_reg:8.645132064819336, train_t_mse:294.521728515625, train_layer_one_recon:0.0\n",
      "Iteration: 372 epochs:4, Training: RAE:0.1950502246618271, Loss: 15.675826072692871, Ranking:41.82802200317383, Reg:3.23919677734375, Gen:7.7520341873168945, Disc:0.0654783621430397, Recon_One:0.0, T_Reg:7.85831356048584,T_MSE:282.44879150390625,  CI:0.8415159345391904 Validation RAE:0.209057063229519 Loss:13.976248440272036, Ranking:47.553523355712734, Reg:3.2606645063920454, Gen:7.559815886558198, Disc:0.05791531469287672, Recon_One:0.0, T_Reg:6.358517279129439, T_MSE:110.4328641596922, CI:0.8566443342961878, *\n",
      "it:400, trainCI:0.783043922369765, train_ranking:50.4462890625, train_RAE:0.22705335915088654,  train_Gen:7.980330467224121, train_Disc:0.055304549634456635, train_reg:3.2391793727874756, train_t_reg:7.55302619934082, train_t_mse:168.80816650390625, train_layer_one_recon:0.0\n",
      "Iteration: 465 epochs:5, Training: RAE:0.1903216391801834, Loss: 16.086929321289062, Ranking:42.919281005859375, Reg:3.238976240158081, Gen:8.500110626220703, Disc:0.0430404469370842, Recon_One:0.0, T_Reg:7.5437774658203125,T_MSE:223.109619140625,  CI:0.779277108433735 Validation RAE:0.20397168262624674 Loss:14.254416861324827, Ranking:47.521104415506215, Reg:3.260442507599419, Gen:8.267486138658045, Disc:0.040815907255759815, Recon_One:0.0, T_Reg:5.946114770737353, T_MSE:110.16422122422495, CI:0.8612122625544466, *\n",
      "it:500, trainCI:0.7857061632931545, train_ranking:44.65285873413086, train_RAE:0.2106567621231079,  train_Gen:8.769142150878906, train_Disc:0.03837517276406288, train_reg:3.238797903060913, train_t_reg:7.442080974578857, train_t_mse:136.72195434570312, train_layer_one_recon:0.0\n",
      "Iteration: 558 epochs:6, Training: RAE:0.1766132116317749, Loss: 15.312494277954102, Ranking:43.94639587402344, Reg:3.2387399673461914, Gen:9.08859634399414, Disc:0.033834200352430344, Recon_One:0.0, T_Reg:6.190064430236816,T_MSE:175.70863342285156,  CI:0.8336944428178251 Validation RAE:0.18124373840945832 Loss:14.548002381138135, Ranking:47.48565656655548, Reg:3.26020466889294, Gen:8.908161610771122, Disc:0.030289550646217193, Recon_One:0.0, T_Reg:5.60955122379686, T_MSE:112.51062677251528, CI:0.8651654460511393, *\n",
      "it:600, trainCI:0.8423903231630259, train_ranking:42.630882263183594, train_RAE:0.16396702826023102,  train_Gen:9.321374893188477, train_Disc:0.029382504522800446, train_reg:3.2385332584381104, train_t_reg:5.138544082641602, train_t_mse:96.0448226928711, train_layer_one_recon:0.0\n",
      "Iteration: 651 epochs:7, Training: RAE:0.19029220938682556, Loss: 16.45337677001953, Ranking:40.23153305053711, Reg:3.2383575439453125, Gen:9.720283508300781, Disc:0.023261873051524162, Recon_One:0.0, T_Reg:6.709832191467285,T_MSE:155.2105712890625,  CI:0.8278829604130808 Validation RAE:0.17610453940323328 Loss:14.787082152171658, Ranking:47.476837303216, Reg:3.2598197109865907, Gen:9.420435902952208, Disc:0.023282493401877324, Recon_One:0.0, T_Reg:5.343363788018483, T_MSE:107.18406886179119, CI:0.867802164486933, *\n",
      "it:700, trainCI:0.8151595106740226, train_ranking:53.7925910949707, train_RAE:0.1576150804758072,  train_Gen:10.021407127380371, train_Disc:0.021254820749163628, train_reg:3.238023281097412, train_t_reg:5.663054943084717, train_t_mse:114.25482177734375, train_layer_one_recon:0.0\n",
      "Iteration: 744 epochs:8, Training: RAE:0.1802174597978592, Loss: 16.438587188720703, Ranking:46.76935958862305, Reg:3.2377002239227295, Gen:10.163856506347656, Disc:0.019372323527932167, Recon_One:0.0, T_Reg:6.25535774230957,T_MSE:92.77967071533203,  CI:0.8197103379390711 Validation RAE:0.1585376829866679 Loss:14.946965484361552, Ranking:47.434027379522384, Reg:3.259158034585216, Gen:9.856705405018367, Disc:0.018761015329563546, Recon_One:0.0, T_Reg:5.07149906833425, T_MSE:117.48751017456131, CI:0.8717468372508133, *\n",
      "it:800, trainCI:0.8285444569001121, train_ranking:43.44044876098633, train_RAE:0.14110012352466583,  train_Gen:10.22838020324707, train_Disc:0.018708299845457077, train_reg:3.237182378768921, train_t_reg:4.672601699829102, train_t_mse:99.62255096435547, train_layer_one_recon:0.0\n",
      "Iteration: 837 epochs:9, Training: RAE:0.20302143692970276, Loss: 18.598526000976562, Ranking:46.74959182739258, Reg:3.2367188930511475, Gen:10.50120735168457, Disc:0.017649145796895027, Recon_One:0.0, T_Reg:8.079668998718262,T_MSE:284.94281005859375,  CI:0.8008554605043884 Validation RAE:0.16612160456647154 Loss:15.176949179648041, Ranking:47.468469654811656, Reg:3.2581701999577013, Gen:10.174357409594698, Disc:0.015943197869356013, Recon_One:0.0, T_Reg:4.986648489806717, T_MSE:106.72802793334182, CI:0.8761601711612158, *\n",
      "it:900, trainCI:0.8658105939004815, train_ranking:47.953025817871094, train_RAE:0.1601468324661255,  train_Gen:10.585836410522461, train_Disc:0.016192834824323654, train_reg:3.2360899448394775, train_t_reg:4.697291851043701, train_t_mse:125.08537292480469, train_layer_one_recon:0.0\n",
      "Iteration: 930 epochs:10, Training: RAE:0.14785170555114746, Loss: 16.16922378540039, Ranking:48.4145393371582, Reg:3.2355918884277344, Gen:11.024368286132812, Disc:0.014229124411940575, Recon_One:0.0, T_Reg:5.1306257247924805,T_MSE:120.82396697998047,  CI:0.8392630241423126 Validation RAE:0.15162662905172153 Loss:15.23163060747237, Ranking:47.439106336247555, Reg:3.2570357261277056, Gen:10.441584018851811, Disc:0.014105322837738287, Recon_One:0.0, T_Reg:4.775941280986542, T_MSE:110.37127657116719, CI:0.8791243452314416, *\n",
      "it:1000, trainCI:0.8237060672891934, train_ranking:55.20169448852539, train_RAE:0.16312886774539948,  train_Gen:10.978517532348633, train_Disc:0.012334241531789303, train_reg:3.2345635890960693, train_t_reg:5.670415878295898, train_t_mse:161.74563598632812, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1023 epochs:11, Training: RAE:0.14935202896595, Loss: 18.61988067626953, Ranking:42.94575500488281, Reg:3.2346882820129395, Gen:11.19656753540039, Disc:0.011334309354424477, Recon_One:0.0, T_Reg:7.4119791984558105,T_MSE:354.84033203125,  CI:0.8097326524481826 Validation RAE:0.13882724431524937 Loss:15.317392701042493, Ranking:47.39734856683164, Reg:3.2561261310746734, Gen:10.815245249248436, Disc:0.011601812404538373, Recon_One:0.0, T_Reg:4.4905458418476565, T_MSE:115.98718291866163, CI:0.8825377718258003, *\n",
      "it:1100, trainCI:0.8434577911462761, train_ranking:39.29997253417969, train_RAE:0.1400115042924881,  train_Gen:11.593156814575195, train_Disc:0.010018369182944298, train_reg:3.233444929122925, train_t_reg:5.137948036193848, train_t_mse:100.5069580078125, train_layer_one_recon:0.0\n",
      "Iteration: 1116 epochs:12, Training: RAE:0.15039631724357605, Loss: 16.797374725341797, Ranking:44.065406799316406, Reg:3.2333624362945557, Gen:11.593116760253906, Disc:0.00928435567766428, Recon_One:0.0, T_Reg:5.194972515106201,T_MSE:124.51359558105469,  CI:0.876230084348641 Validation RAE:0.13473005312017103 Loss:15.301748083519373, Ranking:47.39030270602117, Reg:3.2547914983332715, Gen:10.898329291296584, Disc:0.011359803353892695, Recon_One:0.0, T_Reg:4.392059027917597, T_MSE:120.96717837334752, CI:0.8857136763220931, *\n",
      "it:1200, trainCI:0.8419747254045117, train_ranking:43.674137115478516, train_RAE:0.13974863290786743,  train_Gen:11.925164222717285, train_Disc:0.009299302473664284, train_reg:3.231825590133667, train_t_reg:6.187681198120117, train_t_mse:181.1895294189453, train_layer_one_recon:0.0\n",
      "Iteration: 1209 epochs:13, Training: RAE:0.13585038483142853, Loss: 16.029272079467773, Ranking:43.49076843261719, Reg:3.2317452430725098, Gen:11.33876895904541, Disc:0.011815533973276615, Recon_One:0.0, T_Reg:4.67868709564209,T_MSE:121.84657287597656,  CI:0.8395390070921985 Validation RAE:0.14274535865817678 Loss:15.483239812971398, Ranking:47.43748636592757, Reg:3.2531635871869082, Gen:10.983477906464069, Disc:0.01098060076950311, Recon_One:0.0, T_Reg:4.4887814549217975, T_MSE:125.21911378769602, CI:0.8889305257463679, \n",
      "it:1300, trainCI:0.8254551820728291, train_ranking:44.22523498535156, train_RAE:0.14389535784721375,  train_Gen:11.071334838867188, train_Disc:0.015133781358599663, train_reg:3.2310140132904053, train_t_reg:6.457821369171143, train_t_mse:234.1964874267578, train_layer_one_recon:0.0\n",
      "Iteration: 1302 epochs:14, Training: RAE:0.12684519588947296, Loss: 15.605857849121094, Ranking:40.64602279663086, Reg:3.230963945388794, Gen:11.71567153930664, Disc:0.011264221742749214, Recon_One:0.0, T_Reg:3.8789215087890625,T_MSE:74.69652557373047,  CI:0.8715034413083286 Validation RAE:0.12713751213072358 Loss:15.466080031514808, Ranking:47.37408714203801, Reg:3.252377111464273, Gen:10.91947442846953, Disc:0.01219139601865254, Recon_One:0.0, T_Reg:4.534414232828117, T_MSE:224.8663417753673, CI:0.8893933746851158, \n",
      "Iteration: 1395 epochs:15, Training: RAE:0.1420302838087082, Loss: 17.19686508178711, Ranking:51.34564208984375, Reg:3.2308013439178467, Gen:12.32591438293457, Disc:0.006974499206990004, Recon_One:0.0, T_Reg:4.863975524902344,T_MSE:175.380126953125,  CI:0.8628378718477878 Validation RAE:0.13295782156306327 Loss:15.585008692529717, Ranking:47.4073705784124, Reg:3.2522134323544662, Gen:11.172969856753534, Disc:0.011107652605686752, Recon_One:0.0, T_Reg:4.400931101404638, T_MSE:169.45121682135928, CI:0.8922579109077807, \n",
      "it:1400, trainCI:0.8198054624388635, train_ranking:46.666812896728516, train_RAE:0.14127607643604279,  train_Gen:11.87957763671875, train_Disc:0.009226281195878983, train_reg:3.2307357788085938, train_t_reg:5.936220169067383, train_t_mse:146.90760803222656, train_layer_one_recon:0.0\n",
      "Iteration: 1488 epochs:16, Training: RAE:0.13707374036312103, Loss: 17.240230560302734, Ranking:52.732688903808594, Reg:3.231525421142578, Gen:12.873525619506836, Disc:0.005547333508729935, Recon_One:0.0, T_Reg:4.361157417297363,T_MSE:95.49651336669922,  CI:0.8606775977874358 Validation RAE:0.12977196247678735 Loss:16.15176661187177, Ranking:47.40455370329761, Reg:3.2529423083903657, Gen:11.962202642654738, Disc:0.006555745323866743, Recon_One:0.0, T_Reg:4.1830081126981185, T_MSE:118.51124226249455, CI:0.8946682127139347, *\n",
      "it:1500, trainCI:0.8369366068156834, train_ranking:49.2921257019043, train_RAE:0.1429573893547058,  train_Gen:12.382767677307129, train_Disc:0.007268882822245359, train_reg:3.2313313484191895, train_t_reg:5.01068115234375, train_t_mse:124.39081573486328, train_layer_one_recon:0.0\n",
      "Iteration: 1581 epochs:17, Training: RAE:0.13667625188827515, Loss: 17.38271713256836, Ranking:38.59432601928711, Reg:3.2301414012908936, Gen:12.732297897338867, Disc:0.0060052587650716305, Recon_One:0.0, T_Reg:4.644414901733398,T_MSE:97.90465545654297,  CI:0.8562874251497006 Validation RAE:0.1257236178638757 Loss:16.139943650085748, Ranking:47.40143013072041, Reg:3.251549115967449, Gen:11.946899324144976, Disc:0.007133300756115354, Recon_One:0.0, T_Reg:4.185911084735961, T_MSE:132.1519529937252, CI:0.8946628156638584, \n",
      "it:1600, trainCI:0.8364594309799789, train_ranking:48.87556457519531, train_RAE:0.1529952436685562,  train_Gen:12.490660667419434, train_Disc:0.007159031927585602, train_reg:3.229858160018921, train_t_reg:5.278251647949219, train_t_mse:143.6608123779297, train_layer_one_recon:0.0\n",
      "Iteration: 1674 epochs:18, Training: RAE:0.14238522946834564, Loss: 18.234771728515625, Ranking:52.368873596191406, Reg:3.2296805381774902, Gen:13.587488174438477, Disc:0.003782119834795594, Recon_One:0.0, T_Reg:4.6435017585754395,T_MSE:97.5857925415039,  CI:0.8521039909229935 Validation RAE:0.12014378581931624 Loss:16.596855001627272, Ranking:47.38408277463179, Reg:3.2510851984905336, Gen:12.558035172565857, Disc:0.004709474128673669, Recon_One:0.0, T_Reg:4.034110345109427, T_MSE:140.68347033641032, CI:0.896696828911333, *\n",
      "it:1700, trainCI:0.8508893233512946, train_ranking:53.97805404663086, train_RAE:0.14132273197174072,  train_Gen:13.51848030090332, train_Disc:0.004069171845912933, train_reg:3.229424238204956, train_t_reg:4.8313093185424805, train_t_mse:180.99456787109375, train_layer_one_recon:0.0\n",
      "Iteration: 1767 epochs:19, Training: RAE:0.1172274649143219, Loss: 17.581523895263672, Ranking:44.324241638183594, Reg:3.229048490524292, Gen:13.177251815795898, Disc:0.004809297621250153, Recon_One:0.0, T_Reg:4.3994622230529785,T_MSE:114.72209167480469,  CI:0.8414817383263985 Validation RAE:0.11790861862777874 Loss:16.438595855386612, Ranking:47.354608764495794, Reg:3.2504489619508004, Gen:12.412997032681659, Disc:0.005296185115748001, Recon_One:0.0, T_Reg:4.020302719334684, T_MSE:152.97444877705604, CI:0.8983327578209742, *\n",
      "it:1800, trainCI:0.8687101161209332, train_ranking:49.322959899902344, train_RAE:0.15698595345020294,  train_Gen:12.641812324523926, train_Disc:0.0073736743070185184, train_reg:3.22861647605896, train_t_reg:4.488928318023682, train_t_mse:96.5130844116211, train_layer_one_recon:0.0\n",
      "Iteration: 1860 epochs:20, Training: RAE:0.12979350984096527, Loss: 18.212358474731445, Ranking:42.8956413269043, Reg:3.2282211780548096, Gen:13.632234573364258, Disc:0.005102962721139193, Recon_One:0.0, T_Reg:4.575020790100098,T_MSE:103.36791229248047,  CI:0.8688298446590296 Validation RAE:0.12285869377127763 Loss:16.866647468233936, Ranking:47.386111118382956, Reg:3.2496161664800822, Gen:12.741739940416728, Disc:0.004690581772183424, Recon_One:0.0, T_Reg:4.120217014196829, T_MSE:187.59480927517313, CI:0.8988815444032435, \n",
      "it:1900, trainCI:0.8679164343014028, train_ranking:60.198612213134766, train_RAE:0.15231305360794067,  train_Gen:12.91330337524414, train_Disc:0.005343245342373848, train_reg:3.2277801036834717, train_t_reg:6.127894401550293, train_t_mse:554.2738647460938, train_layer_one_recon:0.0\n",
      "Iteration: 1953 epochs:21, Training: RAE:0.13441871106624603, Loss: 17.091463088989258, Ranking:47.12665557861328, Reg:3.2276036739349365, Gen:12.805835723876953, Disc:0.005933400243520737, Recon_One:0.0, T_Reg:4.279694080352783,T_MSE:104.0364990234375,  CI:0.8303043573461791 Validation RAE:0.11620786950799007 Loss:16.642221224461554, Ranking:47.367164160559234, Reg:3.2489945698607277, Gen:12.692031535980655, Disc:0.004860654943682625, Recon_One:0.0, T_Reg:3.945329141002663, T_MSE:199.83111843401542, CI:0.899202772672203, *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:2000, trainCI:0.8659112370160529, train_ranking:49.04975891113281, train_RAE:0.1522829681634903,  train_Gen:13.650239944458008, train_Disc:0.004110551904886961, train_reg:3.227339267730713, train_t_reg:4.776177406311035, train_t_mse:142.89056396484375, train_layer_one_recon:0.0\n",
      "Iteration: 2046 epochs:22, Training: RAE:0.13276775181293488, Loss: 18.148408889770508, Ranking:49.66469955444336, Reg:3.2272253036499023, Gen:13.840003967285156, Disc:0.003549463814124465, Recon_One:0.0, T_Reg:4.304854869842529,T_MSE:126.82245635986328,  CI:0.8872559202326548 Validation RAE:0.11789408142423279 Loss:16.887996750383568, Ranking:47.35025773424647, Reg:3.2486136919321886, Gen:12.943435719986029, Disc:0.004573211812691285, Recon_One:0.0, T_Reg:3.93998785526943, T_MSE:171.22854380901566, CI:0.9007162819555962, *\n",
      "it:2100, trainCI:0.8678442496132027, train_ranking:39.76363754272461, train_RAE:0.14222583174705505,  train_Gen:13.384010314941406, train_Disc:0.0039908066391944885, train_reg:3.2269773483276367, train_t_reg:4.630645751953125, train_t_mse:99.88823699951172, train_layer_one_recon:0.0\n",
      "Iteration: 2139 epochs:23, Training: RAE:0.12432623654603958, Loss: 18.351015090942383, Ranking:45.94479751586914, Reg:3.2266852855682373, Gen:13.519372940063477, Disc:0.003992391750216484, Recon_One:0.0, T_Reg:4.82765007019043,T_MSE:139.02413940429688,  CI:0.8281460674157304 Validation RAE:0.11591457740745054 Loss:17.132504916241786, Ranking:47.3301375793251, Reg:3.248070094888622, Gen:13.163748052219487, Disc:0.004022197849544042, Recon_One:0.0, T_Reg:3.9647348198098245, T_MSE:221.10346042470394, CI:0.9023057650977546, \n",
      "it:2200, trainCI:0.8728203297030293, train_ranking:43.55592346191406, train_RAE:0.13208521902561188,  train_Gen:13.27898120880127, train_Disc:0.005060011520981789, train_reg:3.226588726043701, train_t_reg:4.7491841316223145, train_t_mse:112.94850158691406, train_layer_one_recon:0.0\n",
      "Iteration: 2232 epochs:24, Training: RAE:0.13818590342998505, Loss: 18.67357635498047, Ranking:51.20667266845703, Reg:3.2262632846832275, Gen:13.622364044189453, Disc:0.004059365950524807, Recon_One:0.0, T_Reg:5.047153472900391,T_MSE:233.7277374267578,  CI:0.862924413904608 Validation RAE:0.1201239666879751 Loss:16.777550018890597, Ranking:47.3525812555227, Reg:3.247645297198947, Gen:12.819692392982482, Disc:0.005981399262750448, Recon_One:0.0, T_Reg:3.9518764723505515, T_MSE:174.9129803967473, CI:0.9025657057115216, \n",
      "it:2300, trainCI:0.8694101225249444, train_ranking:49.822628021240234, train_RAE:0.1281144767999649,  train_Gen:14.908060073852539, train_Disc:0.0026901355013251305, train_reg:3.22591495513916, train_t_reg:3.9436495304107666, train_t_mse:112.39331817626953, train_layer_one_recon:0.0\n",
      "Iteration: 2325 epochs:25, Training: RAE:0.1525554656982422, Loss: 19.62919807434082, Ranking:51.10444259643555, Reg:3.2255570888519287, Gen:14.71150016784668, Disc:0.0022690356709063053, Recon_One:0.0, T_Reg:4.915428161621094,T_MSE:98.28257751464844,  CI:0.8508267795926598 Validation RAE:0.11527196101111085 Loss:17.193494135847207, Ranking:47.32761938780326, Reg:3.2469344210651525, Gen:13.358231391014717, Disc:0.005684761059485265, Recon_One:0.0, T_Reg:3.829578010532369, T_MSE:198.4222751744795, CI:0.903096536723345, *\n",
      "it:2400, trainCI:0.9056209646790733, train_ranking:40.32293701171875, train_RAE:0.10497114062309265,  train_Gen:14.411124229431152, train_Disc:0.0028961719945073128, train_reg:3.224824905395508, train_t_reg:3.3236682415008545, train_t_mse:95.71504211425781, train_layer_one_recon:0.0\n",
      "Iteration: 2418 epochs:26, Training: RAE:0.13601525127887726, Loss: 18.440601348876953, Ranking:57.92798614501953, Reg:3.224682092666626, Gen:14.313261032104492, Disc:0.0031197569333016872, Recon_One:0.0, T_Reg:4.124220848083496,T_MSE:145.90496826171875,  CI:0.8563520993654651 Validation RAE:0.11590037052819502 Loss:17.17200369272617, Ranking:47.33435888506255, Reg:3.246053625855488, Gen:13.289445803376218, Disc:0.004397303081897031, Recon_One:0.0, T_Reg:3.878160361962213, T_MSE:195.10706860646167, CI:0.9053334582958005, \n",
      "it:2500, trainCI:0.7892162710246928, train_ranking:42.876590728759766, train_RAE:0.15027956664562225,  train_Gen:14.82072639465332, train_Disc:0.0022563498932868242, train_reg:3.2240400314331055, train_t_reg:6.329642295837402, train_t_mse:168.75071716308594, train_layer_one_recon:0.0\n",
      "Iteration: 2511 epochs:27, Training: RAE:0.1336142122745514, Loss: 18.693992614746094, Ranking:52.971160888671875, Reg:3.2241263389587402, Gen:14.304779052734375, Disc:0.0028319242410361767, Recon_One:0.0, T_Reg:4.38638162612915,T_MSE:191.41404724121094,  CI:0.8739569183000194 Validation RAE:0.10626222642493334 Loss:18.048475336339813, Ranking:47.28925732861493, Reg:3.245494188898069, Gen:14.081340070454734, Disc:0.00355251475860482, Recon_One:0.0, T_Reg:3.9635828991181943, T_MSE:474.3927953600123, CI:0.9034548697115785, \n",
      "it:2600, trainCI:0.8826025459688827, train_ranking:49.23845291137695, train_RAE:0.133384108543396,  train_Gen:14.93465518951416, train_Disc:0.0021337815560400486, train_reg:3.223478078842163, train_t_reg:4.334824085235596, train_t_mse:100.58918762207031, train_layer_one_recon:0.0\n",
      "Iteration: 2604 epochs:28, Training: RAE:0.15501275658607483, Loss: 21.2430477142334, Ranking:43.81507873535156, Reg:3.2234416007995605, Gen:14.73720932006836, Disc:0.0025671853218227625, Recon_One:0.0, T_Reg:6.503271102905273,T_MSE:357.9776916503906,  CI:0.8566131025957973 Validation RAE:0.11624620277776977 Loss:17.989950798982022, Ranking:47.368708666941814, Reg:3.2448049126468, Gen:14.052653715165388, Disc:0.002485095709981554, Recon_One:0.0, T_Reg:3.934812022549399, T_MSE:187.73620365052665, CI:0.9048673918848917, \n",
      "Iteration: 2697 epochs:29, Training: RAE:0.13342167437076569, Loss: 19.103836059570312, Ranking:45.23944854736328, Reg:3.222564220428467, Gen:14.71251106262207, Disc:0.0024224338121712208, Recon_One:0.0, T_Reg:4.3889031410217285,T_MSE:121.91915130615234,  CI:0.8751853964632059 Validation RAE:0.11025004212791001 Loss:17.57790517908373, Ranking:47.32891112338666, Reg:3.2439217174501884, Gen:13.792261267000546, Disc:0.002973516868168624, Recon_One:0.0, T_Reg:3.7826702239081995, T_MSE:212.56971889933274, CI:0.9075874532285932, *\n",
      "it:2700, trainCI:0.8895251608979882, train_ranking:51.01676559448242, train_RAE:0.11143502593040466,  train_Gen:14.875842094421387, train_Disc:0.0022095157764852047, train_reg:3.22237491607666, train_t_reg:3.7172884941101074, train_t_mse:80.29443359375, train_layer_one_recon:0.0\n",
      "Iteration: 2790 epochs:30, Training: RAE:0.1430353820323944, Loss: 19.792739868164062, Ranking:56.29341125488281, Reg:3.221835136413574, Gen:14.841402053833008, Disc:0.0023688501678407192, Recon_One:0.0, T_Reg:4.948968410491943,T_MSE:175.4198455810547,  CI:0.8548720540267377 Validation RAE:0.11361381296397775 Loss:inf, Ranking:47.31824299358078, Reg:3.2431878014416995, Gen:13.718159562187582, Disc:inf, Recon_One:0.0, T_Reg:3.901354493208791, T_MSE:319.6427085182884, CI:0.9071369552313658, \n",
      "it:2800, trainCI:0.8820803295571575, train_ranking:55.10997009277344, train_RAE:0.13417494297027588,  train_Gen:15.508773803710938, train_Disc:0.0016798950964584947, train_reg:3.2218377590179443, train_t_reg:3.923875093460083, train_t_mse:115.3799057006836, train_layer_one_recon:0.0\n",
      "Iteration: 2883 epochs:31, Training: RAE:0.13763853907585144, Loss: 19.962108612060547, Ranking:54.96262741088867, Reg:3.2210986614227295, Gen:15.175331115722656, Disc:0.0018827999010682106, Recon_One:0.0, T_Reg:4.7848944664001465,T_MSE:180.57481384277344,  CI:0.8656235294117647 Validation RAE:0.10608897312806669 Loss:18.616030844387538, Ranking:47.31404906856398, Reg:3.242446445473674, Gen:14.803837608870706, Disc:0.001538967469091529, Recon_One:0.0, T_Reg:3.810654301277858, T_MSE:296.4462565052013, CI:0.9073994386860342, \n",
      "it:2900, trainCI:0.8878146453089245, train_ranking:44.52371597290039, train_RAE:0.1319693922996521,  train_Gen:15.127580642700195, train_Disc:0.0020088849123567343, train_reg:3.2210323810577393, train_t_reg:4.280921936035156, train_t_mse:154.28463745117188, train_layer_one_recon:0.0\n",
      "Iteration: 2976 epochs:32, Training: RAE:0.1148729920387268, Loss: 18.30583953857422, Ranking:50.331783294677734, Reg:3.2204318046569824, Gen:15.041908264160156, Disc:0.0024773331824690104, Recon_One:0.0, T_Reg:3.2614545822143555,T_MSE:115.04889678955078,  CI:0.8890823433019255 Validation RAE:0.10730275380934896 Loss:17.854625761054287, Ranking:47.30311230717562, Reg:3.24177516912451, Gen:14.008891017523142, Disc:0.002860924474404941, Recon_One:0.0, T_Reg:3.842874293001172, T_MSE:304.9827127288517, CI:0.9087660340389873, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:3000, trainCI:0.8962547682348861, train_ranking:44.40399169921875, train_RAE:0.1294354647397995,  train_Gen:15.11056137084961, train_Disc:0.0021830254700034857, train_reg:3.2203049659729004, train_t_reg:3.9631989002227783, train_t_mse:103.91962432861328, train_layer_one_recon:0.0\n",
      "Iteration: 3069 epochs:33, Training: RAE:0.12056683003902435, Loss: 19.67916488647461, Ranking:44.53042984008789, Reg:3.219693183898926, Gen:15.387547492980957, Disc:0.0019036650191992521, Recon_One:0.0, T_Reg:4.2897138595581055,T_MSE:164.3798828125,  CI:0.8471885463572336 Validation RAE:0.10188928096871593 Loss:17.89196087626259, Ranking:47.30407814540102, Reg:3.241031653168232, Gen:14.165400009804015, Disc:0.00264501191905786, Recon_One:0.0, T_Reg:3.723915767800857, T_MSE:380.0643742017423, CI:0.90669631722947, *\n",
      "it:3100, trainCI:0.8618122600907293, train_ranking:44.16870880126953, train_RAE:0.11934037506580353,  train_Gen:15.691276550292969, train_Disc:0.0012797188246622682, train_reg:3.219595432281494, train_t_reg:4.590455055236816, train_t_mse:165.57077026367188, train_layer_one_recon:0.0\n",
      "Iteration: 3162 epochs:34, Training: RAE:0.10770896822214127, Loss: 19.293201446533203, Ranking:44.1756477355957, Reg:3.2193801403045654, Gen:15.771976470947266, Disc:0.0014237129362300038, Recon_One:0.0, T_Reg:3.5198020935058594,T_MSE:95.4104995727539,  CI:0.8823359185090867 Validation RAE:0.10166446153925585 Loss:18.615628815269684, Ranking:47.30526803806005, Reg:3.2407165348820497, Gen:14.948248538253038, Disc:0.0015645074439793452, Recon_One:0.0, T_Reg:3.6658158298729506, T_MSE:254.31893417741918, CI:0.9097907470274968, *\n",
      "it:3200, trainCI:0.8805242125058769, train_ranking:43.56328582763672, train_RAE:0.1110815554857254,  train_Gen:15.72285270690918, train_Disc:0.0014744087820872664, train_reg:3.21943998336792, train_t_reg:3.382594347000122, train_t_mse:83.39510345458984, train_layer_one_recon:0.0\n",
      "Iteration: 3255 epochs:35, Training: RAE:0.12533996999263763, Loss: 19.946378707885742, Ranking:43.24491882324219, Reg:3.218808650970459, Gen:15.877811431884766, Disc:0.0013979899231344461, Recon_One:0.0, T_Reg:4.067169189453125,T_MSE:125.90899658203125,  CI:0.8856819130538494 Validation RAE:0.11091749578047294 Loss:18.648111949909683, Ranking:47.331937026929836, Reg:3.2401412580107785, Gen:14.87918663907382, Disc:0.0016283368505700553, Recon_One:0.0, T_Reg:3.7672970031699164, T_MSE:250.54629193375493, CI:0.9098078203878341, \n",
      "it:3300, trainCI:0.8967344753747324, train_ranking:48.14459228515625, train_RAE:0.13080942630767822,  train_Gen:16.050010681152344, train_Disc:0.0012118646409362555, train_reg:3.219101905822754, train_t_reg:4.0696120262146, train_t_mse:155.283203125, train_layer_one_recon:0.0\n",
      "Iteration: 3348 epochs:36, Training: RAE:0.13425078988075256, Loss: 19.749204635620117, Ranking:46.08243942260742, Reg:3.2186338901519775, Gen:15.603124618530273, Disc:0.0017819921486079693, Recon_One:0.0, T_Reg:4.1442975997924805,T_MSE:104.11711883544922,  CI:0.8672324270001674 Validation RAE:0.10458853422320902 Loss:18.139315217945803, Ranking:47.32453321328353, Reg:3.23996533896754, Gen:14.548903774496644, Disc:0.002279525598385557, Recon_One:0.0, T_Reg:3.5881317897604394, T_MSE:208.7272902108646, CI:0.9091557114334327, *\n",
      "it:3400, trainCI:0.8937691521961185, train_ranking:34.711830139160156, train_RAE:0.0992925614118576,  train_Gen:15.970415115356445, train_Disc:0.0013202822301536798, train_reg:3.218615770339966, train_t_reg:3.6310415267944336, train_t_mse:133.99920654296875, train_layer_one_recon:0.0\n",
      "Iteration: 3441 epochs:37, Training: RAE:0.12545451521873474, Loss: 21.15814208984375, Ranking:47.29299545288086, Reg:3.218390464782715, Gen:16.513771057128906, Disc:0.000981558347120881, Recon_One:0.0, T_Reg:4.643390655517578,T_MSE:210.90228271484375,  CI:0.8795822908734907 Validation RAE:0.100402844487704 Loss:19.15772442700223, Ranking:47.31512927138479, Reg:3.2397203003002195, Gen:15.535632571503864, Disc:0.00112609422543352, Recon_One:0.0, T_Reg:3.6209658442310384, T_MSE:270.80135266751336, CI:0.910034444596323, \n",
      "it:3500, trainCI:0.8454781275792949, train_ranking:43.202552795410156, train_RAE:0.12321528792381287,  train_Gen:16.106521606445312, train_Disc:0.0012360491091385484, train_reg:3.2185161113739014, train_t_reg:4.521666526794434, train_t_mse:120.07367706298828, train_layer_one_recon:0.0\n",
      "Iteration: 3534 epochs:38, Training: RAE:0.11462093889713287, Loss: 20.2548770904541, Ranking:51.195556640625, Reg:3.218324899673462, Gen:16.722736358642578, Disc:0.000875696656294167, Recon_One:0.0, T_Reg:3.5312657356262207,T_MSE:110.3666000366211,  CI:0.8885433386837881 Validation RAE:0.09648706458860208 Loss:19.565273347878225, Ranking:47.28155783657672, Reg:3.239654300659168, Gen:16.04347235562877, Disc:0.0009361792036270583, Recon_One:0.0, T_Reg:3.52086498690528, T_MSE:271.23895067713687, CI:0.9094138357322702, *\n",
      "it:3600, trainCI:0.8423392275017287, train_ranking:51.93831253051758, train_RAE:0.12436150759458542,  train_Gen:16.356334686279297, train_Disc:0.0010881221387535334, train_reg:3.217582941055298, train_t_reg:4.186480522155762, train_t_mse:120.44963836669922, train_layer_one_recon:0.0\n",
      "Iteration: 3627 epochs:39, Training: RAE:0.09506841748952866, Loss: 19.388721466064453, Ranking:42.69776153564453, Reg:3.217522144317627, Gen:16.268896102905273, Disc:0.0011262116022408009, Recon_One:0.0, T_Reg:3.1187000274658203,T_MSE:125.0233154296875,  CI:0.9060150375939849 Validation RAE:0.09697076304489274 Loss:18.951306266159776, Ranking:47.283725087398494, Reg:3.2388462250540075, Gen:15.371045765764075, Disc:0.0012671605811851597, Recon_One:0.0, T_Reg:3.5789931716360837, T_MSE:373.92067441168734, CI:0.909998118297733, \n",
      "it:3700, trainCI:0.8600120264582081, train_ranking:42.84742736816406, train_RAE:0.12077997624874115,  train_Gen:16.785619735717773, train_Disc:0.0010353638790547848, train_reg:3.2171802520751953, train_t_reg:6.926224708557129, train_t_mse:700.9690551757812, train_layer_one_recon:0.0\n",
      "Iteration: 3720 epochs:40, Training: RAE:0.10787370055913925, Loss: 20.088232040405273, Ranking:45.807518005371094, Reg:3.217020273208618, Gen:16.777477264404297, Disc:0.0009769066236913204, Recon_One:0.0, T_Reg:3.30977725982666,T_MSE:126.64949798583984,  CI:0.8975585340081197 Validation RAE:0.09847108292865861 Loss:19.483233446238323, Ranking:47.28723132224236, Reg:3.2383410278015976, Gen:15.794496833197368, Disc:0.0009781408843796198, Recon_One:0.0, T_Reg:3.687758493143215, T_MSE:442.0923342030392, CI:0.9111810582639579, \n",
      "it:3800, trainCI:0.9160810879126434, train_ranking:50.990516662597656, train_RAE:0.12435046583414078,  train_Gen:16.38102912902832, train_Disc:0.0011352712754160166, train_reg:3.2162773609161377, train_t_reg:3.4439401626586914, train_t_mse:104.60194396972656, train_layer_one_recon:0.0\n",
      "Iteration: 3813 epochs:41, Training: RAE:0.11026708036661148, Loss: 20.319169998168945, Ranking:37.10110855102539, Reg:3.2163023948669434, Gen:16.298694610595703, Disc:0.0012339020613580942, Recon_One:0.0, T_Reg:4.019241809844971,T_MSE:186.7442169189453,  CI:0.9043975737524125 Validation RAE:0.10505505125120429 Loss:19.18980511513534, Ranking:47.333247795453204, Reg:3.237618391731761, Gen:15.403677449161385, Disc:0.0013569713495294423, Recon_One:0.0, T_Reg:3.784770650745586, T_MSE:423.9306941812927, CI:0.9110486748529537, \n",
      "it:3900, trainCI:0.9010321797207043, train_ranking:51.037132263183594, train_RAE:0.1174711361527443,  train_Gen:17.551063537597656, train_Disc:0.0006663716631010175, train_reg:3.215724468231201, train_t_reg:4.097783088684082, train_t_mse:128.5086669921875, train_layer_one_recon:0.0\n",
      "Iteration: 3906 epochs:42, Training: RAE:0.15201446413993835, Loss: 20.975502014160156, Ranking:40.69038391113281, Reg:3.2157504558563232, Gen:16.603052139282227, Disc:0.0009904312901198864, Recon_One:0.0, T_Reg:4.371460437774658,T_MSE:93.31966400146484,  CI:0.8622290037510332 Validation RAE:0.10874763986416514 Loss:18.81309222829212, Ranking:47.334927201971674, Reg:3.2370627947534576, Gen:15.136493956191519, Disc:0.0017591860047563104, Recon_One:0.0, T_Reg:3.674839071233496, T_MSE:317.18264760204266, CI:0.911162324272828, \n",
      "Iteration: 3999 epochs:43, Training: RAE:0.1284467577934265, Loss: 21.468599319458008, Ranking:48.655235290527344, Reg:3.215092420578003, Gen:17.563560485839844, Disc:0.000556847604457289, Recon_One:0.0, T_Reg:3.9044814109802246,T_MSE:101.13148498535156,  CI:0.890657111239922 Validation RAE:0.10361553353675682 Loss:19.319293718718434, Ranking:47.32472003661529, Reg:3.236400398355999, Gen:15.446629535560088, Disc:0.0014359298042733607, Recon_One:0.0, T_Reg:3.8712281248816045, T_MSE:555.8086205888304, CI:0.911649304252782, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:4000, trainCI:0.8988857216895568, train_ranking:49.814857482910156, train_RAE:0.10137804597616196,  train_Gen:17.28583335876465, train_Disc:0.0006762139964848757, train_reg:3.2151434421539307, train_t_reg:4.265575885772705, train_t_mse:288.4984130859375, train_layer_one_recon:0.0\n",
      "Iteration: 4092 epochs:44, Training: RAE:0.11148481070995331, Loss: 20.894689559936523, Ranking:48.93118667602539, Reg:3.2148303985595703, Gen:17.30149269104004, Disc:0.0007031324785202742, Recon_One:0.0, T_Reg:3.5924935340881348,T_MSE:102.45381927490234,  CI:0.8735686274509804 Validation RAE:0.09263950594890352 Loss:19.999484913310692, Ranking:47.2335943269986, Reg:3.236136639790489, Gen:16.393860808250025, Disc:0.0007231596352634291, Recon_One:0.0, T_Reg:3.604900790733651, T_MSE:384.7630945253152, CI:0.9117556884129383, \n",
      "it:4100, trainCI:0.8784381404379247, train_ranking:47.54733657836914, train_RAE:0.13545487821102142,  train_Gen:16.935985565185547, train_Disc:0.0008392692543566227, train_reg:3.2145893573760986, train_t_reg:4.066854476928711, train_t_mse:124.86802673339844, train_layer_one_recon:0.0\n",
      "Iteration: 4185 epochs:45, Training: RAE:0.11312433332204819, Loss: 20.677433013916016, Ranking:49.81492233276367, Reg:3.2144980430603027, Gen:17.492412567138672, Disc:0.0006920574232935905, Recon_One:0.0, T_Reg:3.1843276023864746,T_MSE:105.35072326660156,  CI:0.8910981951667176 Validation RAE:0.09782350938536606 Loss:19.08308591815223, Ranking:47.29573069862594, Reg:3.2358020816100335, Gen:15.58106745483429, Disc:0.0014027402429318907, Recon_One:0.0, T_Reg:3.500615618773605, T_MSE:322.31905475562553, CI:0.9121712093740948, *\n",
      "it:4200, trainCI:0.8561204083780655, train_ranking:48.7299690246582, train_RAE:0.12530182301998138,  train_Gen:17.801721572875977, train_Disc:0.0005716387531720102, train_reg:3.2141265869140625, train_t_reg:4.852414131164551, train_t_mse:167.37451171875, train_layer_one_recon:0.0\n",
      "Iteration: 4278 epochs:46, Training: RAE:0.12303561717271805, Loss: 22.321617126464844, Ranking:46.510501861572266, Reg:3.2138986587524414, Gen:17.39696502685547, Disc:0.0006385559099726379, Recon_One:0.0, T_Reg:4.924012660980225,T_MSE:305.8899230957031,  CI:0.8807899658928375 Validation RAE:0.10139550452375763 Loss:19.412929439031885, Ranking:47.28008996282084, Reg:3.2351987248914784, Gen:15.92342993371469, Disc:0.0010904956996120392, Recon_One:0.0, T_Reg:3.4884091286386747, T_MSE:305.10885938191484, CI:0.9123848599045158, *\n",
      "it:4300, trainCI:0.8598681708708328, train_ranking:40.33496856689453, train_RAE:0.11890935897827148,  train_Gen:17.429779052734375, train_Disc:0.0006666372064501047, train_reg:3.2138924598693848, train_t_reg:3.933648109436035, train_t_mse:103.1966552734375, train_layer_one_recon:0.0\n",
      "Iteration: 4371 epochs:47, Training: RAE:0.10501854866743088, Loss: 21.1987361907959, Ranking:49.14044189453125, Reg:3.213364362716675, Gen:17.84015655517578, Disc:0.0005461821565404534, Recon_One:0.0, T_Reg:3.3580331802368164,T_MSE:127.06085968017578,  CI:0.9030593631104393 Validation RAE:0.09875424421473088 Loss:20.05618788144492, Ranking:47.311213661376065, Reg:3.234660887816585, Gen:16.58390354510917, Disc:0.0006861463863277063, Recon_One:0.0, T_Reg:3.471598253110595, T_MSE:270.2164089827295, CI:0.911674732661795, *\n",
      "it:4400, trainCI:0.8788396845530249, train_ranking:46.78605270385742, train_RAE:0.1269376128911972,  train_Gen:17.82300567626953, train_Disc:0.0005601369775831699, train_reg:3.213038206100464, train_t_reg:3.9785819053649902, train_t_mse:108.13034057617188, train_layer_one_recon:0.0\n",
      "Iteration: 4464 epochs:48, Training: RAE:0.11920288950204849, Loss: 22.0037841796875, Ranking:45.2137565612793, Reg:3.21247935295105, Gen:17.5787353515625, Disc:0.0005746101960539818, Recon_One:0.0, T_Reg:4.424473285675049,T_MSE:210.75421142578125,  CI:0.8785686019560178 Validation RAE:0.09545932822157714 Loss:20.09228218253201, Ranking:47.29605459251657, Reg:3.233770012661742, Gen:16.413561236758493, Disc:0.0007951610065808915, Recon_One:0.0, T_Reg:3.677925861402051, T_MSE:607.6338886424603, CI:0.9125348356229799, \n",
      "it:4500, trainCI:0.9015367103016505, train_ranking:40.24908447265625, train_RAE:0.09367857873439789,  train_Gen:17.756332397460938, train_Disc:0.0005312851280905306, train_reg:3.2124156951904297, train_t_reg:3.3776793479919434, train_t_mse:93.33078002929688, train_layer_one_recon:0.0\n",
      "Iteration: 4557 epochs:49, Training: RAE:0.11190403252840042, Loss: 22.047718048095703, Ranking:47.20859146118164, Reg:3.211960554122925, Gen:18.101438522338867, Disc:0.00042792962631210685, Recon_One:0.0, T_Reg:3.9458508491516113,T_MSE:145.82017517089844,  CI:0.900709219858156 Validation RAE:0.0981988014747191 Loss:19.62932211258299, Ranking:47.30704795185798, Reg:3.233247775502006, Gen:16.080195119384825, Disc:0.0011670095446893736, Recon_One:0.0, T_Reg:3.5479597647637, T_MSE:333.15978561235363, CI:0.9140697774225411, \n",
      "it:4600, trainCI:0.8973598159137701, train_ranking:42.41653823852539, train_RAE:0.10239531099796295,  train_Gen:17.710895538330078, train_Disc:0.000562538392841816, train_reg:3.2120649814605713, train_t_reg:3.210991859436035, train_t_mse:86.3010482788086, train_layer_one_recon:0.0\n",
      "Iteration: 4650 epochs:50, Training: RAE:0.11146152764558792, Loss: 22.054672241210938, Ranking:52.30559158325195, Reg:3.2120344638824463, Gen:18.336849212646484, Disc:0.0003907694772351533, Recon_One:0.0, T_Reg:3.717433214187622,T_MSE:117.48152923583984,  CI:0.8842734367282427 Validation RAE:0.09519440227111191 Loss:20.195987997642977, Ranking:47.27383179859592, Reg:3.233322175097373, Gen:16.73717864889107, Disc:0.0013095673885929206, Recon_One:0.0, T_Reg:3.4574999680470806, T_MSE:318.53641754718996, CI:0.9125698126590508, *\n",
      "it:4700, trainCI:0.8855724232393563, train_ranking:45.06885528564453, train_RAE:0.10093969106674194,  train_Gen:18.222492218017578, train_Disc:0.0004855721490457654, train_reg:3.2116808891296387, train_t_reg:3.8256003856658936, train_t_mse:149.82861328125, train_layer_one_recon:0.0\n",
      "Iteration: 4743 epochs:51, Training: RAE:0.11718552559614182, Loss: 23.144390106201172, Ranking:50.953792572021484, Reg:3.211686849594116, Gen:18.108440399169922, Disc:0.00047904258826747537, Recon_One:0.0, T_Reg:5.035471439361572,T_MSE:285.142578125,  CI:0.8741788782213239 Validation RAE:0.09452448080588359 Loss:19.86615666452312, Ranking:47.290622357712756, Reg:3.2329722570004544, Gen:16.444037231010274, Disc:0.0008674890006124569, Recon_One:0.0, T_Reg:3.4212519738828298, T_MSE:313.9521536446071, CI:0.9132158499321166, *\n",
      "it:4800, trainCI:0.893938590443867, train_ranking:48.56071472167969, train_RAE:0.11390268802642822,  train_Gen:18.387243270874023, train_Disc:0.0005407591816037893, train_reg:3.2116103172302246, train_t_reg:3.774214267730713, train_t_mse:153.41209411621094, train_layer_one_recon:0.0\n",
      "Iteration: 4836 epochs:52, Training: RAE:0.1262979507446289, Loss: 21.542003631591797, Ranking:47.968955993652344, Reg:3.211606502532959, Gen:18.24397850036621, Disc:0.0004641467530746013, Recon_One:0.0, T_Reg:3.2975616455078125,T_MSE:57.01192855834961,  CI:0.8891440166604369 Validation RAE:0.10192885890563935 Loss:20.277899176504697, Ranking:47.32153802957328, Reg:3.23289137744033, Gen:16.64912116606563, Disc:0.0008644968633530309, Recon_One:0.0, T_Reg:3.62791381687824, T_MSE:425.2071777015563, CI:0.9133777095396908, \n",
      "it:4900, trainCI:0.861833568406206, train_ranking:45.354000091552734, train_RAE:0.10031504184007645,  train_Gen:18.483131408691406, train_Disc:0.000376838754164055, train_reg:3.2112600803375244, train_t_reg:4.083425045013428, train_t_mse:155.98367309570312, train_layer_one_recon:0.0\n",
      "Iteration: 4929 epochs:53, Training: RAE:0.1341009885072708, Loss: 22.60140609741211, Ranking:52.12015914916992, Reg:3.2111124992370605, Gen:18.31421661376953, Disc:0.00044231110950931907, Recon_One:0.0, T_Reg:4.286746978759766,T_MSE:106.96160888671875,  CI:0.8721823135992073 Validation RAE:0.09788224841373122 Loss:20.260812020740076, Ranking:47.28620788433022, Reg:3.2323941001448464, Gen:16.704976333593358, Disc:0.0008752148273104342, Recon_One:0.0, T_Reg:3.5549605162542908, T_MSE:445.7089974967572, CI:0.9141700899013616, \n",
      "it:5000, trainCI:0.9010194202403325, train_ranking:45.088016510009766, train_RAE:0.11264485120773315,  train_Gen:18.82439613342285, train_Disc:0.0003955300198867917, train_reg:3.2105212211608887, train_t_reg:3.650836944580078, train_t_mse:106.89433288574219, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5022 epochs:54, Training: RAE:0.13666945695877075, Loss: 22.65912628173828, Ranking:52.636268615722656, Reg:3.2104907035827637, Gen:18.843090057373047, Disc:0.00032527680741623044, Recon_One:0.0, T_Reg:3.81571102142334,T_MSE:100.76078033447266,  CI:0.8959242728922459 Validation RAE:0.10548938301946127 Loss:20.848441019615144, Ranking:47.336678232448435, Reg:3.231768183548987, Gen:17.311587184015416, Disc:0.0004902792017503025, Recon_One:0.0, T_Reg:3.536363497396939, T_MSE:321.51804345987046, CI:0.9141350090758662, \n",
      "it:5100, trainCI:0.8832728124633946, train_ranking:43.782630920410156, train_RAE:0.11484920233488083,  train_Gen:18.835174560546875, train_Disc:0.0004480027128010988, train_reg:3.210606336593628, train_t_reg:3.4761948585510254, train_t_mse:101.7891616821289, train_layer_one_recon:0.0\n",
      "Iteration: 5115 epochs:55, Training: RAE:0.12705473601818085, Loss: 23.523637771606445, Ranking:46.369773864746094, Reg:3.2104098796844482, Gen:18.912179946899414, Disc:0.0003091059916187078, Recon_One:0.0, T_Reg:4.611148834228516,T_MSE:108.8225326538086,  CI:0.8548744052229722 Validation RAE:0.10126096569024966 Loss:21.10840501793626, Ranking:47.313295931790464, Reg:3.2316868239914727, Gen:17.420625394473184, Disc:0.0009467475581739498, Recon_One:0.0, T_Reg:3.686832713830377, T_MSE:494.85653591883454, CI:0.9152117205660717, \n",
      "it:5200, trainCI:0.8809992249448518, train_ranking:42.77363967895508, train_RAE:0.11653191596269608,  train_Gen:18.984142303466797, train_Disc:0.00034573767334222794, train_reg:3.210054636001587, train_t_reg:3.969691038131714, train_t_mse:167.2447052001953, train_layer_one_recon:0.0\n",
      "Iteration: 5208 epochs:56, Training: RAE:0.10818027704954147, Loss: 22.139318466186523, Ranking:44.950111389160156, Reg:3.2101762294769287, Gen:18.585243225097656, Disc:0.00038451782893389463, Recon_One:0.0, T_Reg:3.5536904335021973,T_MSE:105.03868103027344,  CI:0.9167858164140692 Validation RAE:0.09427857996933875 Loss:21.091684914088418, Ranking:47.281205059364915, Reg:3.231451625270636, Gen:17.709262516851258, Disc:0.0022388567625887586, Recon_One:0.0, T_Reg:3.380183501587639, T_MSE:323.8234183304426, CI:0.9149593565802963, *\n",
      "it:5300, trainCI:0.8666028911564626, train_ranking:48.28145217895508, train_RAE:0.11435690522193909,  train_Gen:18.979381561279297, train_Disc:0.00031254824716597795, train_reg:3.2095017433166504, train_t_reg:3.6809134483337402, train_t_mse:92.4908676147461, train_layer_one_recon:0.0\n",
      "Iteration: 5301 epochs:57, Training: RAE:0.11435690522193909, Loss: 22.660608291625977, Ranking:48.28145217895508, Reg:3.2095017433166504, Gen:18.979381561279297, Disc:0.00031254824716597795, Recon_One:0.0, T_Reg:3.6809134483337402,T_MSE:92.4908676147461,  CI:0.8666028911564626 Validation RAE:0.09713014565632763 Loss:inf, Ranking:47.32148360204321, Reg:3.230772668963241, Gen:17.826758197833556, Disc:inf, Recon_One:0.0, T_Reg:3.457919694459988, T_MSE:358.61155886910655, CI:0.9152082436203495, \n",
      "Iteration: 5394 epochs:58, Training: RAE:0.12142632901668549, Loss: 23.00759506225586, Ranking:47.85319519042969, Reg:3.208970069885254, Gen:19.333919525146484, Disc:0.00028244429267942905, Recon_One:0.0, T_Reg:3.6733920574188232,T_MSE:121.93302154541016,  CI:0.8885731138398841 Validation RAE:0.10050726576761945 Loss:20.511882043084576, Ranking:47.335899551466014, Reg:3.2302374718739895, Gen:16.922626266393628, Disc:0.000791043080607278, Recon_One:0.0, T_Reg:3.588464782732016, T_MSE:443.79820953060033, CI:0.9150795966286289, \n",
      "it:5400, trainCI:0.9197215777262181, train_ranking:50.097373962402344, train_RAE:0.11306435614824295,  train_Gen:18.993080139160156, train_Disc:0.0003182216314598918, train_reg:3.2093920707702637, train_t_reg:3.954981565475464, train_t_mse:247.42864990234375, train_layer_one_recon:0.0\n",
      "Iteration: 5487 epochs:59, Training: RAE:0.12917111814022064, Loss: 23.16152000427246, Ranking:49.787109375, Reg:3.2092580795288086, Gen:19.272058486938477, Disc:0.0003010026994161308, Recon_One:0.0, T_Reg:3.8891611099243164,T_MSE:93.91999053955078,  CI:0.8776551436901291 Validation RAE:0.0977207896179358 Loss:20.33903631878388, Ranking:47.3261785608568, Reg:3.230527390297225, Gen:16.94758805063526, Disc:0.0010281131686441292, Recon_One:0.0, T_Reg:3.3904200198278587, T_MSE:249.03159614382676, CI:0.9151073084049818, \n",
      "it:5500, trainCI:0.891359845691269, train_ranking:45.14360427856445, train_RAE:0.09574828296899796,  train_Gen:19.234149932861328, train_Disc:0.0002959130215458572, train_reg:3.209160327911377, train_t_reg:3.351778984069824, train_t_mse:81.4418716430664, train_layer_one_recon:0.0\n",
      "Iteration: 5580 epochs:60, Training: RAE:0.111842080950737, Loss: 22.49747085571289, Ranking:49.590110778808594, Reg:3.209012269973755, Gen:18.972904205322266, Disc:0.00032815150916576385, Recon_One:0.0, T_Reg:3.5242385864257812,T_MSE:156.2483367919922,  CI:0.899516053494302 Validation RAE:0.09937143868411409 Loss:20.937825883047513, Ranking:47.31025784048749, Reg:3.230279951642957, Gen:17.40200174619544, Disc:0.001136930204204245, Recon_One:0.0, T_Reg:3.534687116948965, T_MSE:427.11962253522375, CI:0.9150447752766948, \n",
      "it:5600, trainCI:0.9166154161541615, train_ranking:50.3468017578125, train_RAE:0.11039072275161743,  train_Gen:19.341732025146484, train_Disc:0.0002691182307898998, train_reg:3.2087888717651367, train_t_reg:3.2029528617858887, train_t_mse:68.89094543457031, train_layer_one_recon:0.0\n",
      "Iteration: 5673 epochs:61, Training: RAE:0.12389875203371048, Loss: 23.731700897216797, Ranking:43.09208679199219, Reg:3.208435297012329, Gen:19.329139709472656, Disc:0.00027604372007772326, Recon_One:0.0, T_Reg:4.402285575866699,T_MSE:152.17393493652344,  CI:0.8600478468899522 Validation RAE:0.09240082366005606 Loss:21.636314077259257, Ranking:47.28140841130243, Reg:3.2296991548017067, Gen:18.057661401162644, Disc:0.0011680831164660832, Recon_One:0.0, T_Reg:3.577484456363195, T_MSE:631.6220575322862, CI:0.9160923219386038, \n",
      "it:5700, trainCI:0.8512197384287172, train_ranking:55.75131607055664, train_RAE:0.1371365189552307,  train_Gen:19.493228912353516, train_Disc:0.00022907201491761953, train_reg:3.2081117630004883, train_t_reg:4.259918689727783, train_t_mse:118.19132995605469, train_layer_one_recon:0.0\n",
      "Iteration: 5766 epochs:62, Training: RAE:0.10234653204679489, Loss: 23.31028175354004, Ranking:43.808006286621094, Reg:3.2083184719085693, Gen:19.76658058166504, Disc:0.00024548795772716403, Recon_One:0.0, T_Reg:3.5434560775756836,T_MSE:108.63695526123047,  CI:0.8859044727315193 Validation RAE:0.08705246970439473 Loss:22.468754266431453, Ranking:47.25297136248328, Reg:3.2295815554412886, Gen:18.860088897911147, Disc:0.00020554659779724985, Recon_One:0.0, T_Reg:3.608459668769469, T_MSE:844.2384108075562, CI:0.9163577633918716, \n",
      "it:5800, trainCI:0.8876235388551648, train_ranking:51.30120849609375, train_RAE:0.11938229948282242,  train_Gen:18.9157657623291, train_Disc:0.00033301900839433074, train_reg:3.2079925537109375, train_t_reg:3.8554797172546387, train_t_mse:127.7137680053711, train_layer_one_recon:0.0\n",
      "Iteration: 5859 epochs:63, Training: RAE:0.10526794195175171, Loss: 23.252588272094727, Ranking:44.955528259277344, Reg:3.208622932434082, Gen:19.683624267578125, Disc:0.00021656087483279407, Recon_One:0.0, T_Reg:3.5687472820281982,T_MSE:108.63734436035156,  CI:0.8981518567259827 Validation RAE:0.09512262635712804 Loss:21.284315462960322, Ranking:47.325733290235, Reg:3.2298880337744604, Gen:18.110067850055433, Disc:0.00037033575506559686, Recon_One:0.0, T_Reg:3.173877274049466, T_MSE:162.46796770514408, CI:0.9156239721603551, *\n",
      "it:5900, trainCI:0.8837235353422203, train_ranking:46.205345153808594, train_RAE:0.11503015458583832,  train_Gen:19.776851654052734, train_Disc:0.00023846738622523844, train_reg:3.208211660385132, train_t_reg:3.715420961380005, train_t_mse:109.05016326904297, train_layer_one_recon:0.0\n",
      "Iteration: 5952 epochs:64, Training: RAE:0.1016487255692482, Loss: 24.02926254272461, Ranking:43.23886489868164, Reg:3.2082324028015137, Gen:20.337604522705078, Disc:0.00016024659271351993, Recon_One:0.0, T_Reg:3.691498279571533,T_MSE:113.83548736572266,  CI:0.8810959231182475 Validation RAE:0.0891923081752612 Loss:21.509774243725797, Ranking:47.27027247186689, Reg:3.22949491591249, Gen:18.174391423700392, Disc:0.00038630094294782975, Recon_One:0.0, T_Reg:3.334996609951953, T_MSE:381.3324949153143, CI:0.9163388737166048, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:6000, trainCI:0.8961673161347605, train_ranking:52.05272674560547, train_RAE:0.11086409538984299,  train_Gen:20.215261459350586, train_Disc:0.00019303301814943552, train_reg:3.208163022994995, train_t_reg:3.36973237991333, train_t_mse:108.71271514892578, train_layer_one_recon:0.0\n",
      "Iteration: 6045 epochs:65, Training: RAE:0.14136835932731628, Loss: 24.843189239501953, Ranking:41.345062255859375, Reg:3.2078611850738525, Gen:19.841081619262695, Disc:0.0002196537534473464, Recon_One:0.0, T_Reg:5.001887798309326,T_MSE:103.58636474609375,  CI:0.8700547399850709 Validation RAE:0.09026112377539237 Loss:21.36265938470136, Ranking:47.31091814993977, Reg:3.2291212379447933, Gen:18.086450893282368, Disc:0.00040770555649490063, Recon_One:0.0, T_Reg:3.2758007023324662, T_MSE:231.71111723773552, CI:0.9150206961302009, \n",
      "it:6100, trainCI:0.8752913220308002, train_ranking:56.200435638427734, train_RAE:0.11868254840373993,  train_Gen:20.08470344543457, train_Disc:0.00016883693751879036, train_reg:3.2076478004455566, train_t_reg:3.1656742095947266, train_t_mse:111.36237335205078, train_layer_one_recon:0.0\n",
      "Iteration: 6138 epochs:66, Training: RAE:0.08320854604244232, Loss: 23.791595458984375, Ranking:39.7734260559082, Reg:3.207731008529663, Gen:20.284011840820312, Disc:0.00017868104623630643, Recon_One:0.0, T_Reg:3.5074050426483154,T_MSE:134.9366912841797,  CI:0.8949945242543322 Validation RAE:0.0908104155705961 Loss:21.88791969321259, Ranking:47.30145193359711, Reg:3.22899019865747, Gen:18.463445100334713, Disc:0.0003173423552685575, Recon_One:0.0, T_Reg:3.424157325038168, T_MSE:411.41324779667434, CI:0.9164284958846974, \n",
      "it:6200, trainCI:0.9019115461487214, train_ranking:50.329830169677734, train_RAE:0.12555578351020813,  train_Gen:20.656522750854492, train_Disc:0.00016556927585043013, train_reg:3.207470655441284, train_t_reg:5.1418914794921875, train_t_mse:502.6257019042969, train_layer_one_recon:0.0\n",
      "Iteration: 6231 epochs:67, Training: RAE:0.10227363556623459, Loss: 24.3291072845459, Ranking:43.06013107299805, Reg:3.20743465423584, Gen:20.393489837646484, Disc:0.0001754802360665053, Recon_One:0.0, T_Reg:3.9354419708251953,T_MSE:149.12356567382812,  CI:0.8886221795487278 Validation RAE:0.08798467843878698 Loss:21.90219130950733, Ranking:47.22984517173676, Reg:3.2286918802799187, Gen:18.411359289698083, Disc:0.0003458526642904933, Recon_One:0.0, T_Reg:3.490486108647058, T_MSE:507.6455823567505, CI:0.9166097122199489, \n",
      "it:6300, trainCI:0.8652517825311943, train_ranking:46.36747741699219, train_RAE:0.12241575866937637,  train_Gen:20.335893630981445, train_Disc:0.00016973965102806687, train_reg:3.207202911376953, train_t_reg:4.077127933502197, train_t_mse:161.07740783691406, train_layer_one_recon:0.0\n",
      "Iteration: 6324 epochs:68, Training: RAE:0.1190844476222992, Loss: 23.747343063354492, Ranking:52.698768615722656, Reg:3.2070913314819336, Gen:20.16590690612793, Disc:0.0001969174190890044, Recon_One:0.0, T_Reg:3.5812392234802246,T_MSE:88.85065460205078,  CI:0.8736317435496481 Validation RAE:0.08840214801614278 Loss:22.405803318364747, Ranking:47.27437540607421, Reg:3.2283462821595053, Gen:18.930275618798944, Disc:0.00022873024357605889, Recon_One:0.0, T_Reg:3.4752990747222574, T_MSE:614.7094966024551, CI:0.9161428154936437, \n",
      "it:6400, trainCI:0.8845440494590417, train_ranking:49.99704360961914, train_RAE:0.12361878901720047,  train_Gen:20.545761108398438, train_Disc:0.00016209905152209103, train_reg:3.206851005554199, train_t_reg:3.5325026512145996, train_t_mse:100.15126037597656, train_layer_one_recon:0.0\n",
      "Iteration: 6417 epochs:69, Training: RAE:0.12390834093093872, Loss: 25.158668518066406, Ranking:45.174503326416016, Reg:3.2065653800964355, Gen:20.909420013427734, Disc:0.00011420111695770174, Recon_One:0.0, T_Reg:4.2491350173950195,T_MSE:126.09481811523438,  CI:0.889461331501517 Validation RAE:0.09321302130801597 Loss:22.247699023455816, Ranking:47.30457283488449, Reg:3.227816845038928, Gen:18.78112999516695, Disc:0.0002687452486472229, Recon_One:0.0, T_Reg:3.46630025062022, T_MSE:385.119780168036, CI:0.916051999747169, \n",
      "it:6500, trainCI:0.8957882554219293, train_ranking:50.983253479003906, train_RAE:0.10908028483390808,  train_Gen:20.252315521240234, train_Disc:0.00018256623297929764, train_reg:3.206113815307617, train_t_reg:3.486854076385498, train_t_mse:130.9573516845703, train_layer_one_recon:0.0\n",
      "Iteration: 6510 epochs:70, Training: RAE:0.15573041141033173, Loss: 25.712589263916016, Ranking:51.9738655090332, Reg:3.2060723304748535, Gen:20.958026885986328, Disc:0.00013856972509529442, Recon_One:0.0, T_Reg:4.754423141479492,T_MSE:76.23475646972656,  CI:0.8370458962475706 Validation RAE:0.09888086374348307 Loss:22.76575093986661, Ranking:47.37878961385422, Reg:3.227320527738223, Gen:19.201030960168872, Disc:0.00019733925664944629, Recon_One:0.0, T_Reg:3.5645224503372495, T_MSE:256.9021846288977, CI:0.9148490803167196, \n",
      "it:6600, trainCI:0.901242879337131, train_ranking:49.65784454345703, train_RAE:0.09377076476812363,  train_Gen:20.81041717529297, train_Disc:0.00014954671496525407, train_reg:3.206580400466919, train_t_reg:2.9681990146636963, train_t_mse:127.75455474853516, train_layer_one_recon:0.0\n",
      "Iteration: 6603 epochs:71, Training: RAE:0.10992243885993958, Loss: 24.34914779663086, Ranking:41.75389862060547, Reg:3.2065608501434326, Gen:20.774900436401367, Disc:0.000153052867972292, Recon_One:0.0, T_Reg:3.5740933418273926,T_MSE:110.88533020019531,  CI:0.8936600306278714 Validation RAE:0.09411512944524521 Loss:22.25022706535886, Ranking:47.31594301304609, Reg:3.227812285063728, Gen:19.021300236791525, Disc:0.00024579784712534434, Recon_One:0.0, T_Reg:3.228681122077559, T_MSE:221.75133802808193, CI:0.9147139983806774, \n",
      "Iteration: 6696 epochs:72, Training: RAE:0.08226694166660309, Loss: 24.043415069580078, Ranking:43.26887893676758, Reg:3.206350088119507, Gen:21.223514556884766, Disc:0.00013943997328169644, Recon_One:0.0, T_Reg:2.819761037826538,T_MSE:116.40560150146484,  CI:0.9311347054985468 Validation RAE:0.0898144441395085 Loss:22.438454076440927, Ranking:47.30010944350713, Reg:3.2276001262175855, Gen:19.052469263795885, Disc:0.00024336084823598216, Recon_One:0.0, T_Reg:3.3857414122296823, T_MSE:384.27422244324896, CI:0.916720663114785, \n",
      "it:6700, trainCI:0.8815661139751986, train_ranking:36.63888168334961, train_RAE:0.09895626455545425,  train_Gen:21.09912872314453, train_Disc:0.00011725010699592531, train_reg:3.206321954727173, train_t_reg:3.551867961883545, train_t_mse:117.57777404785156, train_layer_one_recon:0.0\n",
      "Iteration: 6789 epochs:73, Training: RAE:0.09757804870605469, Loss: 24.27577018737793, Ranking:44.79570770263672, Reg:3.206282138824463, Gen:20.885150909423828, Disc:0.00013449654215946794, Recon_One:0.0, T_Reg:3.3904850482940674,T_MSE:118.63829803466797,  CI:0.8805049408807906 Validation RAE:0.08735914988429513 Loss:22.859046154205867, Ranking:47.276046464812, Reg:3.2275317265895866, Gen:19.26085524697952, Disc:0.000271489576452767, Recon_One:0.0, T_Reg:3.5979195417456884, T_MSE:685.1119314892316, CI:0.9160131306076778, \n",
      "it:6800, trainCI:0.8427869825678665, train_ranking:47.72268295288086, train_RAE:0.12978346645832062,  train_Gen:20.594539642333984, train_Disc:0.00014761585043743253, train_reg:3.2062504291534424, train_t_reg:4.0135040283203125, train_t_mse:121.18180084228516, train_layer_one_recon:0.0\n",
      "Iteration: 6882 epochs:74, Training: RAE:0.09403058886528015, Loss: 23.882766723632812, Ranking:39.727149963378906, Reg:3.206017017364502, Gen:20.8284969329834, Disc:0.00013797893188893795, Recon_One:0.0, T_Reg:3.054131507873535,T_MSE:78.36825561523438,  CI:0.8764660887302397 Validation RAE:0.09035379229314001 Loss:23.605728173264865, Ranking:47.27791970679801, Reg:3.2272648480410453, Gen:19.84718115728945, Disc:0.0022974301657932164, Recon_One:0.0, T_Reg:3.7562495189054736, T_MSE:1184.7177535783683, CI:0.9161310353939582, \n",
      "it:6900, trainCI:0.9076080414108583, train_ranking:42.507816314697266, train_RAE:0.10283702611923218,  train_Gen:21.353906631469727, train_Disc:9.968991798814386e-05, train_reg:3.2062127590179443, train_t_reg:3.1935606002807617, train_t_mse:119.63192749023438, train_layer_one_recon:0.0\n",
      "Iteration: 6975 epochs:75, Training: RAE:0.10889769345521927, Loss: 24.567428588867188, Ranking:43.416473388671875, Reg:3.205936908721924, Gen:20.934574127197266, Disc:0.00012816225353162736, Recon_One:0.0, T_Reg:3.632725715637207,T_MSE:152.59576416015625,  CI:0.8831069108092144 Validation RAE:0.08832498876187181 Loss:23.249442472716666, Ranking:47.28123477746416, Reg:3.2271842084796156, Gen:19.637588335451998, Disc:0.00016426675861492442, Recon_One:0.0, T_Reg:3.6116899364185704, T_MSE:805.9429842724835, CI:0.9164473855599642, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:7000, trainCI:0.8791901927870187, train_ranking:50.527992248535156, train_RAE:0.12283482402563095,  train_Gen:20.989051818847656, train_Disc:0.0001316574343945831, train_reg:3.205711603164673, train_t_reg:3.1554408073425293, train_t_mse:138.45993041992188, train_layer_one_recon:0.0\n",
      "Iteration: 7068 epochs:76, Training: RAE:0.09505575150251389, Loss: 25.07883071899414, Ranking:44.4791259765625, Reg:3.205700159072876, Gen:21.557424545288086, Disc:9.298259828938171e-05, Recon_One:0.0, T_Reg:3.521312713623047,T_MSE:110.97483825683594,  CI:0.8680176818416672 Validation RAE:0.09169084197791856 Loss:inf, Ranking:47.30209972137837, Reg:3.2269458897757475, Gen:19.704901666749755, Disc:inf, Recon_One:0.0, T_Reg:3.6445288952103225, T_MSE:717.1249134444856, CI:0.9151664683769711, \n",
      "it:7100, trainCI:0.9054957507082153, train_ranking:45.21721267700195, train_RAE:0.09527163952589035,  train_Gen:21.369285583496094, train_Disc:0.00011361448559910059, train_reg:3.2057533264160156, train_t_reg:3.1474480628967285, train_t_mse:162.23228454589844, train_layer_one_recon:0.0\n",
      "Iteration: 7161 epochs:77, Training: RAE:0.10893946886062622, Loss: 25.718162536621094, Ranking:54.49222183227539, Reg:3.205495834350586, Gen:21.96546173095703, Disc:9.026653424371034e-05, Recon_One:0.0, T_Reg:3.7526111602783203,T_MSE:174.89608764648438,  CI:0.8806329711856401 Validation RAE:0.0881183058642083 Loss:inf, Ranking:47.253932525951505, Reg:3.2267402108943624, Gen:19.91430858351133, Disc:inf, Recon_One:0.0, T_Reg:3.52421796693047, T_MSE:619.5720988869056, CI:0.9169763483621458, \n",
      "it:7200, trainCI:0.8903743315508021, train_ranking:48.95799255371094, train_RAE:0.09930828958749771,  train_Gen:21.26742172241211, train_Disc:0.00011589059431571513, train_reg:3.205427646636963, train_t_reg:3.917074680328369, train_t_mse:209.9530487060547, train_layer_one_recon:0.0\n",
      "Iteration: 7254 epochs:78, Training: RAE:0.0956941470503807, Loss: 25.217226028442383, Ranking:44.834964752197266, Reg:3.205195426940918, Gen:22.11956024169922, Disc:7.522058149334043e-05, Recon_One:0.0, T_Reg:3.097590684890747,T_MSE:109.05116271972656,  CI:0.9134598841543844 Validation RAE:0.08899670956514023 Loss:23.342290830355786, Ranking:47.2878131625562, Reg:3.2264378125390007, Gen:19.533135227013993, Disc:0.002879421254539454, Recon_One:0.0, T_Reg:3.806275973785694, T_MSE:1677.0009732386523, CI:0.9162660135405759, \n",
      "it:7300, trainCI:0.8909781576448244, train_ranking:54.42978286743164, train_RAE:0.12178366631269455,  train_Gen:21.33566665649414, train_Disc:0.00010711845970945433, train_reg:3.205383539199829, train_t_reg:4.432320594787598, train_t_mse:217.78994750976562, train_layer_one_recon:0.0\n",
      "Iteration: 7347 epochs:79, Training: RAE:0.1071510761976242, Loss: 25.06201171875, Ranking:49.50079345703125, Reg:3.2051262855529785, Gen:21.654735565185547, Disc:9.548859088681638e-05, Recon_One:0.0, T_Reg:3.4071812629699707,T_MSE:129.503662109375,  CI:0.8680281982168775 Validation RAE:0.08696130639585209 Loss:23.559948693547707, Ranking:47.28557328604245, Reg:3.226368212917529, Gen:19.964513555681524, Disc:0.00015089443133381957, Recon_One:0.0, T_Reg:3.595284199556649, T_MSE:1103.7616242702952, CI:0.9168307317995125, \n",
      "it:7400, trainCI:0.900971727135114, train_ranking:52.687530517578125, train_RAE:0.10527196526527405,  train_Gen:22.047199249267578, train_Disc:7.666650344617665e-05, train_reg:3.2051539421081543, train_t_reg:3.2643020153045654, train_t_mse:105.1379623413086, train_layer_one_recon:0.0\n",
      "Iteration: 7440 epochs:80, Training: RAE:0.1321951001882553, Loss: 25.004863739013672, Ranking:49.98082733154297, Reg:3.2051796913146973, Gen:21.58644676208496, Disc:0.00012752003385685384, Recon_One:0.0, T_Reg:3.41828989982605,T_MSE:110.73419189453125,  CI:0.8870062316526754 Validation RAE:0.09474333581126033 Loss:23.26677488627785, Ranking:47.32955824334547, Reg:3.2264219726251486, Gen:19.810028775000372, Disc:0.00020078907993870064, Recon_One:0.0, T_Reg:3.456545159326906, T_MSE:408.3621579974357, CI:0.9175436094619837, \n",
      "it:7500, trainCI:0.8380736543909348, train_ranking:44.68339920043945, train_RAE:0.12194131314754486,  train_Gen:21.662261962890625, train_Disc:9.945464262273163e-05, train_reg:3.205040216445923, train_t_reg:3.8340797424316406, train_t_mse:96.00106048583984, train_layer_one_recon:0.0\n",
      "Iteration: 7533 epochs:81, Training: RAE:0.10316794365644455, Loss: 25.167064666748047, Ranking:44.33300018310547, Reg:3.2048749923706055, Gen:21.655271530151367, Disc:9.127421071752906e-05, Recon_One:0.0, T_Reg:3.511702537536621,T_MSE:140.19195556640625,  CI:0.869213095921884 Validation RAE:0.08814688592616268 Loss:23.66634474794045, Ranking:47.27774607295973, Reg:3.2261152542932816, Gen:19.84358568467005, Disc:0.00034208133565910055, Recon_One:0.0, T_Reg:3.822416679045551, T_MSE:1456.6188255101126, CI:0.9162621733318679, \n",
      "it:7600, trainCI:0.8971246335065068, train_ranking:50.19136428833008, train_RAE:0.10255344957113266,  train_Gen:22.395217895507812, train_Disc:9.153809514828026e-05, train_reg:3.2049381732940674, train_t_reg:3.3368844985961914, train_t_mse:103.70578002929688, train_layer_one_recon:0.0\n",
      "Iteration: 7626 epochs:82, Training: RAE:0.13125894963741302, Loss: 26.29537582397461, Ranking:58.28233337402344, Reg:3.2047152519226074, Gen:22.05951690673828, Disc:6.944432243471965e-05, Recon_One:0.0, T_Reg:4.235788822174072,T_MSE:111.56981658935547,  CI:0.8562650280523644 Validation RAE:0.09018795156465466 Loss:23.567465202233276, Ranking:47.28335477984725, Reg:3.2259544551678117, Gen:20.12990721616355, Disc:0.0011517796470506827, Recon_One:0.0, T_Reg:3.4364062427684368, T_MSE:643.681060831085, CI:0.9174706973912424, \n",
      "it:7700, trainCI:0.9094078583287216, train_ranking:46.34526443481445, train_RAE:0.09665098786354065,  train_Gen:22.065040588378906, train_Disc:9.592348942533135e-05, train_reg:3.2047464847564697, train_t_reg:3.218350887298584, train_t_mse:108.1341781616211, train_layer_one_recon:0.0\n",
      "Iteration: 7719 epochs:83, Training: RAE:0.12396861612796783, Loss: 26.01561164855957, Ranking:54.0035514831543, Reg:3.2045905590057373, Gen:22.074249267578125, Disc:8.535609231330454e-05, Recon_One:0.0, T_Reg:3.941277027130127,T_MSE:169.889404296875,  CI:0.8829614021645437 Validation RAE:0.08607412741655884 Loss:23.771114237266463, Ranking:47.27642612187761, Reg:3.2258289358504673, Gen:20.21837874891103, Disc:0.00013773798900291304, Recon_One:0.0, T_Reg:3.5525978751908216, T_MSE:825.6273573274029, CI:0.9183199024628504, \n",
      "it:7800, trainCI:0.8827462072512214, train_ranking:39.52863311767578, train_RAE:0.08331984281539917,  train_Gen:21.838581085205078, train_Disc:8.910975157050416e-05, train_reg:3.204477071762085, train_t_reg:3.0271594524383545, train_t_mse:89.04439544677734, train_layer_one_recon:0.0\n",
      "Iteration: 7812 epochs:84, Training: RAE:0.10930556058883667, Loss: 26.22547721862793, Ranking:45.429168701171875, Reg:3.204479932785034, Gen:22.32714080810547, Disc:6.447178748203442e-05, Recon_One:0.0, T_Reg:3.8982717990875244,T_MSE:181.19639587402344,  CI:0.8934514681660704 Validation RAE:0.09311658194121143 Loss:23.894119620457342, Ranking:47.29364558996611, Reg:3.2257175764561117, Gen:20.250034284573786, Disc:0.000142447972940295, Recon_One:0.0, T_Reg:3.6439428497019657, T_MSE:871.0451363891128, CI:0.9182936437384411, \n",
      "it:7900, trainCI:0.906855151045701, train_ranking:53.466190338134766, train_RAE:0.10746771842241287,  train_Gen:22.224849700927734, train_Disc:8.546897151973099e-05, train_reg:3.204448699951172, train_t_reg:3.0933680534362793, train_t_mse:139.99354553222656, train_layer_one_recon:0.0\n",
      "Iteration: 7905 epochs:85, Training: RAE:0.13362638652324677, Loss: 26.302465438842773, Ranking:54.17378616333008, Reg:3.2043864727020264, Gen:22.471744537353516, Disc:6.318328087218106e-05, Recon_One:0.0, T_Reg:3.830658435821533,T_MSE:111.69182586669922,  CI:0.8769171962348894 Validation RAE:0.08789901390468625 Loss:23.956496575124056, Ranking:47.252994068446746, Reg:3.225623496967777, Gen:20.330856328489364, Disc:0.00013495785806328525, Recon_One:0.0, T_Reg:3.625505336064077, T_MSE:1026.9369268232515, CI:0.919592879754866, \n",
      "Iteration: 7998 epochs:86, Training: RAE:0.10032962262630463, Loss: 26.483022689819336, Ranking:46.37544250488281, Reg:3.204658269882202, Gen:22.697296142578125, Disc:5.522232095245272e-05, Recon_One:0.0, T_Reg:3.7856719493865967,T_MSE:211.11505126953125,  CI:0.8872006606110653 Validation RAE:0.08596733729083106 Loss:23.502645937371167, Ranking:47.25948780704263, Reg:3.225897095479771, Gen:20.176594266596922, Disc:0.00016163854133618402, Recon_One:0.0, T_Reg:3.325890068174884, T_MSE:458.1465713140352, CI:0.9181166827695959, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:8000, trainCI:0.8749209270228305, train_ranking:44.73487091064453, train_RAE:0.10946767777204514,  train_Gen:22.490446090698242, train_Disc:7.049635314615443e-05, train_reg:3.2045514583587646, train_t_reg:3.8387198448181152, train_t_mse:116.61064910888672, train_layer_one_recon:0.0\n",
      "Iteration: 8091 epochs:87, Training: RAE:0.1231105700135231, Loss: 25.73232078552246, Ranking:55.596824645996094, Reg:3.204653024673462, Gen:22.63351058959961, Disc:6.729063898092136e-05, Recon_One:0.0, T_Reg:3.0987436771392822,T_MSE:105.08465576171875,  CI:0.9010477299185099 Validation RAE:0.08537062129702913 Loss:23.987148540592706, Ranking:47.23367763784985, Reg:3.225891815508487, Gen:20.672291995019066, Disc:0.00011009524171132321, Recon_One:0.0, T_Reg:3.3147463757380318, T_MSE:478.42353328520227, CI:0.9200445194357634, \n",
      "it:8100, trainCI:0.8697540583093545, train_ranking:47.198646545410156, train_RAE:0.10011499375104904,  train_Gen:21.993385314941406, train_Disc:9.154855797532946e-05, train_reg:3.2046892642974854, train_t_reg:3.271135091781616, train_t_mse:97.93717956542969, train_layer_one_recon:0.0\n",
      "Iteration: 8184 epochs:88, Training: RAE:0.10834360122680664, Loss: 25.984912872314453, Ranking:53.305870056152344, Reg:3.2049617767333984, Gen:22.577552795410156, Disc:6.512748950626701e-05, Recon_One:0.0, T_Reg:3.4072954654693604,T_MSE:102.7034683227539,  CI:0.8975465477114042 Validation RAE:0.08612497208568473 Loss:24.049264794068588, Ranking:47.263693251996784, Reg:3.226202613818164, Gen:20.734944927315272, Disc:0.00010823770287955079, Recon_One:0.0, T_Reg:3.314211418647475, T_MSE:486.7656855638644, CI:0.9182146599863641, \n",
      "it:8200, trainCI:0.9247642144974401, train_ranking:47.7420768737793, train_RAE:0.11087463051080704,  train_Gen:22.702247619628906, train_Disc:5.99764462094754e-05, train_reg:3.2049243450164795, train_t_reg:2.7156524658203125, train_t_mse:106.901123046875, train_layer_one_recon:0.0\n",
      "Iteration: 8277 epochs:89, Training: RAE:0.1109117642045021, Loss: 26.266212463378906, Ranking:56.15458679199219, Reg:3.204840660095215, Gen:22.92801284790039, Disc:6.231611769180745e-05, Recon_One:0.0, T_Reg:3.338137626647949,T_MSE:106.61366271972656,  CI:0.8749366388645684 Validation RAE:0.08758654962580875 Loss:23.856926167087284, Ranking:47.28756757084841, Reg:3.2260806944812406, Gen:20.552539741961645, Disc:0.00013628782450533704, Recon_One:0.0, T_Reg:3.3042500432586763, T_MSE:497.7137735549757, CI:0.9191871668943288, \n",
      "it:8300, trainCI:0.9047508824720791, train_ranking:43.91554260253906, train_RAE:0.08370121568441391,  train_Gen:22.799800872802734, train_Disc:7.423978968290612e-05, train_reg:3.205124616622925, train_t_reg:2.8588335514068604, train_t_mse:136.00538635253906, train_layer_one_recon:0.0\n",
      "Iteration: 8370 epochs:90, Training: RAE:0.10567909479141235, Loss: 26.470264434814453, Ranking:44.54762268066406, Reg:3.2047648429870605, Gen:23.0677547454834, Disc:4.751398228108883e-05, Recon_One:0.0, T_Reg:3.4024622440338135,T_MSE:136.8226776123047,  CI:0.903420639990708 Validation RAE:0.08758072117924676 Loss:23.9797556625391, Ranking:47.26804695353592, Reg:3.226004374896316, Gen:20.662587115626582, Disc:0.0001313606722942336, Recon_One:0.0, T_Reg:3.317037267626502, T_MSE:481.6290420011325, CI:0.9195434240940714, \n",
      "it:8400, trainCI:0.9207889295371401, train_ranking:48.52337646484375, train_RAE:0.108355812728405,  train_Gen:23.127826690673828, train_Disc:5.494493234436959e-05, train_reg:3.204651117324829, train_t_reg:3.098938465118408, train_t_mse:90.1932373046875, train_layer_one_recon:0.0\n",
      "Iteration: 8463 epochs:91, Training: RAE:0.13081040978431702, Loss: 26.97209930419922, Ranking:53.39994812011719, Reg:3.20468807220459, Gen:23.06020736694336, Disc:5.317082104738802e-05, Recon_One:0.0, T_Reg:3.911839723587036,T_MSE:96.47071838378906,  CI:0.8661432586992343 Validation RAE:0.08596338546449755 Loss:23.835245144133182, Ranking:47.29361470317757, Reg:3.2259270953166124, Gen:20.562078417040667, Disc:0.00015228145185585963, Recon_One:0.0, T_Reg:3.2730144948769735, T_MSE:483.374286464144, CI:0.919010309714908, \n",
      "it:8500, trainCI:0.8986558299468584, train_ranking:41.22459030151367, train_RAE:0.09178199619054794,  train_Gen:22.886714935302734, train_Disc:5.526355016627349e-05, train_reg:3.2046091556549072, train_t_reg:3.5200161933898926, train_t_mse:120.09111785888672, train_layer_one_recon:0.0\n",
      "Iteration: 8556 epochs:92, Training: RAE:0.1085202693939209, Loss: 26.796720504760742, Ranking:48.87398147583008, Reg:3.2046990394592285, Gen:23.259784698486328, Disc:5.0531984015833586e-05, Recon_One:0.0, T_Reg:3.5368847846984863,T_MSE:137.64715576171875,  CI:0.8922630050171639 Validation RAE:0.08506387215011252 Loss:24.140566307946536, Ranking:47.27340739742583, Reg:3.2259381352565697, Gen:20.99820471292915, Disc:0.00010465825499806434, Recon_One:0.0, T_Reg:3.1422568408044946, T_MSE:332.4430448287157, CI:0.9187480338390889, *\n",
      "it:8600, trainCI:0.9126048031831746, train_ranking:35.915096282958984, train_RAE:0.0961700901389122,  train_Gen:23.603557586669922, train_Disc:4.098917997907847e-05, train_reg:3.2048556804656982, train_t_reg:3.1121773719787598, train_t_mse:109.55403900146484, train_layer_one_recon:0.0\n",
      "Iteration: 8649 epochs:93, Training: RAE:0.10818275809288025, Loss: 25.991365432739258, Ranking:53.67850112915039, Reg:3.2048661708831787, Gen:23.141094207763672, Disc:5.4128075134940445e-05, Recon_One:0.0, T_Reg:2.850217819213867,T_MSE:93.62092590332031,  CI:0.9184151412321369 Validation RAE:0.08486518812198944 Loss:24.510838548079033, Ranking:47.27738628361215, Reg:3.2261063743415765, Gen:21.075777633646002, Disc:0.0005731321688985952, Recon_One:0.0, T_Reg:3.434487714072205, T_MSE:791.8990817445061, CI:0.9192592486496737, \n",
      "it:8700, trainCI:0.8908830244783094, train_ranking:48.05463790893555, train_RAE:0.10786301642656326,  train_Gen:23.08753204345703, train_Disc:4.874229125562124e-05, train_reg:3.204699993133545, train_t_reg:2.8164405822753906, train_t_mse:80.27851867675781, train_layer_one_recon:0.0\n",
      "Iteration: 8742 epochs:94, Training: RAE:0.09068303555250168, Loss: 26.41623878479004, Ranking:46.903018951416016, Reg:3.204828977584839, Gen:23.311279296875, Disc:4.2733619920909405e-05, Recon_One:0.0, T_Reg:3.1049160957336426,T_MSE:134.5966033935547,  CI:0.9165582303188029 Validation RAE:0.08633473110792263 Loss:24.3368064371872, Ranking:47.295488112119195, Reg:3.2260689345451987, Gen:21.08815321851346, Disc:0.00011936520498835644, Recon_One:0.0, T_Reg:3.248533699323762, T_MSE:422.0030229956534, CI:0.9199501748488541, \n",
      "it:8800, trainCI:0.8938605619146722, train_ranking:46.780330657958984, train_RAE:0.09724763035774231,  train_Gen:23.71479034423828, train_Disc:5.529075860977173e-05, train_reg:3.204716205596924, train_t_reg:3.1353566646575928, train_t_mse:116.09272003173828, train_layer_one_recon:0.0\n",
      "Iteration: 8835 epochs:95, Training: RAE:0.08971361815929413, Loss: 26.976736068725586, Ranking:42.94824981689453, Reg:3.204855442047119, Gen:23.683565139770508, Disc:4.375668868306093e-05, Recon_One:0.0, T_Reg:3.2931275367736816,T_MSE:129.2439422607422,  CI:0.8931157270029674 Validation RAE:0.08595569784326436 Loss:24.78079634248219, Ranking:47.28630705596477, Reg:3.226095574400314, Gen:21.375414793590046, Disc:0.0013353662757529707, Recon_One:0.0, T_Reg:3.404046373544998, T_MSE:725.6182193219461, CI:0.919338699454161, \n",
      "it:8900, trainCI:0.8708345620760838, train_ranking:52.44321060180664, train_RAE:0.09501047432422638,  train_Gen:23.919857025146484, train_Disc:3.567944804672152e-05, train_reg:3.2046542167663574, train_t_reg:3.3895087242126465, train_t_mse:128.34051513671875, train_layer_one_recon:0.0\n",
      "Iteration: 8928 epochs:96, Training: RAE:0.1080903708934784, Loss: 26.741334915161133, Ranking:46.121612548828125, Reg:3.2046074867248535, Gen:23.34621810913086, Disc:4.7383404307765886e-05, Recon_One:0.0, T_Reg:3.3950695991516113,T_MSE:85.58328247070312,  CI:0.8689221259451405 Validation RAE:0.08484591648767065 Loss:25.072499103839508, Ranking:47.27269950562363, Reg:3.225845975757793, Gen:21.614019909813745, Disc:7.211389235971195e-05, Recon_One:0.0, T_Reg:3.4584073091993277, T_MSE:960.0349494482825, CI:0.9199193493897649, \n",
      "it:9000, trainCI:0.8852750152222447, train_ranking:50.52971649169922, train_RAE:0.10838678479194641,  train_Gen:23.577495574951172, train_Disc:4.041524152853526e-05, train_reg:3.2047393321990967, train_t_reg:3.1395304203033447, train_t_mse:103.8906021118164, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9021 epochs:97, Training: RAE:0.11302336305379868, Loss: 26.931093215942383, Ranking:45.185997009277344, Reg:3.204885959625244, Gen:23.46334457397461, Disc:4.246813477948308e-05, Recon_One:0.0, T_Reg:3.4677062034606934,T_MSE:137.56423950195312,  CI:0.8980775793425094 Validation RAE:0.08341397682983487 Loss:24.408796863047886, Ranking:47.24548240147398, Reg:3.2261262942332394, Gen:21.24005143934896, Disc:0.00010854246865155457, Recon_One:0.0, T_Reg:3.1686367982027455, T_MSE:406.04219888618206, CI:0.9215703796606771, \n",
      "it:9100, trainCI:0.9128348214285714, train_ranking:46.007408142089844, train_RAE:0.08697912096977234,  train_Gen:24.116226196289062, train_Disc:3.6489545891527086e-05, train_reg:3.205026626586914, train_t_reg:2.644634246826172, train_t_mse:77.35305786132812, train_layer_one_recon:0.0\n",
      "Iteration: 9114 epochs:98, Training: RAE:0.10922899842262268, Loss: 27.376985549926758, Ranking:47.29786682128906, Reg:3.20505428314209, Gen:24.140682220458984, Disc:2.8341384677332826e-05, Recon_One:0.0, T_Reg:3.236274242401123,T_MSE:119.81369018554688,  CI:0.9260005445140213 Validation RAE:0.08825742228151605 Loss:24.92146963654003, Ranking:47.29667783782261, Reg:3.2262957333117197, Gen:21.67715743077879, Disc:7.50329986389501e-05, Recon_One:0.0, T_Reg:3.2442370131267104, T_MSE:363.316357712664, CI:0.9188973349262934, \n",
      "it:9200, trainCI:0.873410487212459, train_ranking:54.14043045043945, train_RAE:0.11866362392902374,  train_Gen:24.20710563659668, train_Disc:2.9383958462858573e-05, train_reg:3.205289363861084, train_t_reg:3.6625354290008545, train_t_mse:116.96401977539062, train_layer_one_recon:0.0\n",
      "Iteration: 9207 epochs:99, Training: RAE:0.07868099957704544, Loss: 26.49393653869629, Ranking:39.9413948059082, Reg:3.205387592315674, Gen:23.963661193847656, Disc:3.068970545427874e-05, Recon_One:0.0, T_Reg:2.5302441120147705,T_MSE:100.1447982788086,  CI:0.9021780664883454 Validation RAE:0.08580127645484713 Loss:24.594892769198545, Ranking:47.27559618552178, Reg:3.226631251486954, Gen:21.27962492847049, Disc:0.00011714393150946924, Recon_One:0.0, T_Reg:3.3151508257122835, T_MSE:580.6223285575353, CI:0.9202745686952621, \n",
      "Iteration: 9300 epochs:100, Training: RAE:0.09603217989206314, Loss: 27.453771591186523, Ranking:48.76880645751953, Reg:3.2056305408477783, Gen:24.324432373046875, Disc:2.88251212623436e-05, Recon_One:0.0, T_Reg:3.12930965423584,T_MSE:106.063232421875,  CI:0.9069336299592139 Validation RAE:0.08445658561597395 Loss:25.010073982478232, Ranking:47.26860875917611, Reg:3.2268758101568857, Gen:21.845716235785837, Disc:7.483312115943735e-05, Recon_One:0.0, T_Reg:3.164282668839846, T_MSE:384.95575395750825, CI:0.9187701409865164, \n",
      "it:9300, trainCI:0.922994517612956, train_ranking:40.34012985229492, train_RAE:0.08103783428668976,  train_Gen:24.29693603515625, train_Disc:3.2951687899185345e-05, train_reg:3.205634355545044, train_t_reg:2.7196667194366455, train_t_mse:119.58524322509766, train_layer_one_recon:0.0\n",
      "Iteration: 9393 epochs:101, Training: RAE:0.09612290561199188, Loss: 28.150043487548828, Ranking:46.51031494140625, Reg:3.2057576179504395, Gen:24.18600082397461, Disc:3.639334317995235e-05, Recon_One:0.0, T_Reg:3.964005708694458,T_MSE:192.71728515625,  CI:0.8962651002992353 Validation RAE:0.08321409492779183 Loss:25.909966660452227, Ranking:47.24473694465869, Reg:3.2270037294611775, Gen:22.32143739111441, Disc:4.910171229662883e-05, Recon_One:0.0, T_Reg:3.5884801322137534, T_MSE:1375.9916715537279, CI:0.921677853609791, \n",
      "it:9400, trainCI:0.8869225037257824, train_ranking:41.09809112548828, train_RAE:0.10796139389276505,  train_Gen:24.34598731994629, train_Disc:2.5994768293458037e-05, train_reg:3.205674648284912, train_t_reg:4.208606719970703, train_t_mse:161.28277587890625, train_layer_one_recon:0.0\n",
      "Iteration: 9486 epochs:102, Training: RAE:0.10178187489509583, Loss: 28.126129150390625, Ranking:43.50543975830078, Reg:3.2055089473724365, Gen:24.24321746826172, Disc:2.6642759621609002e-05, Recon_One:0.0, T_Reg:3.8828859329223633,T_MSE:155.25051879882812,  CI:0.8748759848263787 Validation RAE:0.08164168543609601 Loss:25.82527024456452, Ranking:47.23242463596883, Reg:3.226753410822573, Gen:22.31392146677349, Disc:5.1954694296397214e-05, Recon_One:0.0, T_Reg:3.5112970215507757, T_MSE:1022.3774608379754, CI:0.9209609800544749, \n",
      "it:9500, trainCI:0.8827918981091848, train_ranking:46.01052474975586, train_RAE:0.09880637377500534,  train_Gen:24.394397735595703, train_Disc:2.8383086828398518e-05, train_reg:3.2054336071014404, train_t_reg:3.8317649364471436, train_t_mse:101.78768157958984, train_layer_one_recon:0.0\n",
      "Iteration: 9579 epochs:103, Training: RAE:0.08723655343055725, Loss: 26.776050567626953, Ranking:43.42338943481445, Reg:3.206026315689087, Gen:24.034374237060547, Disc:4.403775164973922e-05, Recon_One:0.0, T_Reg:2.7416329383850098,T_MSE:134.60450744628906,  CI:0.9141822069129351 Validation RAE:0.08447290927719531 Loss:25.6590690197789, Ranking:47.25757065573021, Reg:3.22727420799014, Gen:22.61079609565501, Disc:4.2039789299393736e-05, Recon_One:0.0, T_Reg:3.0482309660912157, T_MSE:283.986569082974, CI:0.9198190888056567, *\n",
      "it:9600, trainCI:0.9068100358422939, train_ranking:47.897891998291016, train_RAE:0.0935884416103363,  train_Gen:24.769912719726562, train_Disc:2.6830321075976826e-05, train_reg:3.2058475017547607, train_t_reg:2.8561463356018066, train_t_mse:98.22698211669922, train_layer_one_recon:0.0\n",
      "Iteration: 9672 epochs:104, Training: RAE:0.11237910389900208, Loss: 27.77524185180664, Ranking:49.606346130371094, Reg:3.205913782119751, Gen:24.533042907714844, Disc:2.516966560506262e-05, Recon_One:0.0, T_Reg:3.2421743869781494,T_MSE:143.69390869140625,  CI:0.9016775396085741 Validation RAE:0.08523424187570539 Loss:25.579680790674004, Ranking:47.2764125984729, Reg:3.2271609286062266, Gen:22.487798642855786, Disc:4.8107598148663614e-05, Recon_One:0.0, T_Reg:3.0918340019931105, T_MSE:350.2679794538583, CI:0.9194357944608207, \n",
      "it:9700, trainCI:0.9061124061124061, train_ranking:39.54192352294922, train_RAE:0.08376507461071014,  train_Gen:24.409183502197266, train_Disc:2.7508565835887566e-05, train_reg:3.20589017868042, train_t_reg:3.065825939178467, train_t_mse:112.6984634399414, train_layer_one_recon:0.0\n",
      "Iteration: 9765 epochs:105, Training: RAE:0.10260668396949768, Loss: 27.407501220703125, Ranking:43.20789337158203, Reg:3.2061116695404053, Gen:24.60917091369629, Disc:2.4964549083961174e-05, Recon_One:0.0, T_Reg:2.798305034637451,T_MSE:100.41163635253906,  CI:0.9254112476987945 Validation RAE:0.08644511632279364 Loss:25.521790183781533, Ranking:47.26778166106571, Reg:3.227360127522854, Gen:22.40389092528732, Disc:5.390233310732211e-05, Recon_One:0.0, T_Reg:3.117845164875366, T_MSE:442.904770939264, CI:0.9201224133988826, \n",
      "it:9800, trainCI:0.8958661860779454, train_ranking:45.69033432006836, train_RAE:0.10780061036348343,  train_Gen:24.832069396972656, train_Disc:2.022250191657804e-05, train_reg:3.2059874534606934, train_t_reg:3.2567031383514404, train_t_mse:124.930908203125, train_layer_one_recon:0.0\n",
      "Iteration: 9858 epochs:106, Training: RAE:0.10693781077861786, Loss: 27.789003372192383, Ranking:48.58909606933594, Reg:3.2063379287719727, Gen:24.72890853881836, Disc:2.1777577785542235e-05, Recon_One:0.0, T_Reg:3.0600738525390625,T_MSE:110.65889739990234,  CI:0.895749417002332 Validation RAE:0.08524037244018949 Loss:25.775375225491207, Ranking:47.28182446469184, Reg:3.227587886284154, Gen:22.345640862958497, Disc:5.896746090761383e-05, Recon_One:0.0, T_Reg:3.4296754272010634, T_MSE:920.3920989509402, CI:0.9194675021300185, \n",
      "it:9900, trainCI:0.8759003683950074, train_ranking:46.706031799316406, train_RAE:0.11303672939538956,  train_Gen:24.885944366455078, train_Disc:2.1045696485089138e-05, train_reg:3.2060532569885254, train_t_reg:3.5228819847106934, train_t_mse:113.80570220947266, train_layer_one_recon:0.0\n",
      "Iteration: 9951 epochs:107, Training: RAE:0.12567663192749023, Loss: 28.504369735717773, Ranking:54.25111389160156, Reg:3.206155776977539, Gen:24.773670196533203, Disc:2.6427838747622445e-05, Recon_One:0.0, T_Reg:3.730673313140869,T_MSE:123.12657928466797,  CI:0.8889259824494468 Validation RAE:0.08722857184446318 Loss:25.682499320175822, Ranking:47.3123282570533, Reg:3.2274045272813794, Gen:22.47873028174063, Disc:5.4041006881826645e-05, Recon_One:0.0, T_Reg:3.203714965685794, T_MSE:404.1178975326502, CI:0.919617737322044, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:10000, trainCI:0.9053476553476554, train_ranking:44.612937927246094, train_RAE:0.09947925060987473,  train_Gen:25.11654281616211, train_Disc:1.972977952391375e-05, train_reg:3.2064499855041504, train_t_reg:3.196441173553467, train_t_mse:138.0648956298828, train_layer_one_recon:0.0\n",
      "Iteration: 10044 epochs:108, Training: RAE:0.11601937562227249, Loss: 29.19007110595703, Ranking:57.52189254760742, Reg:3.20645809173584, Gen:25.310012817382812, Disc:2.3871716621215455e-05, Recon_One:0.0, T_Reg:3.880033493041992,T_MSE:140.22756958007812,  CI:0.874881473788775 Validation RAE:0.08521487567668351 Loss:25.45876443959988, Ranking:47.288865984656354, Reg:3.2277088456262986, Gen:22.358034729465658, Disc:6.345349263016369e-05, Recon_One:0.0, T_Reg:3.1006664443913436, T_MSE:345.3949047115813, CI:0.9202880094257404, \n",
      "it:10100, trainCI:0.9032289249806651, train_ranking:53.30683135986328, train_RAE:0.11455203592777252,  train_Gen:25.23097801208496, train_Disc:2.096160824294202e-05, train_reg:3.2063915729522705, train_t_reg:3.0216217041015625, train_t_mse:118.69642639160156, train_layer_one_recon:0.0\n",
      "Iteration: 10137 epochs:109, Training: RAE:0.11812961846590042, Loss: 28.180225372314453, Ranking:49.4205207824707, Reg:3.2066173553466797, Gen:25.029766082763672, Disc:1.917922418215312e-05, Recon_One:0.0, T_Reg:3.150439739227295,T_MSE:98.03410339355469,  CI:0.9021140429103499 Validation RAE:0.0827276434973432 Loss:25.581530324962863, Ranking:47.25927811079179, Reg:3.227869164754379, Gen:22.541643330883023, Disc:5.8879010938594184e-05, Recon_One:0.0, T_Reg:3.039828069182922, T_MSE:319.7990417480469, CI:0.9206144790606393, *\n",
      "it:10200, trainCI:0.9021700642419951, train_ranking:50.85959243774414, train_RAE:0.09331203252077103,  train_Gen:25.354442596435547, train_Disc:2.0268375010346062e-05, train_reg:3.2067136764526367, train_t_reg:2.558593511581421, train_t_mse:110.5403060913086, train_layer_one_recon:0.0\n",
      "Iteration: 10230 epochs:110, Training: RAE:0.09422167390584946, Loss: 28.85719871520996, Ranking:46.254703521728516, Reg:3.2070298194885254, Gen:25.396814346313477, Disc:1.5479025023523718e-05, Recon_One:0.0, T_Reg:3.4603688716888428,T_MSE:140.78765869140625,  CI:0.8938199459727658 Validation RAE:0.08047310423725051 Loss:25.960103681687638, Ranking:47.21087200188169, Reg:3.228284362496265, Gen:22.911953887328874, Disc:4.2421396535277276e-05, Recon_One:0.0, T_Reg:3.0481075128495907, T_MSE:343.64637222471305, CI:0.9214995433784268, \n",
      "it:10300, trainCI:0.8731326392032593, train_ranking:45.15707778930664, train_RAE:0.11856026947498322,  train_Gen:25.39667510986328, train_Disc:2.2039059331291355e-05, train_reg:3.2070794105529785, train_t_reg:3.7854268550872803, train_t_mse:106.70687866210938, train_layer_one_recon:0.0\n",
      "Iteration: 10323 epochs:111, Training: RAE:0.07830296456813812, Loss: 27.860843658447266, Ranking:41.85990524291992, Reg:3.2070021629333496, Gen:25.151477813720703, Disc:2.206069984822534e-05, Recon_One:0.0, T_Reg:2.709343910217285,T_MSE:120.36096954345703,  CI:0.9345536916860536 Validation RAE:0.08372181102519813 Loss:26.13071261815344, Ranking:47.25991738383675, Reg:3.228256522647676, Gen:23.02420649421771, Disc:3.996952016865932e-05, Recon_One:0.0, T_Reg:3.1064661067620625, T_MSE:442.99787440508084, CI:0.9193220931462343, \n",
      "it:10400, trainCI:0.8524054180289584, train_ranking:49.7919921875, train_RAE:0.12365709245204926,  train_Gen:24.980384826660156, train_Disc:2.434900488879066e-05, train_reg:3.206798791885376, train_t_reg:3.9066014289855957, train_t_mse:133.47186279296875, train_layer_one_recon:0.0\n",
      "Iteration: 10416 epochs:112, Training: RAE:0.10211862623691559, Loss: 28.735729217529297, Ranking:50.74724197387695, Reg:3.206822395324707, Gen:25.57130241394043, Disc:1.544060251035262e-05, Recon_One:0.0, T_Reg:3.164410352706909,T_MSE:103.92913818359375,  CI:0.8720113228529546 Validation RAE:0.08040226043776243 Loss:26.755409603254847, Ranking:47.22539313334114, Reg:3.2280755636318483, Gen:23.59403460207948, Disc:2.5480033250290084e-05, Recon_One:0.0, T_Reg:3.1613494882706448, T_MSE:634.4257040859774, CI:0.9212474907609249, \n",
      "it:10500, trainCI:0.8917479538064805, train_ranking:45.764713287353516, train_RAE:0.10684319585561752,  train_Gen:25.49530029296875, train_Disc:1.924539901665412e-05, train_reg:3.207146167755127, train_t_reg:3.5398402214050293, train_t_mse:135.4021453857422, train_layer_one_recon:0.0\n",
      "Iteration: 10509 epochs:113, Training: RAE:0.10796216875314713, Loss: 30.129873275756836, Ranking:52.41779708862305, Reg:3.2071328163146973, Gen:25.651378631591797, Disc:1.5924910258036107e-05, Recon_One:0.0, T_Reg:4.478478908538818,T_MSE:247.2744140625,  CI:0.8872680992706447 Validation RAE:0.08403916087533081 Loss:26.839138845272238, Ranking:47.27305094719053, Reg:3.228388041932389, Gen:23.55002359970072, Disc:2.734675246267032e-05, Recon_One:0.0, T_Reg:3.2890875726785453, T_MSE:832.6907311139352, CI:0.9209521060586765, \n",
      "it:10600, trainCI:0.8910059301559411, train_ranking:46.692893981933594, train_RAE:0.10687721520662308,  train_Gen:25.799068450927734, train_Disc:1.2688495189649984e-05, train_reg:3.2073233127593994, train_t_reg:3.1936230659484863, train_t_mse:69.78996276855469, train_layer_one_recon:0.0\n",
      "Iteration: 10602 epochs:114, Training: RAE:0.09412605315446854, Loss: 29.219051361083984, Ranking:44.525115966796875, Reg:3.2073073387145996, Gen:25.729061126708984, Disc:1.4244673366192728e-05, Recon_One:0.0, T_Reg:3.489975690841675,T_MSE:117.54761505126953,  CI:0.8781188915718063 Validation RAE:0.08385002625179362 Loss:26.577650458719994, Ranking:47.26295297080552, Reg:3.2285637209769322, Gen:23.264444352865844, Disc:3.741120150984983e-05, Recon_One:0.0, T_Reg:3.3131686556230444, T_MSE:710.870995902562, CI:0.9196119251142696, \n",
      "Iteration: 10695 epochs:115, Training: RAE:0.08975428342819214, Loss: 29.0155029296875, Ranking:50.0051383972168, Reg:3.2078189849853516, Gen:26.271831512451172, Disc:1.411382618243806e-05, Recon_One:0.0, T_Reg:2.7436580657958984,T_MSE:107.85328674316406,  CI:0.9127600124185036 Validation RAE:0.0813051241143608 Loss:26.269471098277453, Ranking:47.26785278415716, Reg:3.229078758175826, Gen:23.191075708413848, Disc:4.2585418496904956e-05, Recon_One:0.0, T_Reg:3.0783526909653958, T_MSE:463.2108346095484, CI:0.9208345126406697, \n",
      "it:10700, trainCI:0.894991531575127, train_ranking:42.44363021850586, train_RAE:0.09639066457748413,  train_Gen:25.746139526367188, train_Disc:1.6278030670946464e-05, train_reg:3.2077958583831787, train_t_reg:3.1718027591705322, train_t_mse:105.46981811523438, train_layer_one_recon:0.0\n",
      "Iteration: 10788 epochs:116, Training: RAE:0.10029871016740799, Loss: 28.85517692565918, Ranking:50.93655014038086, Reg:3.208211898803711, Gen:25.785579681396484, Disc:1.3680879419553094e-05, Recon_One:0.0, T_Reg:3.069584369659424,T_MSE:69.35723114013672,  CI:0.8931247799627823 Validation RAE:0.08388845245585048 Loss:27.170742161798376, Ranking:47.29894776634683, Reg:3.2294742760247432, Gen:23.75156264968763, Disc:2.7967708531627787e-05, Recon_One:0.0, T_Reg:3.419151359220378, T_MSE:1107.2051061754512, CI:0.9200020695611254, \n",
      "it:10800, trainCI:0.8878951426368543, train_ranking:50.4595832824707, train_RAE:0.11301220208406448,  train_Gen:26.006994247436523, train_Disc:1.5304472981370054e-05, train_reg:3.208251953125, train_t_reg:4.3046979904174805, train_t_mse:158.07028198242188, train_layer_one_recon:0.0\n",
      "Iteration: 10881 epochs:117, Training: RAE:0.09488794952630997, Loss: 29.188526153564453, Ranking:44.743839263916016, Reg:3.2085461616516113, Gen:25.90103530883789, Disc:1.2531067113741301e-05, Recon_One:0.0, T_Reg:3.2874786853790283,T_MSE:95.44734191894531,  CI:0.8845667662606297 Validation RAE:0.0813181709455776 Loss:26.439488928392855, Ranking:47.27200330071439, Reg:3.229810754194757, Gen:23.377384816883236, Disc:4.0385234991207415e-05, Recon_One:0.0, T_Reg:3.062063718685824, T_MSE:431.36454214077224, CI:0.9194853539110398, \n",
      "it:10900, trainCI:0.8792042440318303, train_ranking:48.239261627197266, train_RAE:0.10421694070100784,  train_Gen:25.941944122314453, train_Disc:1.659011650190223e-05, train_reg:3.2086260318756104, train_t_reg:4.027324199676514, train_t_mse:178.32901000976562, train_layer_one_recon:0.0\n",
      "Iteration: 10974 epochs:118, Training: RAE:0.08025182783603668, Loss: 29.38889503479004, Ranking:42.822967529296875, Reg:3.2093567848205566, Gen:26.299283981323242, Disc:1.3037660210102331e-05, Recon_One:0.0, T_Reg:3.089597702026367,T_MSE:105.4469223022461,  CI:0.9032993401319737 Validation RAE:0.0840206578237885 Loss:26.561251660950767, Ranking:47.28516992127968, Reg:3.2306267497568437, Gen:23.333176389491243, Disc:4.600741484213683e-05, Recon_One:0.0, T_Reg:3.228029170840684, T_MSE:712.0573744798312, CI:0.9200637204793037, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:11000, trainCI:0.8940529150081948, train_ranking:43.66576385498047, train_RAE:0.08211562782526016,  train_Gen:25.951976776123047, train_Disc:1.3721693903789856e-05, train_reg:3.209515333175659, train_t_reg:2.7468481063842773, train_t_mse:87.78201293945312, train_layer_one_recon:0.0\n",
      "Iteration: 11067 epochs:119, Training: RAE:0.10183882713317871, Loss: 30.2723445892334, Ranking:53.24363327026367, Reg:3.2095751762390137, Gen:26.295894622802734, Disc:1.1138963600387797e-05, Recon_One:0.0, T_Reg:3.9764389991760254,T_MSE:154.41954040527344,  CI:0.8825764958097837 Validation RAE:0.08004814937451757 Loss:27.2885884495695, Ranking:47.25983991643198, Reg:3.230846588561218, Gen:23.936370994145236, Disc:2.6378792002287765e-05, Recon_One:0.0, T_Reg:3.352190951220584, T_MSE:1105.2148623631658, CI:0.9214072226852961, \n",
      "it:11100, trainCI:0.8536648269458916, train_ranking:49.65147018432617, train_RAE:0.12072711437940598,  train_Gen:26.123512268066406, train_Disc:1.4414261386264116e-05, train_reg:3.2097973823547363, train_t_reg:4.115177631378174, train_t_mse:175.13430786132812, train_layer_one_recon:0.0\n",
      "Iteration: 11160 epochs:120, Training: RAE:0.09822869300842285, Loss: 29.181446075439453, Ranking:40.755271911621094, Reg:3.209796905517578, Gen:26.2589111328125, Disc:1.455141682527028e-05, Recon_One:0.0, T_Reg:2.9225196838378906,T_MSE:113.46637725830078,  CI:0.9133265899608042 Validation RAE:0.08127058484568601 Loss:26.950546740233428, Ranking:47.25877106659291, Reg:3.231069787347318, Gen:23.77665432539674, Disc:3.1447859733172646e-05, Recon_One:0.0, T_Reg:3.173860901964595, T_MSE:747.0727729964319, CI:0.9214130348930705, \n",
      "it:11200, trainCI:0.8829014358446313, train_ranking:44.68635177612305, train_RAE:0.09613825380802155,  train_Gen:26.219697952270508, train_Disc:1.1745669326046482e-05, train_reg:3.2099742889404297, train_t_reg:2.951324939727783, train_t_mse:106.8889389038086, train_layer_one_recon:0.0\n",
      "Iteration: 11253 epochs:121, Training: RAE:0.09341876208782196, Loss: 29.805599212646484, Ranking:37.08720779418945, Reg:3.2101082801818848, Gen:26.550308227539062, Disc:1.0790826308948454e-05, Recon_One:0.0, T_Reg:3.2552804946899414,T_MSE:80.7123031616211,  CI:0.9100069013112492 Validation RAE:0.08388516046288491 Loss:27.395760346699227, Ranking:47.31711637709936, Reg:3.2313832256426376, Gen:24.2258764526703, Disc:2.2336560940111046e-05, Recon_One:0.0, T_Reg:3.169861730671203, T_MSE:448.1760658740222, CI:0.9198990585572668, \n",
      "it:11300, trainCI:0.886009046094425, train_ranking:50.64731979370117, train_RAE:0.10881923884153366,  train_Gen:26.703420639038086, train_Disc:9.263364518119488e-06, train_reg:3.2104220390319824, train_t_reg:3.8541085720062256, train_t_mse:168.3711700439453, train_layer_one_recon:0.0\n",
      "Iteration: 11346 epochs:122, Training: RAE:0.0937962532043457, Loss: 29.864925384521484, Ranking:39.983070373535156, Reg:3.2107326984405518, Gen:26.71778106689453, Disc:9.330389730166644e-06, Recon_One:0.0, T_Reg:3.1471357345581055,T_MSE:118.89730072021484,  CI:0.875803679419441 Validation RAE:0.08024692601083264 Loss:27.460044184908117, Ranking:47.271379888452735, Reg:3.232011782224139, Gen:24.296899120316024, Disc:2.2536750334112858e-05, Recon_One:0.0, T_Reg:3.1631225725405065, T_MSE:663.8923037301097, CI:0.9189934439334199, \n",
      "it:11400, trainCI:0.9236802724598793, train_ranking:49.4415397644043, train_RAE:0.07888055592775345,  train_Gen:26.64297103881836, train_Disc:8.811882253212389e-06, train_reg:3.210878610610962, train_t_reg:2.180387258529663, train_t_mse:81.52147674560547, train_layer_one_recon:0.0\n",
      "Iteration: 11439 epochs:123, Training: RAE:0.11756188422441483, Loss: 31.079465866088867, Ranking:49.1700439453125, Reg:3.211108684539795, Gen:26.551219940185547, Disc:1.7553289580973797e-05, Recon_One:0.0, T_Reg:4.528228759765625,T_MSE:252.48622131347656,  CI:0.8930067001675042 Validation RAE:0.08028406368928864 Loss:27.222489219494754, Ranking:47.246466270905664, Reg:3.232390260165731, Gen:24.169067217287935, Disc:2.5069065610228764e-05, Recon_One:0.0, T_Reg:3.05339690147377, T_MSE:376.73294054980397, CI:0.9203803820135833, \n",
      "it:11500, trainCI:0.9063689858082381, train_ranking:44.30787658691406, train_RAE:0.08587430417537689,  train_Gen:26.690963745117188, train_Disc:1.0326033589080907e-05, train_reg:3.2111806869506836, train_t_reg:2.6413307189941406, train_t_mse:79.44243621826172, train_layer_one_recon:0.0\n",
      "Iteration: 11532 epochs:124, Training: RAE:0.0786418467760086, Loss: 29.667150497436523, Ranking:44.95467758178711, Reg:3.2113711833953857, Gen:27.013025283813477, Disc:7.533354164479533e-06, Recon_One:0.0, T_Reg:2.654118299484253,T_MSE:102.9068832397461,  CI:0.9110003963086678 Validation RAE:0.08016135392188131 Loss:26.997032943063488, Ranking:47.27108988655169, Reg:3.23265449872863, Gen:24.087434687345525, Disc:3.060599018752695e-05, Recon_One:0.0, T_Reg:2.9095677393621933, T_MSE:285.2702527310351, CI:0.9201922636815998, *\n",
      "it:11600, trainCI:0.8968462182528607, train_ranking:46.27878952026367, train_RAE:0.1041463166475296,  train_Gen:26.982418060302734, train_Disc:7.839405952836387e-06, train_reg:3.211534023284912, train_t_reg:3.220519542694092, train_t_mse:105.8122329711914, train_layer_one_recon:0.0\n",
      "Iteration: 11625 epochs:125, Training: RAE:0.08846893906593323, Loss: 30.28931999206543, Ranking:43.15420913696289, Reg:3.211637496948242, Gen:27.015968322753906, Disc:8.463620360998902e-06, Recon_One:0.0, T_Reg:3.273343086242676,T_MSE:101.94509887695312,  CI:0.893037336024218 Validation RAE:0.08061819111121749 Loss:28.249927638574913, Ranking:47.27871241205198, Reg:3.2329225772706454, Gen:24.949544642110816, Disc:1.4156385211713616e-05, Recon_One:0.0, T_Reg:3.300369024366174, T_MSE:810.2282577176921, CI:0.9197812056656987, \n",
      "it:11700, trainCI:0.9086755862197566, train_ranking:55.537818908691406, train_RAE:0.11498858779668808,  train_Gen:27.350555419921875, train_Disc:6.184575795487035e-06, train_reg:3.212066888809204, train_t_reg:3.024219512939453, train_t_mse:145.17001342773438, train_layer_one_recon:0.0\n",
      "Iteration: 11718 epochs:126, Training: RAE:0.08435129374265671, Loss: 29.95397186279297, Ranking:44.3171272277832, Reg:3.212348699569702, Gen:27.25366973876953, Disc:1.0755748917290475e-05, Recon_One:0.0, T_Reg:2.700291156768799,T_MSE:80.89696502685547,  CI:0.9145527369826435 Validation RAE:0.08053289537945882 Loss:28.719977645616435, Ranking:47.26582861429634, Reg:3.233638493377029, Gen:25.83719496579711, Disc:7.334977064797004e-06, Recon_One:0.0, T_Reg:2.8827755633362893, T_MSE:230.95404097955495, CI:0.9209226298621064, *\n",
      "it:11800, trainCI:0.9112152413835625, train_ranking:41.43132781982422, train_RAE:0.09138523787260056,  train_Gen:27.05598258972168, train_Disc:9.71225290413713e-06, train_reg:3.2126107215881348, train_t_reg:3.0503084659576416, train_t_mse:86.0718994140625, train_layer_one_recon:0.0\n",
      "Iteration: 11811 epochs:127, Training: RAE:0.09139258414506912, Loss: 30.254291534423828, Ranking:47.68354415893555, Reg:3.212540626525879, Gen:27.019847869873047, Disc:9.100487659452483e-06, Recon_One:0.0, T_Reg:3.2344346046447754,T_MSE:102.08869934082031,  CI:0.8917105121872652 Validation RAE:0.0808255534073599 Loss:27.77146599032483, Ranking:47.280370448251894, Reg:3.233831692326288, Gen:24.794290279528195, Disc:1.7978324596108913e-05, Recon_One:0.0, T_Reg:2.9771577735028893, T_MSE:281.01512479144094, CI:0.9201752941106871, \n",
      "it:11900, trainCI:0.9086351272067844, train_ranking:48.04656982421875, train_RAE:0.10353872179985046,  train_Gen:27.176307678222656, train_Disc:1.0667366950656287e-05, train_reg:3.2131574153900146, train_t_reg:2.9262185096740723, train_t_mse:98.10262298583984, train_layer_one_recon:0.0\n",
      "Iteration: 11904 epochs:128, Training: RAE:0.09738533943891525, Loss: 30.25259017944336, Ranking:40.71588134765625, Reg:3.2131567001342773, Gen:27.421932220458984, Disc:7.195646503532771e-06, Recon_One:0.0, T_Reg:2.8306500911712646,T_MSE:96.0832290649414,  CI:0.9076206657856648 Validation RAE:0.08193012310651536 Loss:27.816481481153577, Ranking:47.290034006129986, Reg:3.234451848953474, Gen:24.80894121897732, Disc:1.8957261055093407e-05, Recon_One:0.0, T_Reg:3.0075213544530035, T_MSE:276.52251885297136, CI:0.9209846959379829, \n",
      "Iteration: 11997 epochs:129, Training: RAE:0.0832487940788269, Loss: 30.03455924987793, Ranking:43.668697357177734, Reg:3.213550090789795, Gen:27.470565795898438, Disc:8.757984687690623e-06, Recon_One:0.0, T_Reg:2.5639848709106445,T_MSE:89.5893325805664,  CI:0.9148785663758547 Validation RAE:0.0807764969893779 Loss:27.989211087824927, Ranking:47.28932377694919, Reg:3.234847846799781, Gen:25.077355508731575, Disc:1.564916190164097e-05, Recon_One:0.0, T_Reg:2.9118401878727096, T_MSE:274.10852132446394, CI:0.9204651260787224, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:12000, trainCI:0.8746662307231213, train_ranking:46.92802810668945, train_RAE:0.09787090867757797,  train_Gen:27.329090118408203, train_Disc:7.871092748246156e-06, train_reg:3.213502883911133, train_t_reg:3.1320712566375732, train_t_mse:97.37147521972656, train_layer_one_recon:0.0\n",
      "Iteration: 12090 epochs:130, Training: RAE:0.08870910853147507, Loss: 30.435340881347656, Ranking:43.27526092529297, Reg:3.2141318321228027, Gen:27.620338439941406, Disc:7.1942304202821106e-06, Recon_One:0.0, T_Reg:2.814995050430298,T_MSE:128.8902587890625,  CI:0.9089575017609768 Validation RAE:0.08082315977907366 Loss:28.449752722231317, Ranking:47.29340367128182, Reg:3.2354334436149257, Gen:25.320298883100143, Disc:1.2757725016967967e-05, Recon_One:0.0, T_Reg:3.129441254851787, T_MSE:565.9453126450129, CI:0.9185993554884315, \n",
      "it:12100, trainCI:0.8579288865818843, train_ranking:49.457698822021484, train_RAE:0.11030017584562302,  train_Gen:27.67802619934082, train_Disc:5.9278609114699066e-06, train_reg:3.2140378952026367, train_t_reg:3.844029664993286, train_t_mse:103.3292007446289, train_layer_one_recon:0.0\n",
      "Iteration: 12183 epochs:131, Training: RAE:0.0927257314324379, Loss: 31.85350227355957, Ranking:40.96307373046875, Reg:3.214637517929077, Gen:27.779766082763672, Disc:5.753048299084185e-06, Recon_One:0.0, T_Reg:4.073729991912842,T_MSE:153.2517852783203,  CI:0.8383788151923913 Validation RAE:0.07933555134791381 Loss:27.769967480213833, Ranking:47.26334281216357, Reg:3.235942480846451, Gen:24.78643117792326, Disc:2.2388055888691126e-05, Recon_One:0.0, T_Reg:2.9835139093688836, T_MSE:357.9094594249699, CI:0.9202320150311997, \n",
      "it:12200, trainCI:0.913188847095349, train_ranking:42.82884979248047, train_RAE:0.10093444585800171,  train_Gen:27.985984802246094, train_Disc:5.417847205535509e-06, train_reg:3.214570999145508, train_t_reg:3.166536808013916, train_t_mse:107.0507583618164, train_layer_one_recon:0.0\n",
      "Iteration: 12276 epochs:132, Training: RAE:0.08759649097919464, Loss: 31.031925201416016, Ranking:38.950050354003906, Reg:3.2150583267211914, Gen:28.015697479248047, Disc:5.463625711854547e-06, Recon_One:0.0, T_Reg:3.0162227153778076,T_MSE:80.55181884765625,  CI:0.8775176562908711 Validation RAE:0.08310444063285864 Loss:28.106246639135794, Ranking:47.31369195050622, Reg:3.2363660785426522, Gen:25.046687599001817, Disc:1.9008346804981856e-05, Recon_One:0.0, T_Reg:3.059540111541271, T_MSE:348.3082664807439, CI:0.9198884201412512, \n",
      "it:12300, trainCI:0.9028808004140072, train_ranking:44.77408218383789, train_RAE:0.08639239519834518,  train_Gen:27.362136840820312, train_Disc:6.306890099949669e-06, train_reg:3.2153258323669434, train_t_reg:3.043867588043213, train_t_mse:122.92781829833984, train_layer_one_recon:0.0\n",
      "Iteration: 12369 epochs:133, Training: RAE:0.10998845845460892, Loss: 30.652956008911133, Ranking:50.043479919433594, Reg:3.215362310409546, Gen:27.673316955566406, Disc:5.258891178527847e-06, Recon_One:0.0, T_Reg:2.9796342849731445,T_MSE:97.3424301147461,  CI:0.885009429634538 Validation RAE:0.08074177918906537 Loss:28.373840091615165, Ranking:47.28047396073241, Reg:3.236672076878435, Gen:25.24395049833217, Disc:1.588359159324487e-05, Recon_One:0.0, T_Reg:3.1298738107601376, T_MSE:491.97436646698446, CI:0.9198427527944524, \n",
      "it:12400, trainCI:0.8962999751676186, train_ranking:51.72578430175781, train_RAE:0.1086060032248497,  train_Gen:28.045162200927734, train_Disc:5.974340183456661e-06, train_reg:3.215568780899048, train_t_reg:3.583534002304077, train_t_mse:200.27197265625, train_layer_one_recon:0.0\n",
      "Iteration: 12462 epochs:134, Training: RAE:0.09085647761821747, Loss: 31.2446231842041, Ranking:46.574363708496094, Reg:3.2159078121185303, Gen:28.28762435913086, Disc:4.892803190159611e-06, Recon_One:0.0, T_Reg:2.9569931030273438,T_MSE:113.98220825195312,  CI:0.9171130377160528 Validation RAE:0.0830207960334244 Loss:28.932546117357333, Ranking:47.28951327157077, Reg:3.2372211938919806, Gen:25.583188945507427, Disc:1.2341875692242929e-05, Recon_One:0.0, T_Reg:3.3493447545261343, T_MSE:999.7018485661371, CI:0.9195192930528653, \n",
      "it:12500, trainCI:0.8959724540901502, train_ranking:49.271514892578125, train_RAE:0.09156718850135803,  train_Gen:27.865217208862305, train_Disc:5.255805263004731e-06, train_reg:3.2163946628570557, train_t_reg:2.785569190979004, train_t_mse:103.11434936523438, train_layer_one_recon:0.0\n",
      "Iteration: 12555 epochs:135, Training: RAE:0.0853801742196083, Loss: 31.540870666503906, Ranking:42.87898635864258, Reg:3.2163453102111816, Gen:28.47539520263672, Disc:3.847004336421378e-06, Recon_One:0.0, T_Reg:3.0654706954956055,T_MSE:110.32877349853516,  CI:0.9055001187930625 Validation RAE:0.083791808307551 Loss:28.997671662292824, Ranking:47.300448530358615, Reg:3.237661591496813, Gen:25.65018606287279, Disc:1.2379985584437391e-05, Recon_One:0.0, T_Reg:3.3474731612268114, T_MSE:833.8623705157135, CI:0.9197462286296277, \n",
      "it:12600, trainCI:0.9207863544376987, train_ranking:44.077674865722656, train_RAE:0.08087494224309921,  train_Gen:27.784788131713867, train_Disc:7.965612894622609e-06, train_reg:3.2162811756134033, train_t_reg:2.6372499465942383, train_t_mse:149.0355224609375, train_layer_one_recon:0.0\n",
      "Iteration: 12648 epochs:136, Training: RAE:0.09590553492307663, Loss: 31.45078468322754, Ranking:46.5319709777832, Reg:3.216529130935669, Gen:28.31155776977539, Disc:5.115974090585951e-06, Recon_One:0.0, T_Reg:3.1392219066619873,T_MSE:102.18496704101562,  CI:0.8909190974133187 Validation RAE:0.08137551416631668 Loss:28.169061518377312, Ranking:47.30311731584403, Reg:3.2378466304904507, Gen:25.208656415501668, Disc:1.827751865822334e-05, Recon_One:0.0, T_Reg:2.9603869986262814, T_MSE:287.48414193568743, CI:0.9201784077934233, \n",
      "it:12700, trainCI:0.8945256225560815, train_ranking:49.79299545288086, train_RAE:0.10557568073272705,  train_Gen:28.15717887878418, train_Disc:5.432480975287035e-06, train_reg:3.216766357421875, train_t_reg:3.7257208824157715, train_t_mse:179.32273864746094, train_layer_one_recon:0.0\n",
      "Iteration: 12741 epochs:137, Training: RAE:0.09696605056524277, Loss: 31.159513473510742, Ranking:48.236351013183594, Reg:3.216787099838257, Gen:28.31137466430664, Disc:6.193482477101497e-06, Recon_One:0.0, T_Reg:2.8481318950653076,T_MSE:80.99803161621094,  CI:0.902970297029703 Validation RAE:0.08107326760360774 Loss:28.900311245714946, Ranking:47.29276940690527, Reg:3.2381063090781503, Gen:25.97084176589567, Disc:9.808484597738041e-06, Recon_One:0.0, T_Reg:2.9294599529145673, T_MSE:285.678970424685, CI:0.9203672526513786, \n",
      "it:12800, trainCI:0.9080894335440975, train_ranking:39.183345794677734, train_RAE:0.0922970175743103,  train_Gen:28.551990509033203, train_Disc:5.323521691025235e-06, train_reg:3.2172815799713135, train_t_reg:3.2968077659606934, train_t_mse:153.3034210205078, train_layer_one_recon:0.0\n",
      "Iteration: 12834 epochs:138, Training: RAE:0.09689096361398697, Loss: 31.706209182739258, Ranking:46.566131591796875, Reg:3.217647075653076, Gen:28.915687561035156, Disc:3.375169399078004e-06, Recon_One:0.0, T_Reg:2.790518283843994,T_MSE:93.35608673095703,  CI:0.934013529998891 Validation RAE:0.08456439964917654 Loss:28.896210148019374, Ranking:47.30968484882118, Reg:3.2389719843700466, Gen:25.821447294921416, Disc:1.171774268106985e-05, Recon_One:0.0, T_Reg:3.074751427073143, T_MSE:296.37054547348873, CI:0.921866075731199, \n",
      "it:12900, trainCI:0.896963997850618, train_ranking:57.82330322265625, train_RAE:0.11590517312288284,  train_Gen:28.709991455078125, train_Disc:4.748834726342466e-06, train_reg:3.2185769081115723, train_t_reg:3.394125461578369, train_t_mse:132.9241943359375, train_layer_one_recon:0.0\n",
      "Iteration: 12927 epochs:139, Training: RAE:0.0994783267378807, Loss: 31.683856964111328, Ranking:50.327396392822266, Reg:3.2187318801879883, Gen:28.65625, Disc:4.618281309376471e-06, Recon_One:0.0, T_Reg:3.027601718902588,T_MSE:70.67442321777344,  CI:0.9245273298645098 Validation RAE:0.08083513868131592 Loss:28.6556117487234, Ranking:47.2815600069997, Reg:3.240063978431075, Gen:25.717312654316597, Disc:1.4226875617339893e-05, Recon_One:0.0, T_Reg:2.9382849344838124, T_MSE:288.28955818835504, CI:0.9214166675229294, \n",
      "it:13000, trainCI:0.8840737317166005, train_ranking:47.41419982910156, train_RAE:0.09852536767721176,  train_Gen:28.562820434570312, train_Disc:4.6359418774954975e-06, train_reg:3.218851089477539, train_t_reg:3.5373077392578125, train_t_mse:96.80033111572266, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13020 epochs:140, Training: RAE:0.11251915991306305, Loss: 33.04920196533203, Ranking:48.43062210083008, Reg:3.21884822845459, Gen:28.938814163208008, Disc:5.118493390909862e-06, Recon_One:0.0, T_Reg:4.110381126403809,T_MSE:203.30653381347656,  CI:0.8620015843675732 Validation RAE:0.07951456233085774 Loss:29.343537162121525, Ranking:47.26458813408635, Reg:3.2401810977941037, Gen:26.510842919454017, Disc:6.760081642495597e-06, Recon_One:0.0, T_Reg:2.832687282705361, T_MSE:223.9961006648245, CI:0.9215868302844671, *\n",
      "it:13100, trainCI:0.9254578433093441, train_ranking:44.02105712890625, train_RAE:0.08149458467960358,  train_Gen:28.535377502441406, train_Disc:4.436058134160703e-06, train_reg:3.2189571857452393, train_t_reg:2.6238317489624023, train_t_mse:79.75485229492188, train_layer_one_recon:0.0\n",
      "Iteration: 13113 epochs:141, Training: RAE:0.08286523073911667, Loss: 31.454627990722656, Ranking:46.90515899658203, Reg:3.2190046310424805, Gen:28.72909164428711, Disc:4.013894340459956e-06, Recon_One:0.0, T_Reg:2.725532054901123,T_MSE:96.12995910644531,  CI:0.9188613266309693 Validation RAE:0.07875057083376501 Loss:28.921467026308267, Ranking:47.27486642253418, Reg:3.2403385369378475, Gen:25.9940520187937, Disc:1.0892026174165677e-05, Recon_One:0.0, T_Reg:2.9274041762691265, T_MSE:305.0441360330528, CI:0.9216234679513307, \n",
      "it:13200, trainCI:0.9064373619438308, train_ranking:48.853065490722656, train_RAE:0.10048124194145203,  train_Gen:28.824922561645508, train_Disc:3.3811197681643534e-06, train_reg:3.2197022438049316, train_t_reg:3.214397430419922, train_t_mse:131.1559600830078, train_layer_one_recon:0.0\n",
      "Iteration: 13206 epochs:142, Training: RAE:0.0972764790058136, Loss: 31.97504997253418, Ranking:49.51317596435547, Reg:3.2197890281677246, Gen:28.882659912109375, Disc:3.9342098716588225e-06, Recon_One:0.0, T_Reg:3.09238600730896,T_MSE:154.50311279296875,  CI:0.9111455908973365 Validation RAE:0.07833787318697807 Loss:29.546432726469966, Ranking:47.237394069811394, Reg:3.241128132643514, Gen:26.55220249973119, Disc:7.0198814937593845e-06, Recon_One:0.0, T_Reg:2.9942233032981678, T_MSE:407.77731481993123, CI:0.9224678987094096, \n",
      "Iteration: 13299 epochs:143, Training: RAE:0.1231272965669632, Loss: 32.444114685058594, Ranking:55.3048095703125, Reg:3.2200927734375, Gen:28.796112060546875, Disc:4.44765009888215e-06, Recon_One:0.0, T_Reg:3.647996664047241,T_MSE:150.61911010742188,  CI:0.8833270958083832 Validation RAE:0.07958922703347833 Loss:29.271102717806134, Ranking:47.27425870410022, Reg:3.241433890980602, Gen:26.342293213527917, Disc:8.90329895835189e-06, Recon_One:0.0, T_Reg:2.9288007495432207, T_MSE:326.2819282290368, CI:0.9220007944042554, \n",
      "it:13300, trainCI:0.8721936459909229, train_ranking:42.78461456298828, train_RAE:0.0932706743478775,  train_Gen:29.120113372802734, train_Disc:3.561881840141723e-06, train_reg:3.220106601715088, train_t_reg:2.9984002113342285, train_t_mse:140.6516571044922, train_layer_one_recon:0.0\n",
      "Iteration: 13392 epochs:144, Training: RAE:0.09540585428476334, Loss: 32.02739715576172, Ranking:41.396820068359375, Reg:3.2211031913757324, Gen:29.230873107910156, Disc:3.7718734802183462e-06, Recon_One:0.0, T_Reg:2.7965197563171387,T_MSE:131.5096435546875,  CI:0.9238707285422975 Validation RAE:0.07808088724767773 Loss:29.33602741513831, Ranking:47.25462439001478, Reg:3.242451005448874, Gen:26.53483602722481, Disc:8.083049393734302e-06, Recon_One:0.0, T_Reg:2.8011833583919556, T_MSE:237.70363371089292, CI:0.9217349377932894, *\n",
      "it:13400, trainCI:0.9232967535436671, train_ranking:44.34701919555664, train_RAE:0.08153034001588821,  train_Gen:28.86199188232422, train_Disc:1.1725929653039202e-05, train_reg:3.221179246902466, train_t_reg:2.7048068046569824, train_t_mse:118.84823608398438, train_layer_one_recon:0.0\n",
      "Iteration: 13485 epochs:145, Training: RAE:0.08880531042814255, Loss: 31.69510841369629, Ranking:53.099342346191406, Reg:3.2220215797424316, Gen:29.228404998779297, Disc:2.4667665456945542e-06, Recon_One:0.0, T_Reg:2.466701030731201,T_MSE:102.632080078125,  CI:0.9224426444196537 Validation RAE:0.07744032420973576 Loss:29.15190534173093, Ranking:47.262410031149685, Reg:3.24337548042098, Gen:26.411423105380827, Disc:9.219329596166274e-06, Recon_One:0.0, T_Reg:2.7404733042247713, T_MSE:203.08837237113025, CI:0.9213599984971291, *\n",
      "it:13500, trainCI:0.9159240604416893, train_ranking:46.36684036254883, train_RAE:0.10876024514436722,  train_Gen:29.177410125732422, train_Disc:3.586033926694654e-06, train_reg:3.222162961959839, train_t_reg:3.369985818862915, train_t_mse:121.80703735351562, train_layer_one_recon:0.0\n",
      "Iteration: 13578 epochs:146, Training: RAE:0.08604031801223755, Loss: 32.2613525390625, Ranking:50.93578338623047, Reg:3.22236704826355, Gen:29.530305862426758, Disc:3.2708899198041763e-06, Recon_One:0.0, T_Reg:2.7310452461242676,T_MSE:120.43580627441406,  CI:0.9445408163265306 Validation RAE:0.0768040614201454 Loss:29.381207858113417, Ranking:47.26998747863426, Reg:3.2437232385296455, Gen:26.499030308916044, Disc:9.430448336934751e-06, Recon_One:0.0, T_Reg:2.8821682309871823, T_MSE:320.54217086816794, CI:0.9219824236761114, \n",
      "it:13600, trainCI:0.9027357539082199, train_ranking:40.32627868652344, train_RAE:0.08212573826313019,  train_Gen:29.07137680053711, train_Disc:4.624614120984916e-06, train_reg:3.2228946685791016, train_t_reg:2.942727565765381, train_t_mse:132.20628356933594, train_layer_one_recon:0.0\n",
      "Iteration: 13671 epochs:147, Training: RAE:0.08999411016702652, Loss: 32.344139099121094, Ranking:54.04419708251953, Reg:3.2232065200805664, Gen:29.678693771362305, Disc:2.9777447707601823e-06, Recon_One:0.0, T_Reg:2.6654410362243652,T_MSE:124.740234375,  CI:0.9126292608196094 Validation RAE:0.0782193777444766 Loss:29.39139824443062, Ranking:47.26761119938409, Reg:3.244568273933795, Gen:26.572473916438604, Disc:8.99395481880093e-06, Recon_One:0.0, T_Reg:2.818915103694357, T_MSE:220.2354762201475, CI:0.9218076941798938, \n",
      "it:13700, trainCI:0.8828964736941354, train_ranking:54.547340393066406, train_RAE:0.10567180812358856,  train_Gen:29.150753021240234, train_Disc:3.327309968881309e-06, train_reg:3.22365403175354, train_t_reg:3.1345558166503906, train_t_mse:131.3797149658203, train_layer_one_recon:0.0\n",
      "Iteration: 13764 epochs:148, Training: RAE:0.08634583652019501, Loss: 32.73551559448242, Ranking:44.98830032348633, Reg:3.224123477935791, Gen:29.758670806884766, Disc:2.438935098325601e-06, Recon_One:0.0, T_Reg:2.9768433570861816,T_MSE:134.7378387451172,  CI:0.9074420450036842 Validation RAE:0.07849484048546203 Loss:29.465287456486216, Ranking:47.286358311338184, Reg:3.2454913089137323, Gen:26.625512125373735, Disc:8.989820996493086e-06, Recon_One:0.0, T_Reg:2.8397662633357084, T_MSE:207.96515152456462, CI:0.9215244009456047, \n",
      "it:13800, trainCI:0.9134507687608187, train_ranking:50.57451248168945, train_RAE:0.09221948683261871,  train_Gen:29.62833023071289, train_Disc:2.697590389288962e-06, train_reg:3.224135398864746, train_t_reg:2.6492490768432617, train_t_mse:81.09374237060547, train_layer_one_recon:0.0\n",
      "Iteration: 13857 epochs:149, Training: RAE:0.08991121500730515, Loss: 33.141109466552734, Ranking:49.3108024597168, Reg:3.2248687744140625, Gen:29.719533920288086, Disc:2.397423941147281e-06, Recon_One:0.0, T_Reg:3.4215736389160156,T_MSE:233.06658935546875,  CI:0.9082906115685361 Validation RAE:0.07588938595996106 Loss:29.861150569612867, Ranking:47.24578692851341, Reg:3.2462415448334627, Gen:26.964082332705058, Disc:7.0872210893627565e-06, Recon_One:0.0, T_Reg:2.8970614752054544, T_MSE:257.9597946821458, CI:0.9222510826015401, \n",
      "it:13900, trainCI:0.8806800807290074, train_ranking:42.05408477783203, train_RAE:0.09532077610492706,  train_Gen:29.809202194213867, train_Disc:2.3212667201732984e-06, train_reg:3.224912643432617, train_t_reg:3.444323778152466, train_t_mse:128.50030517578125, train_layer_one_recon:0.0\n",
      "Iteration: 13950 epochs:150, Training: RAE:0.10464844107627869, Loss: 33.277034759521484, Ranking:59.57149887084961, Reg:3.2255120277404785, Gen:30.32210922241211, Disc:2.3454163056157995e-06, Recon_One:0.0, T_Reg:2.954922914505005,T_MSE:95.56306457519531,  CI:0.8926436184039511 Validation RAE:0.07655223822450584 Loss:29.606956306868707, Ranking:47.271835510322596, Reg:3.2468890613118484, Gen:26.895850745531803, Disc:7.641845433424254e-06, Recon_One:0.0, T_Reg:2.711097850074496, T_MSE:169.13787051858313, CI:0.9221903138934703, *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:14000, trainCI:0.8720540405303978, train_ranking:51.53176498413086, train_RAE:0.10670530796051025,  train_Gen:29.686138153076172, train_Disc:2.3936472643981688e-06, train_reg:3.225537061691284, train_t_reg:3.221104145050049, train_t_mse:143.0862579345703, train_layer_one_recon:0.0\n",
      "Iteration: 14043 epochs:151, Training: RAE:0.09190356731414795, Loss: 32.94637680053711, Ranking:47.15055847167969, Reg:3.2259438037872314, Gen:30.0399169921875, Disc:2.002180053750635e-06, Recon_One:0.0, T_Reg:2.906456470489502,T_MSE:128.0699005126953,  CI:0.9051556420233463 Validation RAE:0.07663693542691101 Loss:30.071209197612617, Ranking:47.290550733754465, Reg:3.247323698948007, Gen:27.33391990389722, Disc:5.297996924317274e-06, Recon_One:0.0, T_Reg:2.7372839093968557, T_MSE:170.2259659990752, CI:0.9209764446787317, \n",
      "it:14100, trainCI:0.8785508663299114, train_ranking:46.97285842895508, train_RAE:0.095030777156353,  train_Gen:29.694183349609375, train_Disc:2.6345392143412028e-06, train_reg:3.226454734802246, train_t_reg:3.357476234436035, train_t_mse:117.59589385986328, train_layer_one_recon:0.0\n",
      "Iteration: 14136 epochs:152, Training: RAE:0.10190636664628983, Loss: 33.700050354003906, Ranking:52.070682525634766, Reg:3.226548194885254, Gen:30.213857650756836, Disc:2.769617822195869e-06, Recon_One:0.0, T_Reg:3.4861912727355957,T_MSE:191.6348876953125,  CI:0.9050679851668727 Validation RAE:0.0765842434852231 Loss:30.280888418980176, Ranking:47.26406589692662, Reg:3.2479320956391513, Gen:27.482540702557465, Disc:4.997498820010514e-06, Recon_One:0.0, T_Reg:2.7983428016668324, T_MSE:215.93862573877192, CI:0.9221103960365725, \n",
      "it:14200, trainCI:0.9269437704399198, train_ranking:48.521644592285156, train_RAE:0.08313797414302826,  train_Gen:30.272525787353516, train_Disc:3.2079324228107e-06, train_reg:3.2269859313964844, train_t_reg:2.504110336303711, train_t_mse:166.06307983398438, train_layer_one_recon:0.0\n",
      "Iteration: 14229 epochs:153, Training: RAE:0.09397412836551666, Loss: 32.99171829223633, Ranking:53.029422760009766, Reg:3.2270469665527344, Gen:30.107925415039062, Disc:2.115931465596077e-06, Recon_One:0.0, T_Reg:2.8837900161743164,T_MSE:139.67832946777344,  CI:0.9063869146139616 Validation RAE:0.07828323500587506 Loss:30.612633063433332, Ranking:47.28380856520536, Reg:3.2484341729085298, Gen:27.85921185049725, Disc:3.7254942481280397e-06, Recon_One:0.0, T_Reg:2.7534174251305963, T_MSE:173.23681649020483, CI:0.9213619704961954, \n",
      "it:14300, trainCI:0.9105732628827907, train_ranking:45.03989791870117, train_RAE:0.09380262345075607,  train_Gen:30.16583251953125, train_Disc:2.5341730633954285e-06, train_reg:3.227355718612671, train_t_reg:3.1753997802734375, train_t_mse:143.79165649414062, train_layer_one_recon:0.0\n",
      "Iteration: 14322 epochs:154, Training: RAE:0.094855397939682, Loss: 33.30439758300781, Ranking:47.61152267456055, Reg:3.2276666164398193, Gen:30.1331844329834, Disc:2.3025113478070125e-06, Recon_One:0.0, T_Reg:3.171211004257202,T_MSE:136.28433227539062,  CI:0.9020020506178835 Validation RAE:0.07811488439973568 Loss:30.39063610731847, Ranking:47.27694335036894, Reg:3.2490579295161366, Gen:27.68837401788503, Disc:4.6208853605723685e-06, Recon_One:0.0, T_Reg:2.7022574929366994, T_MSE:169.6399638157003, CI:0.9208878604048846, *\n",
      "it:14400, trainCI:0.9301565180102916, train_ranking:48.06464767456055, train_RAE:0.10302972793579102,  train_Gen:30.688735961914062, train_Disc:1.8995278878719546e-06, train_reg:3.2282629013061523, train_t_reg:2.547377586364746, train_t_mse:105.36089324951172, train_layer_one_recon:0.0\n",
      "Iteration: 14415 epochs:155, Training: RAE:0.1028289720416069, Loss: 34.04719543457031, Ranking:45.32841873168945, Reg:3.2284584045410156, Gen:30.500747680664062, Disc:2.012344793911325e-06, Recon_One:0.0, T_Reg:3.5464444160461426,T_MSE:150.2677764892578,  CI:0.8964263394125334 Validation RAE:0.08138571117607611 Loss:29.985377984418413, Ranking:47.29567510240657, Reg:3.2498549651813398, Gen:27.255241152672852, Disc:7.01687364454397e-06, Recon_One:0.0, T_Reg:2.7301299187396784, T_MSE:147.03470663948627, CI:0.9210109546623922, \n",
      "it:14500, trainCI:0.9295538575301947, train_ranking:51.9791374206543, train_RAE:0.07486049830913544,  train_Gen:30.33767318725586, train_Disc:1.906761781356181e-06, train_reg:3.22890567779541, train_t_reg:2.2937674522399902, train_t_mse:117.93995666503906, train_layer_one_recon:0.0\n",
      "Iteration: 14508 epochs:156, Training: RAE:0.085459865629673, Loss: 33.63525390625, Ranking:41.75706100463867, Reg:3.228944778442383, Gen:30.684850692749023, Disc:2.8915219445480034e-06, Recon_One:0.0, T_Reg:2.9504010677337646,T_MSE:138.36801147460938,  CI:0.9078408604779075 Validation RAE:0.07839476738842008 Loss:30.270129131409202, Ranking:47.279228805765236, Reg:3.2503445625185923, Gen:27.5192607532848, Disc:5.696661894259789e-06, Recon_One:0.0, T_Reg:2.7508628164155193, T_MSE:193.84980234516044, CI:0.9221782224255111, \n",
      "it:14600, trainCI:0.9110304968027545, train_ranking:41.246368408203125, train_RAE:0.07152805477380753,  train_Gen:30.27515411376953, train_Disc:2.258766926388489e-06, train_reg:3.2292401790618896, train_t_reg:2.3883776664733887, train_t_mse:86.58260345458984, train_layer_one_recon:0.0\n",
      "Iteration: 14601 epochs:157, Training: RAE:0.07152805477380753, Loss: 32.66353225708008, Ranking:41.246368408203125, Reg:3.2292401790618896, Gen:30.27515411376953, Disc:2.258766926388489e-06, Recon_One:0.0, T_Reg:2.3883776664733887,T_MSE:86.58260345458984,  CI:0.9110304968027545 Validation RAE:0.07629089725454315 Loss:30.383476633212858, Ranking:47.247329765339856, Reg:3.2506419209013644, Gen:27.656857472770703, Disc:5.715828295253574e-06, Recon_One:0.0, T_Reg:2.726613306560948, T_MSE:182.74614444535658, CI:0.9216797218194328, \n",
      "Iteration: 14694 epochs:158, Training: RAE:0.09035444259643555, Loss: 34.04097366333008, Ranking:47.22692108154297, Reg:3.2301149368286133, Gen:30.626251220703125, Disc:1.9401427380216774e-06, Recon_One:0.0, T_Reg:3.414719820022583,T_MSE:147.29881286621094,  CI:0.8909988606152678 Validation RAE:0.07811901051859953 Loss:30.512944617777656, Ranking:47.278816926266174, Reg:3.251522476112334, Gen:27.735231696955633, Disc:5.247354904235729e-06, Recon_One:0.0, T_Reg:2.777707672154917, T_MSE:198.34062619940912, CI:0.9225792128672317, \n",
      "it:14700, trainCI:0.9450362164465275, train_ranking:42.46123123168945, train_RAE:0.0733073279261589,  train_Gen:31.079578399658203, train_Disc:1.2214482012495864e-06, train_reg:3.2301745414733887, train_t_reg:2.5486111640930176, train_t_mse:116.37773895263672, train_layer_one_recon:0.0\n",
      "Iteration: 14787 epochs:159, Training: RAE:0.11413539201021194, Loss: 34.10958480834961, Ranking:46.079341888427734, Reg:3.230912208557129, Gen:30.633102416992188, Disc:1.5242241033774917e-06, Recon_One:0.0, T_Reg:3.4764795303344727,T_MSE:107.8966293334961,  CI:0.8993337034980566 Validation RAE:0.08022547351880954 Loss:30.214403604915532, Ranking:47.30294718807364, Reg:3.252325031747516, Gen:27.45398720219774, Disc:7.049776125139536e-06, Recon_One:0.0, T_Reg:2.76040932797366, T_MSE:177.3357574531581, CI:0.9218651935210905, \n",
      "it:14800, trainCI:0.9203383050460027, train_ranking:44.86116409301758, train_RAE:0.08456674218177795,  train_Gen:31.243789672851562, train_Disc:1.409835135746107e-06, train_reg:3.230940580368042, train_t_reg:2.7258548736572266, train_t_mse:101.40465545654297, train_layer_one_recon:0.0\n",
      "Iteration: 14880 epochs:160, Training: RAE:0.12042537331581116, Loss: 34.09296417236328, Ranking:58.9893913269043, Reg:3.231503486633301, Gen:30.734010696411133, Disc:2.027431946771685e-06, Recon_One:0.0, T_Reg:3.358949661254883,T_MSE:128.04629516601562,  CI:0.8926192145862553 Validation RAE:0.07602353707818638 Loss:31.109840237559176, Ranking:47.24952322819299, Reg:3.25292022851045, Gen:28.31355676034458, Disc:3.3561330294413323e-06, Recon_One:0.0, T_Reg:2.796280117232874, T_MSE:261.2325250707419, CI:0.9227022033353147, \n",
      "it:14900, trainCI:0.8902023740027243, train_ranking:53.17657470703125, train_RAE:0.10467788577079773,  train_Gen:30.720054626464844, train_Disc:1.414123971699155e-06, train_reg:3.231698989868164, train_t_reg:3.407567024230957, train_t_mse:90.826904296875, train_layer_one_recon:0.0\n",
      "Iteration: 14973 epochs:161, Training: RAE:0.10270260274410248, Loss: 34.13074493408203, Ranking:55.95947265625, Reg:3.2320399284362793, Gen:31.206254959106445, Disc:1.5605594398948597e-06, Recon_One:0.0, T_Reg:2.9244868755340576,T_MSE:112.28692626953125,  CI:0.9205851137464814 Validation RAE:0.0784070935713823 Loss:31.410684653546074, Ranking:47.2617326922248, Reg:3.2534602255735963, Gen:28.685482695831034, Disc:2.5304344548339084e-06, Recon_One:0.0, T_Reg:2.725199390772478, T_MSE:197.2932839164052, CI:0.9217966925008924, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:15000, trainCI:0.9044569539844033, train_ranking:49.821285247802734, train_RAE:0.09450104087591171,  train_Gen:31.13658905029297, train_Disc:1.4410658195629367e-06, train_reg:3.2322845458984375, train_t_reg:2.7579939365386963, train_t_mse:129.0408172607422, train_layer_one_recon:0.0\n",
      "Iteration: 15066 epochs:162, Training: RAE:0.09671458601951599, Loss: 34.39120864868164, Ranking:46.00736999511719, Reg:3.2325568199157715, Gen:31.301145553588867, Disc:1.4000600003782893e-06, Recon_One:0.0, T_Reg:3.090061902999878,T_MSE:96.35843658447266,  CI:0.8929883138564274 Validation RAE:0.0790597475218269 Loss:31.27340097583591, Ranking:47.28349836167506, Reg:3.253980542743774, Gen:28.490692743051195, Disc:3.1286649798487676e-06, Recon_One:0.0, T_Reg:2.7827050814975034, T_MSE:197.47163725596928, CI:0.9212349322405552, \n",
      "it:15100, trainCI:0.899698530335385, train_ranking:40.64850997924805, train_RAE:0.08340546488761902,  train_Gen:31.477401733398438, train_Disc:1.3671844953933032e-06, train_reg:3.23266863822937, train_t_reg:3.2685647010803223, train_t_mse:110.79753112792969, train_layer_one_recon:0.0\n",
      "Iteration: 15159 epochs:163, Training: RAE:0.09727464616298676, Loss: 34.794185638427734, Ranking:46.935916900634766, Reg:3.2330734729766846, Gen:31.36872673034668, Disc:9.674190550867934e-07, Recon_One:0.0, T_Reg:3.4254562854766846,T_MSE:153.42405700683594,  CI:0.9087132393134361 Validation RAE:0.07907695454780915 Loss:30.761756481968703, Ranking:47.27753854713187, Reg:3.254500619915257, Gen:28.136268347162627, Disc:4.5745464548254685e-06, Recon_One:0.0, T_Reg:2.6254836061350537, T_MSE:138.44832734821944, CI:0.9211968934164604, *\n",
      "it:15200, trainCI:0.8934300153812349, train_ranking:46.849334716796875, train_RAE:0.08551237732172012,  train_Gen:31.55055046081543, train_Disc:1.3419030437944457e-06, train_reg:3.2333688735961914, train_t_reg:2.8494443893432617, train_t_mse:72.59353637695312, train_layer_one_recon:0.0\n",
      "Iteration: 15252 epochs:164, Training: RAE:0.0889313593506813, Loss: 34.36369705200195, Ranking:44.2949333190918, Reg:3.2335543632507324, Gen:31.714338302612305, Disc:1.1262576435910887e-06, Recon_One:0.0, T_Reg:2.6493561267852783,T_MSE:128.1208038330078,  CI:0.9322886550248641 Validation RAE:0.07866805758687337 Loss:31.793924503152304, Ranking:47.280890681944264, Reg:3.2549846972825303, Gen:29.04730214019619, Disc:2.075023577692121e-06, Recon_One:0.0, T_Reg:2.746620516009639, T_MSE:176.62055499854497, CI:0.9223634865483198, \n",
      "it:15300, trainCI:0.9070400622325944, train_ranking:53.35903549194336, train_RAE:0.11035194247961044,  train_Gen:31.498626708984375, train_Disc:1.314014184572443e-06, train_reg:3.2340810298919678, train_t_reg:3.404402732849121, train_t_mse:136.78639221191406, train_layer_one_recon:0.0\n",
      "Iteration: 15345 epochs:165, Training: RAE:0.07784963399171829, Loss: 34.87751770019531, Ranking:45.110694885253906, Reg:3.2343215942382812, Gen:31.857351303100586, Disc:9.320902449871937e-07, Recon_One:0.0, T_Reg:3.0201635360717773,T_MSE:139.48800659179688,  CI:0.9017150019941884 Validation RAE:0.07514156551622399 Loss:31.538499944490596, Ranking:47.26685856347742, Reg:3.2557570130821762, Gen:28.763767598762623, Disc:2.7760623184344295e-06, Recon_One:0.0, T_Reg:2.7747297057423337, T_MSE:242.85874723926014, CI:0.9217341593726054, \n",
      "it:15400, trainCI:0.8996121261610697, train_ranking:50.035682678222656, train_RAE:0.09185668081045151,  train_Gen:31.600502014160156, train_Disc:1.0720268619479612e-06, train_reg:3.234874963760376, train_t_reg:2.608564853668213, train_t_mse:114.00098419189453, train_layer_one_recon:0.0\n",
      "Iteration: 15438 epochs:166, Training: RAE:0.10713229328393936, Loss: 35.28272247314453, Ranking:51.6834602355957, Reg:3.234978437423706, Gen:31.66134262084961, Disc:9.509307119515142e-07, Recon_One:0.0, T_Reg:3.6213772296905518,T_MSE:119.03007507324219,  CI:0.8762113005019132 Validation RAE:0.07588339756861677 Loss:32.39697502511165, Ranking:47.276639992018794, Reg:3.2564182094861613, Gen:29.678083655684237, Disc:1.2556194930025248e-06, Recon_One:0.0, T_Reg:2.718890044217231, T_MSE:199.254242378398, CI:0.9217413727376111, \n",
      "it:15500, trainCI:0.9084974431509085, train_ranking:46.92445755004883, train_RAE:0.08817736804485321,  train_Gen:31.96297264099121, train_Disc:8.385669616473024e-07, train_reg:3.2354116439819336, train_t_reg:2.7556278705596924, train_t_mse:94.11913299560547, train_layer_one_recon:0.0\n",
      "Iteration: 15531 epochs:167, Training: RAE:0.09368081390857697, Loss: 34.94053268432617, Ranking:48.29279327392578, Reg:3.2355966567993164, Gen:32.01654815673828, Disc:7.348209010160645e-07, Recon_One:0.0, T_Reg:2.9239821434020996,T_MSE:104.7843017578125,  CI:0.9014633625293741 Validation RAE:0.07449588098439691 Loss:31.41237249132304, Ranking:47.237631313738504, Reg:3.2570405261016, Gen:28.74041134318039, Disc:3.2051962209655774e-06, Recon_One:0.0, T_Reg:2.671957730769932, T_MSE:183.0069528216941, CI:0.9209563095303704, \n",
      "it:15600, trainCI:0.8754974417282547, train_ranking:35.564239501953125, train_RAE:0.06900261342525482,  train_Gen:31.91204071044922, train_Disc:7.161078769968299e-07, train_reg:3.236180305480957, train_t_reg:3.0115246772766113, train_t_mse:116.36725616455078, train_layer_one_recon:0.0\n",
      "Iteration: 15624 epochs:168, Training: RAE:0.10664021968841553, Loss: 34.91636657714844, Ranking:49.841758728027344, Reg:3.236215591430664, Gen:31.873825073242188, Disc:1.1439037734817248e-06, Recon_One:0.0, T_Reg:3.0425407886505127,T_MSE:126.1219482421875,  CI:0.9097154072620216 Validation RAE:0.07504891265056514 Loss:32.33851860564426, Ranking:47.24238821308479, Reg:3.257663562713123, Gen:29.69055089918363, Disc:1.4097618985487714e-06, Recon_One:0.0, T_Reg:2.647966156903842, T_MSE:186.06785193106168, CI:0.9221838270544365, \n",
      "it:15700, trainCI:0.9242569511025887, train_ranking:48.30854797363281, train_RAE:0.09264526516199112,  train_Gen:31.773265838623047, train_Disc:8.776612503424985e-07, train_reg:3.2364907264709473, train_t_reg:2.440479278564453, train_t_mse:119.50008392333984, train_layer_one_recon:0.0\n",
      "Iteration: 15717 epochs:169, Training: RAE:0.1083683967590332, Loss: 35.76456069946289, Ranking:52.28947067260742, Reg:3.236816644668579, Gen:32.13233947753906, Disc:1.461019564885646e-06, Recon_One:0.0, T_Reg:3.632220506668091,T_MSE:165.9590301513672,  CI:0.8855857617836886 Validation RAE:0.07584228181397004 Loss:31.73601778504311, Ranking:47.23192493781695, Reg:3.258268599422541, Gen:29.060364663936323, Disc:2.5760665176073986e-06, Recon_One:0.0, T_Reg:2.67565031416553, T_MSE:178.41088048246363, CI:0.9214141765767404, \n",
      "it:15800, trainCI:0.8980323948255245, train_ranking:47.52193832397461, train_RAE:0.08920405060052872,  train_Gen:32.20759582519531, train_Disc:1.0666614116416895e-06, train_reg:3.2373433113098145, train_t_reg:3.3236167430877686, train_t_mse:142.2808380126953, train_layer_one_recon:0.0\n",
      "Iteration: 15810 epochs:170, Training: RAE:0.1071702167391777, Loss: 35.96280288696289, Ranking:45.41435241699219, Reg:3.237311363220215, Gen:32.07664489746094, Disc:7.522518217228935e-07, Recon_One:0.0, T_Reg:3.886157989501953,T_MSE:154.0847930908203,  CI:0.8959268306538658 Validation RAE:0.0756319981206726 Loss:32.24459388516345, Ranking:47.25519420952443, Reg:3.258766596714109, Gen:29.620214419110322, Disc:1.5812954723942927e-06, Recon_One:0.0, T_Reg:2.6243775773677465, T_MSE:164.0140988997583, CI:0.9221511852804177, *\n",
      "it:15900, trainCI:0.8473239436619718, train_ranking:54.826473236083984, train_RAE:0.11689263582229614,  train_Gen:32.17768096923828, train_Disc:1.1142763014504453e-06, train_reg:3.2381041049957275, train_t_reg:3.7455379962921143, train_t_mse:141.04615783691406, train_layer_one_recon:0.0\n",
      "Iteration: 15903 epochs:171, Training: RAE:0.09904418885707855, Loss: 34.5929069519043, Ranking:54.292022705078125, Reg:3.2380852699279785, Gen:32.009735107421875, Disc:1.262371029042697e-06, Recon_One:0.0, T_Reg:2.583170175552368,T_MSE:88.00753784179688,  CI:0.928476821192053 Validation RAE:0.07568087013748358 Loss:32.67708029823928, Ranking:47.26379225667572, Reg:3.259545632477207, Gen:30.04030813436829, Disc:1.237208611913087e-06, Recon_One:0.0, T_Reg:2.636770812573993, T_MSE:168.4086461297956, CI:0.9225880868630301, \n",
      "Iteration: 15996 epochs:172, Training: RAE:0.0915885716676712, Loss: 34.954872131347656, Ranking:55.34159469604492, Reg:3.23840069770813, Gen:32.524009704589844, Disc:6.348952297230426e-07, Recon_One:0.0, T_Reg:2.430860996246338,T_MSE:77.83668518066406,  CI:0.921911421911422 Validation RAE:0.07551206089253423 Loss:31.938226660952296, Ranking:47.278126230892184, Reg:3.259863150750337, Gen:29.281493784771033, Disc:2.591540815931571e-06, Recon_One:0.0, T_Reg:2.656730048370552, T_MSE:163.5744486717309, CI:0.9212569355985583, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:16000, trainCI:0.9028177762719521, train_ranking:45.410221099853516, train_RAE:0.09146972745656967,  train_Gen:32.286590576171875, train_Disc:9.85525616670202e-07, train_reg:3.2384512424468994, train_t_reg:2.7844414710998535, train_t_mse:121.59454345703125, train_layer_one_recon:0.0\n",
      "Iteration: 16089 epochs:173, Training: RAE:0.08309566974639893, Loss: 35.04017639160156, Ranking:40.06618881225586, Reg:3.2387266159057617, Gen:32.39167022705078, Disc:7.129392542992719e-07, Recon_One:0.0, T_Reg:2.6485047340393066,T_MSE:108.86223602294922,  CI:0.9441728839722151 Validation RAE:0.07686490190447279 Loss:31.69310843928152, Ranking:47.283390675304204, Reg:3.260191228966035, Gen:29.11158564449385, Disc:3.1009840616434275e-06, Recon_One:0.0, T_Reg:2.5815195495879277, T_MSE:122.00812525461208, CI:0.921906605501483, *\n",
      "it:16100, trainCI:0.8985925046633881, train_ranking:45.66014862060547, train_RAE:0.08622962981462479,  train_Gen:32.57419204711914, train_Disc:8.774612751949462e-07, train_reg:3.2389402389526367, train_t_reg:3.0321967601776123, train_t_mse:93.22553253173828, train_layer_one_recon:0.0\n",
      "Iteration: 16182 epochs:174, Training: RAE:0.1144791767001152, Loss: 36.614192962646484, Ranking:54.955078125, Reg:3.2397241592407227, Gen:32.63530731201172, Disc:7.659011203031696e-07, Recon_One:0.0, T_Reg:3.9788849353790283,T_MSE:206.48948669433594,  CI:0.9078141200867188 Validation RAE:0.07671537097858849 Loss:31.981706994912827, Ranking:47.27328986067376, Reg:3.2611953835047913, Gen:29.423883883404823, Disc:2.4358756031288485e-06, Recon_One:0.0, T_Reg:2.5578207323905064, T_MSE:127.80308916044933, CI:0.9229928137240341, *\n",
      "it:16200, trainCI:0.9256756756756757, train_ranking:40.6646728515625, train_RAE:0.0634922981262207,  train_Gen:32.42229080200195, train_Disc:1.2007559462290374e-06, train_reg:3.2399511337280273, train_t_reg:2.2571778297424316, train_t_mse:84.92591094970703, train_layer_one_recon:0.0\n",
      "Iteration: 16275 epochs:175, Training: RAE:0.09752392023801804, Loss: 35.52071762084961, Ranking:45.273475646972656, Reg:3.240389585494995, Gen:32.293670654296875, Disc:9.834573120315326e-07, Recon_One:0.0, T_Reg:3.227046489715576,T_MSE:115.67388916015625,  CI:0.9159123256475946 Validation RAE:0.07566818248909593 Loss:32.398333459462734, Ranking:47.279547357076225, Reg:3.261865219861787, Gen:29.84145489933939, Disc:1.7486090901947263e-06, Recon_One:0.0, T_Reg:2.5568768070894015, T_MSE:124.08654667428691, CI:0.9225067678489008, *\n",
      "it:16300, trainCI:0.8804390435123481, train_ranking:45.5231819152832, train_RAE:0.09319800138473511,  train_Gen:32.596282958984375, train_Disc:8.76374656400003e-07, train_reg:3.2405800819396973, train_t_reg:3.0735385417938232, train_t_mse:93.6710205078125, train_layer_one_recon:0.0\n",
      "Iteration: 16368 epochs:176, Training: RAE:0.07662242650985718, Loss: 35.98528289794922, Ranking:40.11439895629883, Reg:3.240987777709961, Gen:32.880340576171875, Disc:7.295894306480477e-07, Recon_One:0.0, T_Reg:3.104942560195923,T_MSE:150.72235107421875,  CI:0.88401194181541 Validation RAE:0.07405554875964386 Loss:33.605869904270435, Ranking:47.256378592648204, Reg:3.2624673765868684, Gen:30.95020120317107, Disc:6.99020780180899e-07, Recon_One:0.0, T_Reg:2.6556675219753467, T_MSE:155.15531382740207, CI:0.9229351586987007, \n",
      "it:16400, trainCI:0.9107712262876291, train_ranking:47.623008728027344, train_RAE:0.09104260802268982,  train_Gen:33.14166259765625, train_Disc:6.525521598632622e-07, train_reg:3.241029977798462, train_t_reg:3.319570302963257, train_t_mse:184.40736389160156, train_layer_one_recon:0.0\n",
      "Iteration: 16461 epochs:177, Training: RAE:0.06666103005409241, Loss: 35.201358795166016, Ranking:37.20222091674805, Reg:3.241265296936035, Gen:32.95695495605469, Disc:6.289228053901752e-07, Recon_One:0.0, T_Reg:2.2444047927856445,T_MSE:116.09626770019531,  CI:0.9419505174422589 Validation RAE:0.07461266268621881 Loss:32.457202593207256, Ranking:47.26430698083284, Reg:3.2627467350675357, Gen:29.909828816173345, Disc:1.8805476552518722e-06, Recon_One:0.0, T_Reg:2.5473719666089747, T_MSE:126.60877284548111, CI:0.9220034929292935, *\n",
      "it:16500, trainCI:0.9106698409263067, train_ranking:47.425533294677734, train_RAE:0.08740135282278061,  train_Gen:32.999664306640625, train_Disc:5.538130380955408e-07, train_reg:3.2418317794799805, train_t_reg:2.7005677223205566, train_t_mse:124.04734802246094, train_layer_one_recon:0.0\n",
      "Iteration: 16554 epochs:178, Training: RAE:0.07914899289608002, Loss: 35.71171188354492, Ranking:47.018714904785156, Reg:3.242245674133301, Gen:33.055824279785156, Disc:1.014232339002774e-06, Recon_One:0.0, T_Reg:2.655886650085449,T_MSE:123.88241577148438,  CI:0.9310475983481852 Validation RAE:0.07401142535831118 Loss:33.98372785619039, Ranking:47.2595908186563, Reg:3.2637336097002714, Gen:31.39964220925422, Disc:5.337210752383773e-07, Recon_One:0.0, T_Reg:2.58408522954714, T_MSE:142.97794834798583, CI:0.9231662458524449, \n",
      "it:16600, trainCI:0.8764972925668654, train_ranking:46.60169219970703, train_RAE:0.09944355487823486,  train_Gen:32.86360549926758, train_Disc:9.417213391316182e-07, train_reg:3.242633581161499, train_t_reg:3.3845443725585938, train_t_mse:105.84980010986328, train_layer_one_recon:0.0\n",
      "Iteration: 16647 epochs:179, Training: RAE:0.07840614765882492, Loss: 36.27035903930664, Ranking:44.30605697631836, Reg:3.2428524494171143, Gen:33.46253204345703, Disc:5.751452363256249e-07, Recon_One:0.0, T_Reg:2.8078250885009766,T_MSE:121.83118438720703,  CI:0.9090008161361781 Validation RAE:0.07372021694209138 Loss:34.518141756657585, Ranking:47.24570879328619, Reg:3.264344406378363, Gen:31.95860092231776, Disc:3.488237197069663e-07, Recon_One:0.0, T_Reg:2.559540427385516, T_MSE:141.7082388847936, CI:0.9230385848602574, \n",
      "it:16700, trainCI:0.9109785730064061, train_ranking:46.37369155883789, train_RAE:0.09195489436388016,  train_Gen:33.45376968383789, train_Disc:5.340533562048222e-07, train_reg:3.2433934211730957, train_t_reg:2.713887929916382, train_t_mse:129.41372680664062, train_layer_one_recon:0.0\n",
      "Iteration: 16740 epochs:180, Training: RAE:0.10741075873374939, Loss: 37.32942581176758, Ranking:42.78980255126953, Reg:3.243602752685547, Gen:33.32127380371094, Disc:1.5896075638011098e-06, Recon_One:0.0, T_Reg:4.008150577545166,T_MSE:123.46768951416016,  CI:0.8510715363718684 Validation RAE:0.07805131213678723 Loss:34.2428317826674, Ranking:47.31247400930409, Reg:3.265099682270683, Gen:31.588873625308466, Disc:4.704644780124557e-07, Recon_One:0.0, T_Reg:2.6539577086657244, T_MSE:114.23378701476554, CI:0.9211173388225484, \n",
      "it:16800, trainCI:0.9025726536445927, train_ranking:42.793914794921875, train_RAE:0.08748092502355576,  train_Gen:33.38125991821289, train_Disc:4.4535244114740635e-07, train_reg:3.2443130016326904, train_t_reg:2.794513463973999, train_t_mse:123.31998443603516, train_layer_one_recon:0.0\n",
      "Iteration: 16833 epochs:181, Training: RAE:0.08207857608795166, Loss: 36.897090911865234, Ranking:44.98082733154297, Reg:3.244666337966919, Gen:33.5054931640625, Disc:5.858248641743558e-07, Recon_One:0.0, T_Reg:3.391597270965576,T_MSE:124.51708221435547,  CI:0.8977318403674993 Validation RAE:0.07389566462919744 Loss:34.96303572660091, Ranking:47.27338619406289, Reg:3.26617031644788, Gen:32.4220939980636, Disc:2.7237725645868e-07, Recon_One:0.0, T_Reg:2.5409413215829924, T_MSE:123.06912150161779, CI:0.9230437224367722, *\n",
      "it:16900, trainCI:0.8812363862669848, train_ranking:49.27988052368164, train_RAE:0.09895993024110794,  train_Gen:33.440433502197266, train_Disc:4.89740386910853e-07, train_reg:3.245011329650879, train_t_reg:3.2183139324188232, train_t_mse:105.44815826416016, train_layer_one_recon:0.0\n",
      "Iteration: 16926 epochs:182, Training: RAE:0.10639713704586029, Loss: 36.99456024169922, Ranking:53.231571197509766, Reg:3.245148181915283, Gen:33.58692932128906, Disc:4.474428010325937e-07, Recon_One:0.0, T_Reg:3.4076297283172607,T_MSE:133.63134765625,  CI:0.8925468237111411 Validation RAE:0.07644686901496324 Loss:33.45506808095028, Ranking:47.29482195922043, Reg:3.2666553538099325, Gen:30.879740925510184, Disc:9.341510752742682e-07, Recon_One:0.0, T_Reg:2.5753266963121577, T_MSE:115.0882701866624, CI:0.9218123647039983, \n",
      "it:17000, trainCI:0.9152183545861848, train_ranking:52.6602668762207, train_RAE:0.09309599548578262,  train_Gen:33.733863830566406, train_Disc:4.6663552666359465e-07, train_reg:3.245820999145508, train_t_reg:3.2742366790771484, train_t_mse:131.38783264160156, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17019 epochs:183, Training: RAE:0.07570413500070572, Loss: 36.554988861083984, Ranking:39.924461364746094, Reg:3.2459731101989746, Gen:33.880516052246094, Disc:4.551123709006788e-07, Recon_One:0.0, T_Reg:2.6744706630706787,T_MSE:138.69418334960938,  CI:0.9005108556832695 Validation RAE:0.07397721608784164 Loss:35.324312648699255, Ranking:47.27775993027567, Reg:3.2674857492937033, Gen:32.79629795942155, Disc:2.3051430783217945e-07, Recon_One:0.0, T_Reg:2.5280146840603424, T_MSE:120.78804535106732, CI:0.9216135041665745, *\n",
      "it:17100, trainCI:0.8964259664478483, train_ranking:45.70470428466797, train_RAE:0.09222859889268875,  train_Gen:33.968666076660156, train_Disc:4.660227261865657e-07, train_reg:3.24619460105896, train_t_reg:3.368229389190674, train_t_mse:128.44398498535156, train_layer_one_recon:0.0\n",
      "Iteration: 17112 epochs:184, Training: RAE:0.11367052048444748, Loss: 37.106380462646484, Ranking:45.326416015625, Reg:3.2462024688720703, Gen:33.38306427001953, Disc:6.657879794147448e-07, Recon_One:0.0, T_Reg:3.723315715789795,T_MSE:84.04418182373047,  CI:0.9236489554950046 Validation RAE:0.08197184277092112 Loss:34.15037693940983, Ranking:47.366756287994896, Reg:3.267716628038035, Gen:31.379545928985607, Disc:6.7730467428018e-07, Recon_One:0.0, T_Reg:2.7708303739059503, T_MSE:99.16081950264125, CI:0.9204592619762357, \n",
      "it:17200, trainCI:0.9041542221015476, train_ranking:47.07713317871094, train_RAE:0.08484825491905212,  train_Gen:34.194679260253906, train_Disc:3.3339929927933554e-07, train_reg:3.246821165084839, train_t_reg:2.8781795501708984, train_t_mse:127.45252227783203, train_layer_one_recon:0.0\n",
      "Iteration: 17205 epochs:185, Training: RAE:0.09218470007181168, Loss: 36.90717697143555, Ranking:42.425987243652344, Reg:3.2467432022094727, Gen:34.146453857421875, Disc:8.304001539727324e-07, Recon_One:0.0, T_Reg:2.7607226371765137,T_MSE:81.9464111328125,  CI:0.9227253336583582 Validation RAE:0.07497169258140751 Loss:34.58636466213893, Ranking:47.285984497719056, Reg:3.268260945077686, Gen:32.043100330581275, Disc:4.0201193063202295e-07, Recon_One:0.0, T_Reg:2.543263981994337, T_MSE:123.71805192709596, CI:0.9222541443895641, \n",
      "Iteration: 17298 epochs:186, Training: RAE:0.06358171999454498, Loss: 36.720237731933594, Ranking:32.393409729003906, Reg:3.2474496364593506, Gen:34.286842346191406, Disc:3.716874061865383e-07, Recon_One:0.0, T_Reg:2.4333932399749756,T_MSE:95.76573181152344,  CI:0.9141624166339741 Validation RAE:0.07540862536812717 Loss:34.41824336431765, Ranking:47.29743848759874, Reg:3.2689720612101754, Gen:31.888389575476943, Disc:4.832794898710218e-07, Recon_One:0.0, T_Reg:2.529853324495406, T_MSE:112.78281818259667, CI:0.9211294302905076, \n",
      "it:17300, trainCI:0.8993443000115036, train_ranking:44.39784240722656, train_RAE:0.08188509196043015,  train_Gen:33.942779541015625, train_Disc:3.6999949770688545e-07, train_reg:3.2474732398986816, train_t_reg:2.8385367393493652, train_t_mse:91.1559829711914, train_layer_one_recon:0.0\n",
      "Iteration: 17391 epochs:187, Training: RAE:0.08232805877923965, Loss: 37.097373962402344, Ranking:36.2490119934082, Reg:3.2482454776763916, Gen:34.17368698120117, Disc:5.924439960836025e-07, Recon_One:0.0, T_Reg:2.9236860275268555,T_MSE:93.80724334716797,  CI:0.8876268900404628 Validation RAE:0.07468014976483249 Loss:34.50286081020006, Ranking:47.28531333615187, Reg:3.269773176853189, Gen:31.99833527317312, Disc:4.563297655437221e-07, Recon_One:0.0, T_Reg:2.5045252396372595, T_MSE:115.62424879514144, CI:0.9224443904047507, *\n",
      "it:17400, trainCI:0.9052647307864721, train_ranking:52.13957977294922, train_RAE:0.1180899366736412,  train_Gen:33.897727966308594, train_Disc:5.753240088779421e-07, train_reg:3.248288154602051, train_t_reg:3.3950538635253906, train_t_mse:131.88980102539062, train_layer_one_recon:0.0\n",
      "Iteration: 17484 epochs:188, Training: RAE:0.07885874807834625, Loss: 37.27890396118164, Ranking:43.6805305480957, Reg:3.248753547668457, Gen:34.16236877441406, Disc:4.3159263896086486e-07, Recon_One:0.0, T_Reg:3.116534948348999,T_MSE:143.49534606933594,  CI:0.8905109489051095 Validation RAE:0.0742497388448166 Loss:34.77426235327292, Ranking:47.285713528757974, Reg:3.2702846140716617, Gen:32.29094276700122, Disc:3.881240472220862e-07, Recon_One:0.0, T_Reg:2.4833191219264004, T_MSE:110.9688507820407, CI:0.9229055268179938, *\n",
      "it:17500, trainCI:0.8976250261560996, train_ranking:49.13721466064453, train_RAE:0.09337630867958069,  train_Gen:34.107818603515625, train_Disc:3.9480801206082106e-07, train_reg:3.24894642829895, train_t_reg:2.8996753692626953, train_t_mse:108.41860961914062, train_layer_one_recon:0.0\n",
      "Iteration: 17577 epochs:189, Training: RAE:0.07807336747646332, Loss: 37.03129959106445, Ranking:45.5820198059082, Reg:3.2498619556427, Gen:34.483402252197266, Disc:3.7263237118168036e-07, Recon_One:0.0, T_Reg:2.547896385192871,T_MSE:107.03013610839844,  CI:0.9025364152747315 Validation RAE:0.07414849591718042 Loss:34.70935401759088, Ranking:47.28171844787712, Reg:3.2714003680034685, Gen:32.19079552731902, Disc:4.1334234460975403e-07, Recon_One:0.0, T_Reg:2.5185579163619423, T_MSE:115.25341232851235, CI:0.9221240962406121, \n",
      "it:17600, trainCI:0.8830635055886923, train_ranking:51.36244583129883, train_RAE:0.09103243798017502,  train_Gen:34.61012268066406, train_Disc:2.965205965210771e-07, train_reg:3.249953269958496, train_t_reg:3.079423666000366, train_t_mse:97.85315704345703, train_layer_one_recon:0.0\n",
      "Iteration: 17670 epochs:190, Training: RAE:0.07157174497842789, Loss: 37.57081985473633, Ranking:37.60000991821289, Reg:3.2504937648773193, Gen:34.51994705200195, Disc:3.542620561347576e-07, Recon_One:0.0, T_Reg:3.050870895385742,T_MSE:111.63292694091797,  CI:0.870011479505706 Validation RAE:0.07397379806295282 Loss:35.41783483919537, Ranking:47.27450462971924, Reg:3.2720363645445065, Gen:32.89180341565312, Disc:2.58203949000266e-07, Recon_One:0.0, T_Reg:2.5260310009358538, T_MSE:120.5976124389389, CI:0.9230591351663169, \n",
      "it:17700, trainCI:0.9390700160342063, train_ranking:47.87939453125, train_RAE:0.07793853431940079,  train_Gen:35.00023651123047, train_Disc:2.6679975917431875e-07, train_reg:3.2506721019744873, train_t_reg:2.3378686904907227, train_t_mse:121.7506332397461, train_layer_one_recon:0.0\n",
      "Iteration: 17763 epochs:191, Training: RAE:0.08204005658626556, Loss: 37.189456939697266, Ranking:46.425628662109375, Reg:3.251224994659424, Gen:34.67546081542969, Disc:4.0256628608403844e-07, Recon_One:0.0, T_Reg:2.5139942169189453,T_MSE:97.88834381103516,  CI:0.9284722607874716 Validation RAE:0.07316013270558396 Loss:36.37457782363271, Ranking:47.25590694303943, Reg:3.272772440541248, Gen:33.90777724317212, Disc:1.5196586556483462e-07, Recon_One:0.0, T_Reg:2.466800632634222, T_MSE:117.58247853458353, CI:0.922970031945347, *\n",
      "it:17800, trainCI:0.9055076117521574, train_ranking:53.15732955932617, train_RAE:0.09740394353866577,  train_Gen:34.676239013671875, train_Disc:4.1174101284013886e-07, train_reg:3.251809597015381, train_t_reg:2.6212234497070312, train_t_mse:115.06147766113281, train_layer_one_recon:0.0\n",
      "Iteration: 17856 epochs:192, Training: RAE:0.0879063606262207, Loss: 37.24879837036133, Ranking:54.6281852722168, Reg:3.2524170875549316, Gen:34.67308044433594, Disc:3.7057955637465056e-07, Recon_One:0.0, T_Reg:2.575716972351074,T_MSE:106.36883544921875,  CI:0.9200720584052338 Validation RAE:0.07343793233603377 Loss:35.59607548372021, Ranking:47.27603193967361, Reg:3.2739724340149055, Gen:33.128364661253585, Disc:2.7486067058049053e-07, Recon_One:0.0, T_Reg:2.4677106033373852, T_MSE:114.38500973318791, CI:0.9227580420457187, \n",
      "it:17900, trainCI:0.8878587631916363, train_ranking:52.0108528137207, train_RAE:0.09803731739521027,  train_Gen:34.755950927734375, train_Disc:3.8211442188185174e-07, train_reg:3.252809762954712, train_t_reg:3.1414175033569336, train_t_mse:121.06292724609375, train_layer_one_recon:0.0\n",
      "Iteration: 17949 epochs:193, Training: RAE:0.08500723540782928, Loss: 37.63546371459961, Ranking:52.26896286010742, Reg:3.2528958320617676, Gen:35.000274658203125, Disc:2.87550136590653e-07, Recon_One:0.0, T_Reg:2.635190010070801,T_MSE:92.02559661865234,  CI:0.9193508607507522 Validation RAE:0.07342185633650895 Loss:35.893941995902885, Ranking:47.25113518464352, Reg:3.2744543513939264, Gen:33.48242175479196, Disc:2.095358803449445e-07, Recon_One:0.0, T_Reg:2.4115199541559633, T_MSE:116.58476280602602, CI:0.9228417482166122, *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:18000, trainCI:0.9256910641718394, train_ranking:58.02619552612305, train_RAE:0.10036569833755493,  train_Gen:34.93409729003906, train_Disc:5.563135800912278e-07, train_reg:3.2531542778015137, train_t_reg:2.6923768520355225, train_t_mse:94.64027404785156, train_layer_one_recon:0.0\n",
      "Iteration: 18042 epochs:194, Training: RAE:0.11788502335548401, Loss: 38.47208023071289, Ranking:51.18997573852539, Reg:3.2534313201904297, Gen:34.8338623046875, Disc:5.61530157483503e-07, Recon_One:0.0, T_Reg:3.6382179260253906,T_MSE:116.30944061279297,  CI:0.8744977902772197 Validation RAE:0.07622039323581581 Loss:35.76066767377854, Ranking:47.29319364111975, Reg:3.2749933884622933, Gen:33.28733679144266, Disc:2.8293210108984775e-07, Recon_One:0.0, T_Reg:2.4733304753815726, T_MSE:108.39357246111761, CI:0.9236768898211947, \n",
      "it:18100, trainCI:0.8707851188254324, train_ranking:41.13376235961914, train_RAE:0.10120726376771927,  train_Gen:34.8026123046875, train_Disc:3.76628122467082e-07, train_reg:3.253913402557373, train_t_reg:4.036327838897705, train_t_mse:105.61548614501953, train_layer_one_recon:0.0\n",
      "Iteration: 18135 epochs:195, Training: RAE:0.09236831963062286, Loss: 38.168800354003906, Ranking:52.118778228759766, Reg:3.254380226135254, Gen:34.955970764160156, Disc:2.9050022476440063e-07, Recon_One:0.0, T_Reg:3.2128288745880127,T_MSE:144.8821258544922,  CI:0.9133382826033161 Validation RAE:0.07469276763099096 Loss:36.092569256508604, Ranking:47.27691997658302, Reg:3.2759485832673243, Gen:33.66305053241554, Disc:1.9684956655007493e-07, Recon_One:0.0, T_Reg:2.4295183275734855, T_MSE:110.54119364356971, CI:0.9235961416489005, \n",
      "it:18200, trainCI:0.9031125672829394, train_ranking:43.7960090637207, train_RAE:0.07714520394802094,  train_Gen:35.098960876464844, train_Disc:2.921145210166287e-07, train_reg:3.2549092769622803, train_t_reg:3.6105308532714844, train_t_mse:175.97682189941406, train_layer_one_recon:0.0\n",
      "Iteration: 18228 epochs:196, Training: RAE:0.09716954827308655, Loss: 38.49188232421875, Ranking:49.601905822753906, Reg:3.2551662921905518, Gen:35.477603912353516, Disc:2.562237568781711e-07, Recon_One:0.0, T_Reg:3.0142786502838135,T_MSE:123.96641540527344,  CI:0.90459491516683 Validation RAE:0.07496397349295414 Loss:36.00989450614751, Ranking:47.27590471949595, Reg:3.2767398589638543, Gen:33.58710309155393, Disc:2.6724576604456384e-07, Recon_One:0.0, T_Reg:2.4227912372032434, T_MSE:112.74182523684723, CI:0.9229162690234339, \n",
      "it:18300, trainCI:0.9079674241129905, train_ranking:45.072845458984375, train_RAE:0.08330484479665756,  train_Gen:35.52211380004883, train_Disc:2.5141824266938784e-07, train_reg:3.255610942840576, train_t_reg:2.851140022277832, train_t_mse:146.2817840576172, train_layer_one_recon:0.0\n",
      "Iteration: 18321 epochs:197, Training: RAE:0.0895843356847763, Loss: 38.21592330932617, Ranking:42.94509506225586, Reg:3.255871295928955, Gen:35.37809371948242, Disc:2.1186701815167908e-07, Recon_One:0.0, T_Reg:2.837830066680908,T_MSE:104.94415283203125,  CI:0.9097632253831932 Validation RAE:0.07273855755273083 Loss:35.9661881977638, Ranking:47.26328688203297, Reg:3.277449535104175, Gen:33.58309365249029, Disc:3.010278745571874e-07, Recon_One:0.0, T_Reg:2.38309456614296, T_MSE:112.3253831747727, CI:0.924323030883685, *\n",
      "it:18400, trainCI:0.8830775343962648, train_ranking:51.771820068359375, train_RAE:0.10122324526309967,  train_Gen:35.92723083496094, train_Disc:1.9868525669153314e-07, train_reg:3.256371021270752, train_t_reg:3.3723950386047363, train_t_mse:139.76034545898438, train_layer_one_recon:0.0\n",
      "Iteration: 18414 epochs:198, Training: RAE:0.1062580794095993, Loss: 38.869529724121094, Ranking:50.873741149902344, Reg:3.2564730644226074, Gen:35.40168762207031, Disc:2.813313813021523e-07, Recon_One:0.0, T_Reg:3.4678430557250977,T_MSE:155.48744201660156,  CI:0.8764393711825373 Validation RAE:0.07229390959057999 Loss:36.03817561842344, Ranking:47.21908020767492, Reg:3.2780552918096775, Gen:33.553915153790584, Disc:2.9643376218532065e-07, Recon_One:0.0, T_Reg:2.4842600159396437, T_MSE:122.91149102674062, CI:0.9232697239087139, \n",
      "it:18500, trainCI:0.9076847832732163, train_ranking:42.03409957885742, train_RAE:0.07492068409919739,  train_Gen:35.35830307006836, train_Disc:6.541223456224543e-07, train_reg:3.2572691440582275, train_t_reg:2.629925012588501, train_t_mse:120.0086441040039, train_layer_one_recon:0.0\n",
      "Iteration: 18507 epochs:199, Training: RAE:0.09322253614664078, Loss: 38.76915740966797, Ranking:47.60813522338867, Reg:3.2572622299194336, Gen:35.559852600097656, Disc:3.745169578905916e-07, Recon_One:0.0, T_Reg:3.20930552482605,T_MSE:120.37267303466797,  CI:0.911615749060611 Validation RAE:0.07463063650150903 Loss:36.371304324914384, Ranking:47.29622906113291, Reg:3.2788496874892386, Gen:33.91179269263785, Disc:2.458361001574702e-07, Recon_One:0.0, T_Reg:2.4595116061897175, T_MSE:106.99112126420881, CI:0.924621217900396, \n",
      "Iteration: 18600 epochs:200, Training: RAE:0.07986517250537872, Loss: 38.00831985473633, Ranking:47.23790740966797, Reg:3.258080005645752, Gen:35.64875030517578, Disc:1.8263264678353153e-07, Recon_One:0.0, T_Reg:2.3595688343048096,T_MSE:110.33737182617188,  CI:0.9351841849411257 Validation RAE:0.07235514969229921 Loss:36.3936204470231, Ranking:47.259015823522624, Reg:3.2796728830121675, Gen:33.9422135080593, Disc:2.406198586190301e-07, Recon_One:0.0, T_Reg:2.4514071007020566, T_MSE:113.59140725974756, CI:0.923611917641431, \n",
      "it:18600, trainCI:0.916249453166772, train_ranking:52.83208465576172, train_RAE:0.0822245329618454,  train_Gen:35.69319152832031, train_Disc:3.141183526622626e-07, train_reg:3.2580676078796387, train_t_reg:2.3706274032592773, train_t_mse:117.64354705810547, train_layer_one_recon:0.0\n",
      "Iteration: 18693 epochs:201, Training: RAE:0.08733245730400085, Loss: 38.36243438720703, Ranking:45.19165802001953, Reg:3.258660316467285, Gen:35.611839294433594, Disc:2.6003255015893956e-07, Recon_One:0.0, T_Reg:2.7505955696105957,T_MSE:114.56578063964844,  CI:0.9082246171298922 Validation RAE:0.07554818917430609 Loss:36.573863056312135, Ranking:47.28520915584891, Reg:3.280257039835144, Gen:34.12164070613089, Disc:2.1982582554586194e-07, Recon_One:0.0, T_Reg:2.4522219380095733, T_MSE:109.60123988260429, CI:0.923220579616193, \n",
      "it:18700, trainCI:0.9247915011914217, train_ranking:51.90253448486328, train_RAE:0.08309812098741531,  train_Gen:35.9710807800293, train_Disc:2.602617144020769e-07, train_reg:3.258701801300049, train_t_reg:2.4053797721862793, train_t_mse:107.17658233642578, train_layer_one_recon:0.0\n",
      "Iteration: 18786 epochs:202, Training: RAE:0.08237738907337189, Loss: 38.86592102050781, Ranking:48.791664123535156, Reg:3.2593679428100586, Gen:36.15570068359375, Disc:2.2122812026736938e-07, Recon_One:0.0, T_Reg:2.710222005844116,T_MSE:106.52297973632812,  CI:0.9190407979203141 Validation RAE:0.07298713848339523 Loss:36.73703645756502, Ranking:47.24756517275521, Reg:3.280969355961107, Gen:34.302543290960976, Disc:1.9374246276874767e-07, Recon_One:0.0, T_Reg:2.4344930674741456, T_MSE:116.44853503909486, CI:0.9237774098788643, \n",
      "it:18800, trainCI:0.8906448337141406, train_ranking:40.2366943359375, train_RAE:0.07853829860687256,  train_Gen:36.23340606689453, train_Disc:2.3767103130012401e-07, train_reg:3.259486436843872, train_t_reg:2.8255515098571777, train_t_mse:103.65670776367188, train_layer_one_recon:0.0\n",
      "Iteration: 18879 epochs:203, Training: RAE:0.08687683194875717, Loss: 38.60683822631836, Ranking:49.76307678222656, Reg:3.2596843242645264, Gen:36.0153694152832, Disc:1.8031451531896892e-07, Recon_One:0.0, T_Reg:2.5914673805236816,T_MSE:131.607177734375,  CI:0.9119727399452734 Validation RAE:0.07262735402709293 Loss:36.7389470976085, Ranking:47.26645803696009, Reg:3.2812878342290155, Gen:34.364661631382035, Disc:1.87760046561269e-07, Recon_One:0.0, T_Reg:2.3742850488374363, T_MSE:111.59299397537139, CI:0.9246407303122101, *\n",
      "it:18900, trainCI:0.9188298095038727, train_ranking:49.38888168334961, train_RAE:0.08440175652503967,  train_Gen:36.07145690917969, train_Disc:1.8081718167195504e-07, train_reg:3.260047197341919, train_t_reg:2.6348938941955566, train_t_mse:119.62237548828125, train_layer_one_recon:0.0\n",
      "Iteration: 18972 epochs:204, Training: RAE:0.07170654088258743, Loss: 38.15617370605469, Ranking:46.996036529541016, Reg:3.2602908611297607, Gen:35.888084411621094, Disc:2.46767939415804e-07, Recon_One:0.0, T_Reg:2.268089771270752,T_MSE:146.2639923095703,  CI:0.9457432247467835 Validation RAE:0.07246596615482483 Loss:36.9889527779155, Ranking:47.25279806255623, Reg:3.2818983909084123, Gen:34.549971343547654, Disc:1.662678406109968e-07, Recon_One:0.0, T_Reg:2.438981502193562, T_MSE:117.41858989548143, CI:0.9230711228448515, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:19000, trainCI:0.9204677130517224, train_ranking:48.66646957397461, train_RAE:0.08413350582122803,  train_Gen:36.3116455078125, train_Disc:1.4689592831018672e-07, train_reg:3.2606165409088135, train_t_reg:2.3992180824279785, train_t_mse:124.24854278564453, train_layer_one_recon:0.0\n",
      "Iteration: 19065 epochs:205, Training: RAE:0.08835382014513016, Loss: 38.84483337402344, Ranking:51.738224029541016, Reg:3.2614848613739014, Gen:36.17334747314453, Disc:3.7681076037188177e-07, Recon_One:0.0, T_Reg:2.6714844703674316,T_MSE:123.03820037841797,  CI:0.9106821364272855 Validation RAE:0.0717097198330001 Loss:36.98522950077379, Ranking:47.2679239072486, Reg:3.2831003043716276, Gen:34.61049993261481, Disc:1.5657311742411536e-07, Recon_One:0.0, T_Reg:2.374729547289531, T_MSE:110.83049833796926, CI:0.9243390663497768, \n",
      "it:19100, trainCI:0.8985920513277491, train_ranking:43.155860900878906, train_RAE:0.09982132166624069,  train_Gen:36.326698303222656, train_Disc:1.5115259088815947e-07, train_reg:3.2615244388580322, train_t_reg:3.1489593982696533, train_t_mse:120.36724090576172, train_layer_one_recon:0.0\n",
      "Iteration: 19158 epochs:206, Training: RAE:0.09124929457902908, Loss: 39.19630813598633, Ranking:51.094974517822266, Reg:3.2622358798980713, Gen:36.60614013671875, Disc:2.0563422253871977e-07, Recon_One:0.0, T_Reg:2.59016752243042,T_MSE:134.43429565429688,  CI:0.9170913861835798 Validation RAE:0.0738296454230353 Loss:37.224704121833774, Ranking:47.30183209152956, Reg:3.2838563002600316, Gen:34.8133267947282, Disc:1.47853488373246e-07, Recon_One:0.0, T_Reg:2.4113774366701963, T_MSE:106.60561207042302, CI:0.9229330310154975, \n",
      "it:19200, trainCI:0.9127734126141431, train_ranking:48.469444274902344, train_RAE:0.0808858647942543,  train_Gen:36.73076629638672, train_Disc:1.066758983370164e-07, train_reg:3.2623560428619385, train_t_reg:2.8709957599639893, train_t_mse:145.08078002929688, train_layer_one_recon:0.0\n",
      "Iteration: 19251 epochs:207, Training: RAE:0.08488164097070694, Loss: 38.852848052978516, Ranking:48.461273193359375, Reg:3.2627928256988525, Gen:36.440128326416016, Disc:1.8679685354072717e-07, Recon_One:0.0, T_Reg:2.412720203399658,T_MSE:126.69401550292969,  CI:0.9311114654760007 Validation RAE:0.0733138954019314 Loss:37.280506197476335, Ranking:47.293713040034056, Reg:3.2844169372109246, Gen:34.847456195197346, Disc:1.4390630699222638e-07, Recon_One:0.0, T_Reg:2.4330497988018376, T_MSE:106.45588794558945, CI:0.9235765773423742, \n",
      "it:19300, trainCI:0.8787765159631455, train_ranking:48.13005447387695, train_RAE:0.09751848131418228,  train_Gen:36.85121154785156, train_Disc:1.9693808894771792e-07, train_reg:3.263237476348877, train_t_reg:3.123178482055664, train_t_mse:109.77532196044922, train_layer_one_recon:0.0\n",
      "Iteration: 19344 epochs:208, Training: RAE:0.08634039759635925, Loss: 38.798728942871094, Ranking:57.88972473144531, Reg:3.2636306285858154, Gen:36.735103607177734, Disc:1.2792864367838774e-07, Recon_One:0.0, T_Reg:2.0636239051818848,T_MSE:82.68112182617188,  CI:0.9311965243605089 Validation RAE:0.07186055086050926 Loss:37.39424955104013, Ranking:47.25667677537432, Reg:3.2852602926242107, Gen:34.983356395214365, Disc:1.399736924925247e-07, Recon_One:0.0, T_Reg:2.4108923523518775, T_MSE:113.68655092316418, CI:0.9236921468666025, \n",
      "it:19400, trainCI:0.9205133622055561, train_ranking:48.95042037963867, train_RAE:0.09760481864213943,  train_Gen:37.19363021850586, train_Disc:9.809868117827136e-08, train_reg:3.264040946960449, train_t_reg:2.855976104736328, train_t_mse:110.81185150146484, train_layer_one_recon:0.0\n",
      "Iteration: 19437 epochs:209, Training: RAE:0.06303846836090088, Loss: 39.24269485473633, Ranking:44.22262954711914, Reg:3.2645375728607178, Gen:37.029991149902344, Disc:1.4105020795796008e-07, Recon_One:0.0, T_Reg:2.2127022743225098,T_MSE:134.5869903564453,  CI:0.9264798941494564 Validation RAE:0.07305379257740878 Loss:37.50054484771999, Ranking:47.28523636961395, Reg:3.2861732476589696, Gen:35.06954038562038, Disc:1.263925973927649e-07, Recon_One:0.0, T_Reg:2.43100421688356, T_MSE:108.31584026474528, CI:0.9238706646768158, \n",
      "it:19500, trainCI:0.9236221685756845, train_ranking:50.18225860595703, train_RAE:0.08346375823020935,  train_Gen:37.068111419677734, train_Disc:9.340452322703641e-08, train_reg:3.2655022144317627, train_t_reg:2.755763292312622, train_t_mse:129.2621612548828, train_layer_one_recon:0.0\n",
      "Iteration: 19530 epochs:210, Training: RAE:0.08961571753025055, Loss: 39.13414764404297, Ranking:52.30335235595703, Reg:3.2656619548797607, Gen:36.812660217285156, Disc:1.303947954056639e-07, Recon_One:0.0, T_Reg:2.321488857269287,T_MSE:84.59076690673828,  CI:0.906863707776905 Validation RAE:0.07204608077539032 Loss:37.64110060502578, Ranking:47.27245074175918, Reg:3.287305081503323, Gen:35.25731402873337, Disc:1.1833546041412838e-07, Recon_One:0.0, T_Reg:2.383786618031307, T_MSE:110.05321110101346, CI:0.9238998295051123, \n",
      "it:19600, trainCI:0.9123241350160014, train_ranking:42.157379150390625, train_RAE:0.07663895934820175,  train_Gen:37.362998962402344, train_Disc:9.507272125119925e-08, train_reg:3.2659332752227783, train_t_reg:3.2693557739257812, train_t_mse:159.123779296875, train_layer_one_recon:0.0\n",
      "Iteration: 19623 epochs:211, Training: RAE:0.09116364270448685, Loss: 40.10809326171875, Ranking:44.90092086791992, Reg:3.2660608291625977, Gen:37.07872009277344, Disc:7.675106417082134e-08, Recon_One:0.0, T_Reg:3.029374599456787,T_MSE:139.77320861816406,  CI:0.9193437750085743 Validation RAE:0.07318921656914618 Loss:37.77180881936714, Ranking:47.27712332852053, Reg:3.2877065993196086, Gen:35.323906111779834, Disc:1.1169937554340104e-07, Recon_One:0.0, T_Reg:2.447902671065765, T_MSE:108.42047301742365, CI:0.9239348065411832, \n",
      "it:19700, trainCI:0.9098004727092838, train_ranking:46.94814682006836, train_RAE:0.08399609476327896,  train_Gen:37.411258697509766, train_Disc:1.1311642822420254e-07, train_reg:3.2665936946868896, train_t_reg:2.5164480209350586, train_t_mse:108.49922943115234, train_layer_one_recon:0.0\n",
      "Iteration: 19716 epochs:212, Training: RAE:0.08891037851572037, Loss: 40.17720031738281, Ranking:41.35228729248047, Reg:3.2668893337249756, Gen:37.286155700683594, Disc:6.529751317430055e-08, Recon_One:0.0, T_Reg:2.891045331954956,T_MSE:154.5569305419922,  CI:0.901342240366178 Validation RAE:0.07332324948149263 Loss:37.91352191298727, Ranking:47.262946960403426, Reg:3.2885405947838007, Gen:35.5152602849848, Disc:1.0072536129887114e-07, Recon_One:0.0, T_Reg:2.3982614245253147, T_MSE:112.81521525161779, CI:0.9230304373904308, \n",
      "it:19800, trainCI:0.9395976883751945, train_ranking:45.904151916503906, train_RAE:0.07003206759691238,  train_Gen:37.538917541503906, train_Disc:1.8384004363269923e-07, train_reg:3.267163038253784, train_t_reg:1.992642879486084, train_t_mse:91.06098937988281, train_layer_one_recon:0.0\n",
      "Iteration: 19809 epochs:213, Training: RAE:0.08775492757558823, Loss: 40.15376281738281, Ranking:45.76022720336914, Reg:3.26715350151062, Gen:37.382537841796875, Disc:7.794238854330615e-08, Recon_One:0.0, T_Reg:2.771226167678833,T_MSE:132.59584045410156,  CI:0.9210144117975645 Validation RAE:0.07207022982883471 Loss:37.987517976635644, Ranking:47.27553407803347, Reg:3.2888065133375632, Gen:35.59835192351337, Disc:9.285368508151202e-08, Recon_One:0.0, T_Reg:2.389165813123582, T_MSE:108.13598365683518, CI:0.9243999907419833, \n",
      "it:19900, trainCI:0.8989673289449845, train_ranking:42.07781982421875, train_RAE:0.0886196717619896,  train_Gen:37.16944885253906, train_Disc:1.376425018406735e-07, train_reg:3.2678494453430176, train_t_reg:2.721057891845703, train_t_mse:110.7772445678711, train_layer_one_recon:0.0\n",
      "Iteration: 19902 epochs:214, Training: RAE:0.113651342689991, Loss: 40.33237075805664, Ranking:55.329566955566406, Reg:3.267879009246826, Gen:37.26929473876953, Disc:1.2312622743593238e-07, Recon_One:0.0, T_Reg:3.0630767345428467,T_MSE:156.56976318359375,  CI:0.9267745253904424 Validation RAE:0.07335920526420264 Loss:38.09299168474036, Ranking:47.263654518294395, Reg:3.289536829365631, Gen:35.730462231098805, Disc:8.56838456965895e-08, Recon_One:0.0, T_Reg:2.3625296988576086, T_MSE:111.76386736952932, CI:0.92385270910637, *\n",
      "Iteration: 19995 epochs:215, Training: RAE:0.08519662916660309, Loss: 40.239131927490234, Ranking:48.53839874267578, Reg:3.269038677215576, Gen:37.63031768798828, Disc:8.93644411803507e-08, Recon_One:0.0, T_Reg:2.6088151931762695,T_MSE:110.6922836303711,  CI:0.9137567253929739 Validation RAE:0.07303265915973732 Loss:38.272376976952906, Ranking:47.23416064044036, Reg:3.2907041830168047, Gen:35.80759104988314, Disc:9.060578660014835e-08, Recon_One:0.0, T_Reg:2.4647859062003064, T_MSE:117.48403282303862, CI:0.9237033561244531, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:20000, trainCI:0.9207453652957156, train_ranking:54.365482330322266, train_RAE:0.11328292638063431,  train_Gen:37.292930603027344, train_Disc:1.1952872114306956e-07, train_reg:3.2690553665161133, train_t_reg:3.2941675186157227, train_t_mse:155.18983459472656, train_layer_one_recon:0.0\n",
      "Iteration: 20088 epochs:216, Training: RAE:0.11378218233585358, Loss: 40.4475212097168, Ranking:57.878089904785156, Reg:3.269824981689453, Gen:37.69541931152344, Disc:7.131744439448084e-08, Recon_One:0.0, T_Reg:2.752102851867676,T_MSE:104.5018081665039,  CI:0.8868715706829639 Validation RAE:0.0715909131421914 Loss:38.315734181148315, Ranking:47.253865242839176, Reg:3.2914956987120294, Gen:35.94083114610667, Disc:8.165161962700949e-08, Recon_One:0.0, T_Reg:2.3749030037374665, T_MSE:112.61352552418948, CI:0.9240221453419358, \n",
      "it:20100, trainCI:0.8974759754544402, train_ranking:44.11760330200195, train_RAE:0.09734556823968887,  train_Gen:37.19091033935547, train_Disc:9.942716872046731e-08, train_reg:3.2701570987701416, train_t_reg:3.555549383163452, train_t_mse:158.9110565185547, train_layer_one_recon:0.0\n",
      "Iteration: 20181 epochs:217, Training: RAE:0.0981409102678299, Loss: 40.47087478637695, Ranking:56.236602783203125, Reg:3.2707409858703613, Gen:37.71788787841797, Disc:9.307429138516454e-08, Recon_One:0.0, T_Reg:2.7529852390289307,T_MSE:119.25373077392578,  CI:0.9115768187876281 Validation RAE:0.07318351056757041 Loss:38.37026756108217, Ranking:47.27808666241173, Reg:3.2924177736971876, Gen:35.94561993397518, Disc:8.022788625761011e-08, Recon_One:0.0, T_Reg:2.424647658411169, T_MSE:107.60237348069246, CI:0.9243753407536545, \n",
      "it:20200, trainCI:0.9179635522129014, train_ranking:44.393436431884766, train_RAE:0.09266964346170425,  train_Gen:38.117774963378906, train_Disc:6.658691376060233e-08, train_reg:3.2708873748779297, train_t_reg:2.6327342987060547, train_t_mse:107.39996337890625, train_layer_one_recon:0.0\n",
      "Iteration: 20274 epochs:218, Training: RAE:0.08542319387197495, Loss: 40.03623962402344, Ranking:52.45491027832031, Reg:3.2716450691223145, Gen:37.54700469970703, Disc:1.0656461313374166e-07, Recon_One:0.0, T_Reg:2.489234209060669,T_MSE:115.80655670166016,  CI:0.9116841178197476 Validation RAE:0.07138045988459878 Loss:38.4227973066957, Ranking:47.241781496384505, Reg:3.293327848747609, Gen:36.0666772790651, Disc:7.72017719978481e-08, Recon_One:0.0, T_Reg:2.356120220673029, T_MSE:116.03572927028728, CI:0.9241165937182696, *\n",
      "it:20300, trainCI:0.904168357585947, train_ranking:44.32825469970703, train_RAE:0.09813149273395538,  train_Gen:37.89580535888672, train_Disc:1.0714332177030883e-07, train_reg:3.271702289581299, train_t_reg:3.246220588684082, train_t_mse:116.64090728759766, train_layer_one_recon:0.0\n",
      "Iteration: 20367 epochs:219, Training: RAE:0.09100259840488434, Loss: 41.07664489746094, Ranking:46.34925842285156, Reg:3.272505760192871, Gen:38.09630584716797, Disc:1.0481911516535547e-07, Recon_One:0.0, T_Reg:2.9803409576416016,T_MSE:103.70751190185547,  CI:0.8949764085484319 Validation RAE:0.07174352345350192 Loss:38.54115815166833, Ranking:47.25775647732829, Reg:3.29419424403559, Gen:36.184207519859434, Disc:6.993360818539332e-08, Recon_One:0.0, T_Reg:2.356951117023641, T_MSE:112.7686423153464, CI:0.9246075176963564, \n",
      "it:20400, trainCI:0.8989867818752251, train_ranking:49.97526168823242, train_RAE:0.08262193202972412,  train_Gen:37.871482849121094, train_Disc:1.4328848862987797e-07, train_reg:3.2727084159851074, train_t_reg:3.9919252395629883, train_t_mse:227.47543334960938, train_layer_one_recon:0.0\n",
      "Iteration: 20460 epochs:220, Training: RAE:0.080401711165905, Loss: 41.08226013183594, Ranking:43.84514617919922, Reg:3.273434638977051, Gen:38.17382049560547, Disc:1.039741803765537e-07, Recon_One:0.0, T_Reg:2.9084415435791016,T_MSE:77.87020111083984,  CI:0.9060108651206262 Validation RAE:0.07336213465044465 Loss:38.586562064732405, Ranking:47.28802319271826, Reg:3.2951292789502635, Gen:36.175335999412866, Disc:7.464078508144896e-08, Recon_One:0.0, T_Reg:2.4112262114057006, T_MSE:107.93655016757077, CI:0.9238440945841329, \n",
      "it:20500, trainCI:0.8959265763979378, train_ranking:45.21244812011719, train_RAE:0.07489214837551117,  train_Gen:38.056922912597656, train_Disc:5.493719612559289e-08, train_reg:3.273947238922119, train_t_reg:2.5549726486206055, train_t_mse:108.56787872314453, train_layer_one_recon:0.0\n",
      "Iteration: 20553 epochs:221, Training: RAE:0.08758942037820816, Loss: 41.25452423095703, Ranking:46.73328399658203, Reg:3.2745046615600586, Gen:38.20273208618164, Disc:8.880149948709004e-08, Recon_One:0.0, T_Reg:3.0517935752868652,T_MSE:137.23162841796875,  CI:0.914538364365354 Validation RAE:0.07195481523914278 Loss:38.78789984972697, Ranking:47.279938033212346, Reg:3.2962063930922185, Gen:36.37196146221001, Disc:6.527098463788516e-08, Recon_One:0.0, T_Reg:2.415938450125317, T_MSE:109.82849619098495, CI:0.9237977007113624, \n",
      "it:20600, trainCI:0.9338161335747335, train_ranking:51.075714111328125, train_RAE:0.0859135314822197,  train_Gen:38.22734832763672, train_Disc:7.002570612257841e-08, train_reg:3.274679660797119, train_t_reg:2.4715805053710938, train_t_mse:109.5344009399414, train_layer_one_recon:0.0\n",
      "Iteration: 20646 epochs:222, Training: RAE:0.08967380225658417, Loss: 40.47395324707031, Ranking:50.089012145996094, Reg:3.2752983570098877, Gen:38.09541320800781, Disc:6.815059805376222e-08, Recon_One:0.0, T_Reg:2.3785407543182373,T_MSE:123.88860321044922,  CI:0.928337092474882 Validation RAE:0.07336907097141608 Loss:38.88985329871627, Ranking:47.28464651543065, Reg:3.2970053487469797, Gen:36.45263007391657, Disc:6.368464606900983e-08, Recon_One:0.0, T_Reg:2.437223668275542, T_MSE:108.3316516291876, CI:0.9235400434649352, \n",
      "it:20700, trainCI:0.9023799030409873, train_ranking:46.28860092163086, train_RAE:0.08302389085292816,  train_Gen:38.20049285888672, train_Disc:6.466321877951486e-08, train_reg:3.275855541229248, train_t_reg:3.2107882499694824, train_t_mse:132.46441650390625, train_layer_one_recon:0.0\n",
      "Iteration: 20739 epochs:223, Training: RAE:0.10234271734952927, Loss: 41.307472229003906, Ranking:46.55188751220703, Reg:3.275946617126465, Gen:38.475120544433594, Disc:4.944347509194813e-08, Recon_One:0.0, T_Reg:2.8323516845703125,T_MSE:101.36318969726562,  CI:0.9068329899203653 Validation RAE:0.07342202622688933 Loss:39.034449882741065, Ranking:47.27492903088933, Reg:3.2976579051979544, Gen:36.68794265848198, Disc:5.5972569904941274e-08, Recon_One:0.0, T_Reg:2.346507495561957, T_MSE:109.62174336761478, CI:0.922709728068594, *\n",
      "it:20800, trainCI:0.918685853348852, train_ranking:48.53703308105469, train_RAE:0.08462347090244293,  train_Gen:38.606689453125, train_Disc:4.8648743700141495e-08, train_reg:3.276174783706665, train_t_reg:2.654616355895996, train_t_mse:111.90282440185547, train_layer_one_recon:0.0\n",
      "Iteration: 20832 epochs:224, Training: RAE:0.08775747567415237, Loss: 41.050472259521484, Ranking:45.78911590576172, Reg:3.2764854431152344, Gen:38.369415283203125, Disc:5.0919400251814295e-08, Recon_One:0.0, T_Reg:2.681058168411255,T_MSE:102.181396484375,  CI:0.9189627228525121 Validation RAE:0.07037704392878193 Loss:39.09405971506588, Ranking:47.23834137596368, Reg:3.2982003022480475, Gen:36.700748321010394, Disc:5.548285640128555e-08, Recon_One:0.0, T_Reg:2.393311602750003, T_MSE:116.28720850084102, CI:0.9233220856733957, \n",
      "it:20900, trainCI:0.9329941188131897, train_ranking:38.398990631103516, train_RAE:0.06142736226320267,  train_Gen:38.53981018066406, train_Disc:8.561579534216435e-08, train_reg:3.2776689529418945, train_t_reg:2.044706106185913, train_t_mse:133.69317626953125, train_layer_one_recon:0.0\n",
      "Iteration: 20925 epochs:225, Training: RAE:0.08627638965845108, Loss: 41.745216369628906, Ranking:45.92519760131836, Reg:3.2777462005615234, Gen:39.033023834228516, Disc:4.498900452176713e-08, Recon_One:0.0, T_Reg:2.712191581726074,T_MSE:114.5927505493164,  CI:0.9022670025188917 Validation RAE:0.07227802614435577 Loss:39.25037925446408, Ranking:47.28601321408461, Reg:3.2994694153457877, Gen:36.88391632656313, Disc:5.1932333636629614e-08, Recon_One:0.0, T_Reg:2.3664625470334477, T_MSE:107.89326124822138, CI:0.9237728950388966, \n",
      "it:21000, trainCI:0.9100332594235033, train_ranking:46.19306564331055, train_RAE:0.08770706504583359,  train_Gen:38.53498077392578, train_Disc:5.277428272165707e-08, train_reg:3.27820086479187, train_t_reg:2.5985662937164307, train_t_mse:121.70880126953125, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21018 epochs:226, Training: RAE:0.07263365387916565, Loss: 41.17499542236328, Ranking:47.1842155456543, Reg:3.2782859802246094, Gen:38.898590087890625, Disc:4.259702990339065e-08, Recon_One:0.0, T_Reg:2.276406764984131,T_MSE:101.13652801513672,  CI:0.9313890853691713 Validation RAE:0.07150727082535344 Loss:39.378328193377385, Ranking:47.256886638580774, Reg:3.3000127723906596, Gen:36.984922970266986, Disc:5.016188877579032e-08, Recon_One:0.0, T_Reg:2.393405139632593, T_MSE:115.28051356546608, CI:0.9240801117355428, \n",
      "it:21100, trainCI:0.9033331484665299, train_ranking:46.58602523803711, train_RAE:0.09246187657117844,  train_Gen:39.207828521728516, train_Disc:7.682798752739473e-08, train_reg:3.279153347015381, train_t_reg:3.29672908782959, train_t_mse:120.56658935546875, train_layer_one_recon:0.0\n",
      "Iteration: 21111 epochs:227, Training: RAE:0.08210743963718414, Loss: 41.409507751464844, Ranking:51.59178924560547, Reg:3.279158115386963, Gen:38.817047119140625, Disc:3.7992158752331306e-08, Recon_One:0.0, T_Reg:2.592458724975586,T_MSE:123.94493865966797,  CI:0.9173149810492719 Validation RAE:0.07321433067168984 Loss:39.519682332428005, Ranking:47.2816306292243, Reg:3.3008906876159876, Gen:37.041397376166024, Disc:4.6913117548900596e-08, Recon_One:0.0, T_Reg:2.478284257135347, T_MSE:111.20941278501289, CI:0.9241617421179457, \n",
      "it:21200, trainCI:0.8931314957071849, train_ranking:45.465660095214844, train_RAE:0.10412931442260742,  train_Gen:39.34899139404297, train_Disc:3.999593900516629e-08, train_reg:3.2798991203308105, train_t_reg:3.5058157444000244, train_t_mse:151.1309814453125, train_layer_one_recon:0.0\n",
      "Iteration: 21204 epochs:228, Training: RAE:0.08765357732772827, Loss: 41.8114013671875, Ranking:45.582950592041016, Reg:3.279836893081665, Gen:38.81913757324219, Disc:6.975896837957407e-08, Recon_One:0.0, T_Reg:2.9922657012939453,T_MSE:71.94513702392578,  CI:0.8960521143370584 Validation RAE:0.07156102303301407 Loss:39.600569822944166, Ranking:47.28110839206457, Reg:3.3015739638998878, Gen:37.210181988640635, Disc:4.1232659680265755e-08, Recon_One:0.0, T_Reg:2.390387698652089, T_MSE:109.2032100195227, CI:0.9239725858917167, \n",
      "Iteration: 21297 epochs:229, Training: RAE:0.08166329562664032, Loss: 41.769989013671875, Ranking:43.780494689941406, Reg:3.2803659439086914, Gen:39.24810791015625, Disc:4.524557795093642e-08, Recon_One:0.0, T_Reg:2.521879196166992,T_MSE:97.95916748046875,  CI:0.9290972263117602 Validation RAE:0.07268152851506562 Loss:39.762576705323944, Ranking:47.2968200840055, Reg:3.302106521003497, Gen:37.3398709389602, Disc:3.938804055953927e-08, Recon_One:0.0, T_Reg:2.4227057663637415, T_MSE:105.10019867870679, CI:0.9247608146764058, \n",
      "it:21300, trainCI:0.911830599118306, train_ranking:35.34077835083008, train_RAE:0.07519593834877014,  train_Gen:39.05809783935547, train_Disc:5.639630984433097e-08, train_reg:3.280459403991699, train_t_reg:3.116596221923828, train_t_mse:199.10997009277344, train_layer_one_recon:0.0\n",
      "Iteration: 21390 epochs:230, Training: RAE:0.07525408267974854, Loss: 42.16961669921875, Ranking:46.2519645690918, Reg:3.2810781002044678, Gen:39.320640563964844, Disc:4.73821870627944e-08, Recon_One:0.0, T_Reg:2.8489742279052734,T_MSE:132.7734832763672,  CI:0.9161918459921448 Validation RAE:0.0700625610195787 Loss:39.81917432446591, Ranking:47.23670070314759, Reg:3.30282339710466, Gen:37.43371468596836, Disc:3.9176238316642015e-08, Recon_One:0.0, T_Reg:2.3854596437149174, T_MSE:115.66097969798366, CI:0.9250281243393155, \n",
      "it:21400, trainCI:0.8750415420405451, train_ranking:46.81531524658203, train_RAE:0.11707022786140442,  train_Gen:38.83510971069336, train_Disc:6.309578282071016e-08, train_reg:3.2812423706054688, train_t_reg:4.796744346618652, train_t_mse:112.783203125, train_layer_one_recon:0.0\n",
      "Iteration: 21483 epochs:231, Training: RAE:0.06642520427703857, Loss: 41.817039489746094, Ranking:39.130672454833984, Reg:3.2823567390441895, Gen:39.33289337158203, Disc:4.261686825657307e-08, Recon_One:0.0, T_Reg:2.4841458797454834,T_MSE:124.78511810302734,  CI:0.9281577406130019 Validation RAE:0.07126851043910462 Loss:39.932975110760836, Ranking:47.26495810772637, Reg:3.304110510104505, Gen:37.53196389075591, Disc:3.726858793785116e-08, Recon_One:0.0, T_Reg:2.4010113139174587, T_MSE:111.30045434900026, CI:0.9245748759223377, \n",
      "it:21500, trainCI:0.9151845946277444, train_ranking:41.940277099609375, train_RAE:0.09452996402978897,  train_Gen:39.739341735839844, train_Disc:4.185770308140491e-08, train_reg:3.2825100421905518, train_t_reg:2.759124279022217, train_t_mse:135.65664672851562, train_layer_one_recon:0.0\n",
      "Iteration: 21576 epochs:232, Training: RAE:0.08812586963176727, Loss: 43.13418197631836, Ranking:40.246089935302734, Reg:3.2831242084503174, Gen:39.922080993652344, Disc:6.834315513515321e-08, Recon_One:0.0, T_Reg:3.2121024131774902,T_MSE:141.21780395507812,  CI:0.8952435603162459 Validation RAE:0.07059377188050957 Loss:40.03446175185415, Ranking:47.260416247210564, Reg:3.304883065902845, Gen:37.657496814982984, Disc:3.572915123141496e-08, Recon_One:0.0, T_Reg:2.3769649107843485, T_MSE:113.36113139213704, CI:0.9242088106219758, \n",
      "it:21600, trainCI:0.9417357977975064, train_ranking:53.19440841674805, train_RAE:0.0843513086438179,  train_Gen:39.70155334472656, train_Disc:6.712885181059391e-08, train_reg:3.2834832668304443, train_t_reg:2.442673921585083, train_t_mse:135.66726684570312, train_layer_one_recon:0.0\n",
      "Iteration: 21669 epochs:233, Training: RAE:0.09518545120954514, Loss: 42.68941116333008, Ranking:44.13093948364258, Reg:3.2841577529907227, Gen:39.788055419921875, Disc:5.644196221510356e-08, Recon_One:0.0, T_Reg:2.9013545513153076,T_MSE:114.1906509399414,  CI:0.9337363540321634 Validation RAE:0.06971475399813533 Loss:40.198850256063736, Ranking:47.22698822727468, Reg:3.3059234602445065, Gen:37.874849817224245, Disc:3.168941766076033e-08, Recon_One:0.0, T_Reg:2.3240007988375337, T_MSE:116.41251670281201, CI:0.9252299947700509, *\n",
      "it:21700, trainCI:0.9136363636363637, train_ranking:45.68082046508789, train_RAE:0.08784235268831253,  train_Gen:39.50349807739258, train_Disc:1.7132165908151364e-07, train_reg:3.284609079360962, train_t_reg:2.606691837310791, train_t_mse:109.52596282958984, train_layer_one_recon:0.0\n",
      "Iteration: 21762 epochs:234, Training: RAE:0.07231580466032028, Loss: 42.86094665527344, Ranking:42.286781311035156, Reg:3.2849180698394775, Gen:40.338680267333984, Disc:3.302382012293492e-08, Recon_One:0.0, T_Reg:2.522266149520874,T_MSE:72.40068054199219,  CI:0.9122167547536602 Validation RAE:0.07024840528057623 Loss:40.35054746234031, Ranking:47.254382805241725, Reg:3.306688816082005, Gen:37.970807389257786, Disc:3.115558283622186e-08, Recon_One:0.0, T_Reg:2.379739587867768, T_MSE:113.36054003535322, CI:0.9245589442456704, \n",
      "it:21800, trainCI:0.9236178000385282, train_ranking:53.61515808105469, train_RAE:0.08213486522436142,  train_Gen:39.779090881347656, train_Disc:4.528062191866411e-08, train_reg:3.285512685775757, train_t_reg:2.509371757507324, train_t_mse:129.24893188476562, train_layer_one_recon:0.0\n",
      "Iteration: 21855 epochs:235, Training: RAE:0.07991921901702881, Loss: 43.58934783935547, Ranking:40.290157318115234, Reg:3.285724639892578, Gen:40.09449005126953, Disc:5.4390902448631095e-08, Recon_One:0.0, T_Reg:3.494859218597412,T_MSE:150.08335876464844,  CI:0.8932495078427637 Validation RAE:0.07118706756682638 Loss:40.40819256100279, Ranking:47.26496311639478, Reg:3.3075007316662814, Gen:38.01834249073108, Disc:2.9928821817858375e-08, Recon_One:0.0, T_Reg:2.389850080706439, T_MSE:110.22738086680882, CI:0.9249370491192793, \n",
      "it:21900, trainCI:0.9287077946871761, train_ranking:47.11494445800781, train_RAE:0.07556360960006714,  train_Gen:39.99200439453125, train_Disc:5.392292834471846e-08, train_reg:3.2858831882476807, train_t_reg:2.6629745960235596, train_t_mse:159.1194610595703, train_layer_one_recon:0.0\n",
      "Iteration: 21948 epochs:236, Training: RAE:0.0839603841304779, Loss: 43.097347259521484, Ranking:44.041141510009766, Reg:3.285886764526367, Gen:40.07843017578125, Disc:2.7457440765488172e-08, Recon_One:0.0, T_Reg:3.018918514251709,T_MSE:166.38470458984375,  CI:0.9152314787786794 Validation RAE:0.0705357856197895 Loss:40.41758364731928, Ranking:47.24949300922691, Reg:3.307663930778699, Gen:38.026471392607796, Disc:3.072043457433573e-08, Recon_One:0.0, T_Reg:2.391112072103781, T_MSE:116.75732412143873, CI:0.9239946930391443, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:22000, trainCI:0.9010322709961917, train_ranking:51.16828918457031, train_RAE:0.09228312969207764,  train_Gen:39.958683013916016, train_Disc:4.35437073065259e-08, train_reg:3.2862658500671387, train_t_reg:2.908844232559204, train_t_mse:133.51048278808594, train_layer_one_recon:0.0\n",
      "Iteration: 22041 epochs:237, Training: RAE:0.08700244873762131, Loss: 43.17018508911133, Ranking:37.628173828125, Reg:3.2862470149993896, Gen:40.11613082885742, Disc:3.445071428131996e-08, Recon_One:0.0, T_Reg:3.05405330657959,T_MSE:110.33378601074219,  CI:0.9073300937649716 Validation RAE:0.07195628523114801 Loss:41.24199560884984, Ranking:47.271689424160584, Reg:3.3080265688064383, Gen:38.91239497785913, Disc:5.577035230890454e-09, Recon_One:0.0, T_Reg:2.329600474469823, T_MSE:109.07441211131359, CI:0.9234113964732146, \n",
      "it:22100, trainCI:0.8872452175589072, train_ranking:53.32490921020508, train_RAE:0.09208961576223373,  train_Gen:40.11111068725586, train_Disc:2.497202622464556e-08, train_reg:3.287078380584717, train_t_reg:3.1889917850494385, train_t_mse:128.78846740722656, train_layer_one_recon:0.0\n",
      "Iteration: 22134 epochs:238, Training: RAE:0.0948880985379219, Loss: 43.33829116821289, Ranking:52.606101989746094, Reg:3.2873668670654297, Gen:40.23849868774414, Disc:5.311299844379391e-08, Recon_One:0.0, T_Reg:3.0997931957244873,T_MSE:115.94419860839844,  CI:0.8846851261945602 Validation RAE:0.07061904869955958 Loss:40.62442261978613, Ranking:47.24224863819171, Reg:3.3091538426755918, Gen:38.25045670660433, Disc:2.667169411704919e-08, Recon_One:0.0, T_Reg:2.373965944485976, T_MSE:116.32753763107027, CI:0.9248646559956608, \n",
      "it:22200, trainCI:0.8959164707811731, train_ranking:47.07919692993164, train_RAE:0.09122191369533539,  train_Gen:40.42888259887695, train_Disc:2.643490404352633e-08, train_reg:3.288201332092285, train_t_reg:3.2863833904266357, train_t_mse:143.6234893798828, train_layer_one_recon:0.0\n",
      "Iteration: 22227 epochs:239, Training: RAE:0.09411479532718658, Loss: 42.97453689575195, Ranking:56.63892364501953, Reg:3.2881150245666504, Gen:40.384185791015625, Disc:2.6546278064643047e-08, Recon_One:0.0, T_Reg:2.5903520584106445,T_MSE:97.1177749633789,  CI:0.9236909323116219 Validation RAE:0.0742661867444927 Loss:40.862978984970624, Ranking:47.30925660767197, Reg:3.3099069585796594, Gen:38.41392945927263, Disc:2.5251321265160642e-08, Recon_One:0.0, T_Reg:2.4490496456973387, T_MSE:103.52487429329882, CI:0.9242395841863527, \n",
      "it:22300, trainCI:0.9318363672734546, train_ranking:51.25188446044922, train_RAE:0.09160995483398438,  train_Gen:40.45428466796875, train_Disc:2.429598922049081e-08, train_reg:3.288635015487671, train_t_reg:2.4692542552948, train_t_mse:87.06861877441406, train_layer_one_recon:0.0\n",
      "Iteration: 22320 epochs:240, Training: RAE:0.07953760772943497, Loss: 42.98448181152344, Ranking:42.971466064453125, Reg:3.288900375366211, Gen:40.5057373046875, Disc:2.1602605926318574e-08, Recon_One:0.0, T_Reg:2.4787449836730957,T_MSE:104.9818344116211,  CI:0.9597776715276117 Validation RAE:0.070919977062916 Loss:40.86240849763852, Ranking:47.27180612613458, Reg:3.310697514280105, Gen:38.51399297071454, Disc:2.344156903935001e-08, Recon_One:0.0, T_Reg:2.3484154851850723, T_MSE:108.11281689587453, CI:0.925230773190735, \n",
      "it:22400, trainCI:0.9427326170687209, train_ranking:51.103179931640625, train_RAE:0.0863901898264885,  train_Gen:40.49815368652344, train_Disc:2.5049729401871446e-08, train_reg:3.2895185947418213, train_t_reg:2.7451562881469727, train_t_mse:165.0568084716797, train_layer_one_recon:0.0\n",
      "Iteration: 22413 epochs:241, Training: RAE:0.10241980105638504, Loss: 43.73658752441406, Ranking:56.558837890625, Reg:3.2897789478302, Gen:40.70075988769531, Disc:1.9770773462823854e-08, Recon_One:0.0, T_Reg:3.0358293056488037,T_MSE:132.7246551513672,  CI:0.9043502127075614 Validation RAE:0.0702038379142668 Loss:42.54196544311875, Ranking:47.23478488748008, Reg:3.31158190947019, Gen:40.16809653114852, Disc:5.743636265957457e-11, Recon_One:0.0, T_Reg:2.3738691519689183, T_MSE:116.6189255976179, CI:0.9243987452688888, \n",
      "it:22500, trainCI:0.9181359487499291, train_ranking:45.342384338378906, train_RAE:0.08893182873725891,  train_Gen:40.854347229003906, train_Disc:1.6646296785438608e-08, train_reg:3.290290355682373, train_t_reg:2.887240171432495, train_t_mse:119.29532623291016, train_layer_one_recon:0.0\n",
      "Iteration: 22506 epochs:242, Training: RAE:0.07206877321004868, Loss: 42.91133499145508, Ranking:39.73280715942383, Reg:3.290325403213501, Gen:40.47809982299805, Disc:2.4109475305067463e-08, Recon_One:0.0, T_Reg:2.4332351684570312,T_MSE:116.466796875,  CI:0.9141061004554494 Validation RAE:0.07228388084077501 Loss:42.10682785837475, Ranking:47.294088857120556, Reg:3.312131986478515, Gen:39.67260248857512, Disc:1.0745343746476005e-09, Recon_One:0.0, T_Reg:2.4342258289275622, T_MSE:108.29797901927762, CI:0.9243470062407543, \n",
      "Iteration: 22599 epochs:243, Training: RAE:0.08584096282720566, Loss: 43.64408493041992, Ranking:49.99781799316406, Reg:3.2915215492248535, Gen:41.14447784423828, Disc:2.836252832594255e-08, Recon_One:0.0, T_Reg:2.4996070861816406,T_MSE:91.99690246582031,  CI:0.9153850110591019 Validation RAE:0.07021334721037517 Loss:41.01680754661202, Ranking:47.259723214457985, Reg:3.3133360599299824, Gen:38.639715556518816, Disc:2.5789890046246284e-08, Recon_One:0.0, T_Reg:2.377091624877804, T_MSE:113.71386686503716, CI:0.9241116118258916, \n",
      "it:22600, trainCI:0.8701290830858736, train_ranking:42.07893753051758, train_RAE:0.07907623797655106,  train_Gen:40.65131378173828, train_Disc:2.5191148722569778e-08, train_reg:3.2915587425231934, train_t_reg:3.736313581466675, train_t_mse:99.09043884277344, train_layer_one_recon:0.0\n",
      "Iteration: 22692 epochs:244, Training: RAE:0.08630066365003586, Loss: 43.06001663208008, Ranking:42.871639251708984, Reg:3.2931299209594727, Gen:40.752159118652344, Disc:8.608637358520355e-08, Recon_One:0.0, T_Reg:2.3078575134277344,T_MSE:89.91866302490234,  CI:0.9231322700563617 Validation RAE:0.07024690936479894 Loss:41.386358621971034, Ranking:47.24774682046294, Reg:3.314955091124641, Gen:38.98096381537211, Disc:1.000037521843083e-08, Recon_One:0.0, T_Reg:2.405395057032343, T_MSE:122.38973970784087, CI:0.9243988490583134, \n",
      "it:22700, trainCI:0.9241258345592396, train_ranking:45.27014923095703, train_RAE:0.08948519080877304,  train_Gen:40.76969909667969, train_Disc:1.178204378504688e-08, train_reg:3.293355941772461, train_t_reg:2.8201239109039307, train_t_mse:104.78077697753906, train_layer_one_recon:0.0\n",
      "Iteration: 22785 epochs:245, Training: RAE:0.08936983346939087, Loss: 44.44145202636719, Ranking:45.30060577392578, Reg:3.2948110103607178, Gen:41.01777648925781, Disc:1.846909469804814e-08, Recon_One:0.0, T_Reg:3.423675060272217,T_MSE:136.2373504638672,  CI:0.8920802175390891 Validation RAE:0.07461098106492978 Loss:40.14278322186219, Ranking:47.29334289943842, Reg:3.3166473219211925, Gen:37.61098498446622, Disc:5.2658399625393554e-08, Recon_One:0.0, T_Reg:2.531798127831348, T_MSE:128.70426380710333, CI:0.9236529663588376, \n",
      "it:22800, trainCI:0.9083935519733185, train_ranking:46.070804595947266, train_RAE:0.09315848350524902,  train_Gen:40.4432373046875, train_Disc:5.9434551502590693e-08, train_reg:3.2952139377593994, train_t_reg:2.638230085372925, train_t_mse:123.43832397460938, train_layer_one_recon:0.0\n",
      "Iteration: 22878 epochs:246, Training: RAE:0.07274828106164932, Loss: 43.29927444458008, Ranking:45.44316482543945, Reg:3.296505928039551, Gen:40.49636459350586, Disc:1.97580209970738e-08, Recon_One:0.0, T_Reg:2.8029110431671143,T_MSE:113.53325653076172,  CI:0.8958439643930374 Validation RAE:0.07174721098779455 Loss:39.87766872633542, Ranking:47.246909705015725, Reg:3.3183534726420385, Gen:37.326640541350464, Disc:6.608318467487083e-08, Recon_One:0.0, T_Reg:2.5510284406357413, T_MSE:156.31141901105676, CI:0.9241023745671073, \n",
      "it:22900, trainCI:0.9278676158596955, train_ranking:55.1552619934082, train_RAE:0.10465605556964874,  train_Gen:40.863975524902344, train_Disc:1.7753670533693366e-08, train_reg:3.296534299850464, train_t_reg:2.4622561931610107, train_t_mse:117.67237854003906, train_layer_one_recon:0.0\n",
      "Iteration: 22971 epochs:247, Training: RAE:0.08815111219882965, Loss: 43.340110778808594, Ranking:50.087371826171875, Reg:3.297332286834717, Gen:40.46955490112305, Disc:2.4874797333040988e-08, Recon_One:0.0, T_Reg:2.8705556392669678,T_MSE:91.95147705078125,  CI:0.9034723290762682 Validation RAE:0.07332613288972382 Loss:40.53624818455328, Ranking:47.27159175512656, Reg:3.319185308117978, Gen:37.85008712755198, Disc:4.518723147874239e-08, Recon_One:0.0, T_Reg:2.6861609109151328, T_MSE:171.38577993473322, CI:0.9244888344893918, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:23000, trainCI:0.9305728013820656, train_ranking:47.661712646484375, train_RAE:0.08944831043481827,  train_Gen:40.99803161621094, train_Disc:6.930541474048368e-08, train_reg:3.297653913497925, train_t_reg:2.602867364883423, train_t_mse:130.32681274414062, train_layer_one_recon:0.0\n",
      "Iteration: 23064 epochs:248, Training: RAE:0.07315311580896378, Loss: 43.33488845825195, Ranking:45.853370666503906, Reg:3.298323392868042, Gen:40.91138458251953, Disc:2.0432505465350914e-08, Recon_One:0.0, T_Reg:2.4235033988952637,T_MSE:83.27129364013672,  CI:0.9297342657342658 Validation RAE:0.07082854766886398 Loss:40.474752254660196, Ranking:47.25378610587826, Reg:3.3201829826919766, Gen:37.93625776150889, Disc:4.1193828346496704e-08, Recon_One:0.0, T_Reg:2.5384944670644867, T_MSE:164.15536071235454, CI:0.9246178966388107, \n",
      "it:23100, trainCI:0.9292474087426769, train_ranking:45.5978889465332, train_RAE:0.09487665444612503,  train_Gen:40.96477508544922, train_Disc:1.5940334208153217e-07, train_reg:3.2983622550964355, train_t_reg:2.919443368911743, train_t_mse:125.91223907470703, train_layer_one_recon:0.0\n",
      "Iteration: 23157 epochs:249, Training: RAE:0.09292183071374893, Loss: 44.1244010925293, Ranking:50.727928161621094, Reg:3.2990336418151855, Gen:41.27350616455078, Disc:1.9559156072546102e-08, Recon_One:0.0, T_Reg:2.850895881652832,T_MSE:112.17665100097656,  CI:0.9094310998735777 Validation RAE:0.07321362697986479 Loss:40.70199487268053, Ranking:47.272718204652364, Reg:3.320897938803582, Gen:38.109762543094774, Disc:3.5893951087890645e-08, Recon_One:0.0, T_Reg:2.5922328043657794, T_MSE:152.39332069586825, CI:0.9244935569082086, \n",
      "it:23200, trainCI:0.9233226837060703, train_ranking:53.83060836791992, train_RAE:0.08452140539884567,  train_Gen:41.62531661987305, train_Disc:1.811784322569565e-08, train_reg:3.299542188644409, train_t_reg:2.6840407848358154, train_t_mse:138.6874237060547, train_layer_one_recon:0.0\n",
      "Iteration: 23250 epochs:250, Training: RAE:0.08408580720424652, Loss: 43.987037658691406, Ranking:43.41358947753906, Reg:3.29978084564209, Gen:41.442806243896484, Disc:2.289812606193209e-08, Recon_One:0.0, T_Reg:2.5442309379577637,T_MSE:81.711181640625,  CI:0.9283657518951637 Validation RAE:0.07269375964419698 Loss:40.96088359337144, Ranking:47.26144168859007, Reg:3.3216500947128704, Gen:38.32925307805857, Disc:2.5290784275153533e-08, Recon_One:0.0, T_Reg:2.6316305779212263, T_MSE:166.22055824568858, CI:0.9236390585759489, \n",
      "it:23300, trainCI:0.8687606391741255, train_ranking:46.682151794433594, train_RAE:0.09438847005367279,  train_Gen:41.48101806640625, train_Disc:1.704566798821361e-08, train_reg:3.300328493118286, train_t_reg:3.194615125656128, train_t_mse:121.27340698242188, train_layer_one_recon:0.0\n",
      "Iteration: 23343 epochs:251, Training: RAE:0.08380739390850067, Loss: 44.6209716796875, Ranking:39.85725021362305, Reg:3.30075740814209, Gen:41.64909362792969, Disc:8.61383231409718e-09, Recon_One:0.0, T_Reg:2.971876859664917,T_MSE:101.59764099121094,  CI:0.887302396736359 Validation RAE:0.07177755533363188 Loss:40.660049278199175, Ranking:47.25934889997201, Reg:3.32263312936649, Gen:38.09515526253864, Disc:4.030527035463612e-08, Recon_One:0.0, T_Reg:2.5648939843563583, T_MSE:171.3589852282863, CI:0.9241424372849808, \n",
      "it:23400, trainCI:0.8864423285003246, train_ranking:47.54130554199219, train_RAE:0.09087620675563812,  train_Gen:41.403717041015625, train_Disc:1.5805676767399746e-08, train_reg:3.3012659549713135, train_t_reg:2.890582799911499, train_t_mse:89.73480224609375, train_layer_one_recon:0.0\n",
      "Iteration: 23436 epochs:252, Training: RAE:0.09250447899103165, Loss: 43.82172775268555, Ranking:48.84976577758789, Reg:3.3018136024475098, Gen:41.40946960449219, Disc:3.1125537702791917e-08, Recon_One:0.0, T_Reg:2.4122583866119385,T_MSE:127.61016845703125,  CI:0.9241113806560489 Validation RAE:0.07251442763039033 Loss:40.30897651625616, Ranking:47.264298800007765, Reg:3.3236963235841506, Gen:37.8389056092339, Disc:5.334624364386443e-08, Recon_One:0.0, T_Reg:2.47007063571939, T_MSE:140.1290755220036, CI:0.9238067822860098, \n",
      "it:23500, trainCI:0.89574077365085, train_ranking:43.478858947753906, train_RAE:0.08376828581094742,  train_Gen:41.265464782714844, train_Disc:2.8002023810813625e-08, train_reg:3.3025338649749756, train_t_reg:3.3160359859466553, train_t_mse:164.1748504638672, train_layer_one_recon:0.0\n",
      "Iteration: 23529 epochs:253, Training: RAE:0.09040729701519012, Loss: 44.826622009277344, Ranking:50.09735107421875, Reg:3.3025078773498535, Gen:41.87226104736328, Disc:1.7058535917158224e-08, Recon_One:0.0, T_Reg:2.954361915588379,T_MSE:151.4534149169922,  CI:0.9039406345957012 Validation RAE:0.07123402790925168 Loss:40.475716423329466, Ranking:47.24701188185132, Reg:3.3243951997832086, Gen:37.99565973409462, Disc:4.5691927798214226e-08, Recon_One:0.0, T_Reg:2.4800568301036416, T_MSE:153.69887252412647, CI:0.9237407203172884, \n",
      "it:23600, trainCI:0.9147986716479867, train_ranking:49.729312896728516, train_RAE:0.07665476948022842,  train_Gen:41.37718200683594, train_Disc:2.4310926605153327e-08, train_reg:3.3028366565704346, train_t_reg:2.479400157928467, train_t_mse:88.44219207763672, train_layer_one_recon:0.0\n",
      "Iteration: 23622 epochs:254, Training: RAE:0.09215371310710907, Loss: 44.386314392089844, Ranking:53.78944778442383, Reg:3.3031139373779297, Gen:41.785308837890625, Disc:1.6058020690934427e-08, Recon_One:0.0, T_Reg:2.6010074615478516,T_MSE:106.02477264404297,  CI:0.9087908934379185 Validation RAE:0.07181916152039393 Loss:40.66590925328535, Ranking:47.24951337781179, Reg:3.325005276465216, Gen:38.17144078851805, Disc:3.946333963070111e-08, Recon_One:0.0, T_Reg:2.4944682873769657, T_MSE:158.58511973041527, CI:0.9239011787676313, \n",
      "it:23700, trainCI:0.910758552305404, train_ranking:41.3007698059082, train_RAE:0.06450273096561432,  train_Gen:41.96269607543945, train_Disc:1.2776127711333629e-08, train_reg:3.3041694164276123, train_t_reg:2.129049777984619, train_t_mse:103.41569519042969, train_layer_one_recon:0.0\n",
      "Iteration: 23715 epochs:255, Training: RAE:0.08537132292985916, Loss: 44.19007110595703, Ranking:50.993324279785156, Reg:3.304054021835327, Gen:41.6873893737793, Disc:2.4123741226844686e-08, Recon_One:0.0, T_Reg:2.5026798248291016,T_MSE:117.3996353149414,  CI:0.9221394037066881 Validation RAE:0.07088872049377906 Loss:40.50819346408956, Ranking:47.24804850925695, Reg:3.3259515913185425, Gen:38.04008411857297, Disc:5.070855187544444e-08, Recon_One:0.0, T_Reg:2.46810916290889, T_MSE:142.45314508046718, CI:0.9238366217455658, \n",
      "it:23800, trainCI:0.9221006317689531, train_ranking:45.614051818847656, train_RAE:0.08997372537851334,  train_Gen:41.945655822753906, train_Disc:1.016526951502783e-08, train_reg:3.304854393005371, train_t_reg:2.3446364402770996, train_t_mse:79.2919692993164, train_layer_one_recon:0.0\n",
      "Iteration: 23808 epochs:256, Training: RAE:0.08195305615663528, Loss: 44.31260299682617, Ranking:52.3673210144043, Reg:3.304948091506958, Gen:42.119529724121094, Disc:9.015657553845813e-09, Recon_One:0.0, T_Reg:2.1930718421936035,T_MSE:93.4540023803711,  CI:0.9183083406841125 Validation RAE:0.07011099347356291 Loss:40.470772366740185, Ranking:47.24235331936152, Reg:3.3268515864237855, Gen:38.0155499911359, Disc:5.5304071894044576e-08, Recon_One:0.0, T_Reg:2.4552220886493306, T_MSE:147.3773566576724, CI:0.9242868602692318, \n",
      "it:23900, trainCI:0.8770630793579018, train_ranking:45.12759780883789, train_RAE:0.08223575353622437,  train_Gen:41.88560485839844, train_Disc:1.6384831269533606e-08, train_reg:3.305650234222412, train_t_reg:3.0562474727630615, train_t_mse:119.58496856689453, train_layer_one_recon:0.0\n",
      "Iteration: 23901 epochs:257, Training: RAE:0.08223575353622437, Loss: 44.94185256958008, Ranking:45.12759780883789, Reg:3.305650234222412, Gen:41.88560485839844, Disc:1.6384831269533606e-08, Recon_One:0.0, T_Reg:3.0562474727630615,T_MSE:119.58496856689453,  CI:0.8770630793579018 Validation RAE:0.07169522485748535 Loss:40.64717332735738, Ranking:47.263199564246996, Reg:3.3275583825797694, Gen:38.12320130131044, Disc:5.286709425450382e-08, Recon_One:0.0, T_Reg:2.5239715512669116, T_MSE:147.36166783865056, CI:0.9241648039059697, \n",
      "Iteration: 23994 epochs:258, Training: RAE:0.09265047311782837, Loss: 45.00056838989258, Ranking:51.557186126708984, Reg:3.3062026500701904, Gen:42.57901382446289, Disc:1.0420537321920165e-08, Recon_One:0.0, T_Reg:2.421555995941162,T_MSE:114.00414276123047,  CI:0.9082509239836181 Validation RAE:0.0712274983795461 Loss:40.62208858030624, Ranking:47.27066364886985, Reg:3.3281144595554624, Gen:38.16034541929664, Disc:5.3923616703540554e-08, Recon_One:0.0, T_Reg:2.46174338013884, T_MSE:137.50376928533868, CI:0.9242026870459278, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:24000, trainCI:0.8881894311290789, train_ranking:44.31610107421875, train_RAE:0.08851009607315063,  train_Gen:42.00867462158203, train_Disc:6.401918994924927e-09, train_reg:3.3063228130340576, train_t_reg:2.94620943069458, train_t_mse:109.66400146484375, train_layer_one_recon:0.0\n",
      "Iteration: 24087 epochs:259, Training: RAE:0.08876325935125351, Loss: 45.069923400878906, Ranking:48.47597885131836, Reg:3.3071136474609375, Gen:42.30623245239258, Disc:1.196390275737258e-08, Recon_One:0.0, T_Reg:2.7636899948120117,T_MSE:107.1322250366211,  CI:0.9334465555673496 Validation RAE:0.07250227019651034 Loss:41.07300714357087, Ranking:47.2847127968093, Reg:3.3290314945680315, Gen:38.59383782342298, Disc:3.443976517138952e-08, Recon_One:0.0, T_Reg:2.47916928884371, T_MSE:128.2856556628963, CI:0.9244707232348092, \n",
      "it:24100, trainCI:0.9144490539309926, train_ranking:50.80454635620117, train_RAE:0.07702524214982986,  train_Gen:42.218467712402344, train_Disc:1.993294418412006e-08, train_reg:3.3074228763580322, train_t_reg:2.4748454093933105, train_t_mse:126.55258178710938, train_layer_one_recon:0.0\n",
      "Iteration: 24180 epochs:260, Training: RAE:0.07671994715929031, Loss: 45.453582763671875, Ranking:42.5079460144043, Reg:3.3076698780059814, Gen:42.47077941894531, Disc:8.077037705334078e-09, Recon_One:0.0, T_Reg:2.9828040599823,T_MSE:123.56200408935547,  CI:0.9007946063086925 Validation RAE:0.07126422763631032 Loss:41.07614256999665, Ranking:47.265777859789765, Reg:3.32959141152284, Gen:38.61939655746149, Disc:3.5031768552112656e-08, Recon_One:0.0, T_Reg:2.456745876883721, T_MSE:130.69477675183796, CI:0.9243941266394967, \n",
      "it:24200, trainCI:0.9132647416749641, train_ranking:46.031192779541016, train_RAE:0.0856635794043541,  train_Gen:42.6825065612793, train_Disc:4.846616885600952e-09, train_reg:3.3075356483459473, train_t_reg:2.411540985107422, train_t_mse:119.51972961425781, train_layer_one_recon:0.0\n",
      "Iteration: 24273 epochs:261, Training: RAE:0.09727532416582108, Loss: 46.10506820678711, Ranking:45.282352447509766, Reg:3.3082082271575928, Gen:42.7216682434082, Disc:1.0169282305128036e-08, Recon_One:0.0, T_Reg:3.38339900970459,T_MSE:157.25564575195312,  CI:0.9059116930227286 Validation RAE:0.07130725718489643 Loss:41.134190866466284, Ranking:47.247256638781046, Reg:3.3301333285755437, Gen:38.71277349657367, Disc:3.489974153528033e-08, Recon_One:0.0, T_Reg:2.4214168116347827, T_MSE:129.31737757868, CI:0.9231797384776353, \n",
      "it:24300, trainCI:0.911602530616983, train_ranking:44.01370620727539, train_RAE:0.0843440592288971,  train_Gen:42.56657409667969, train_Disc:1.4282292681855324e-08, train_reg:3.308068037033081, train_t_reg:2.8680877685546875, train_t_mse:120.12480163574219, train_layer_one_recon:0.0\n",
      "Iteration: 24366 epochs:262, Training: RAE:0.06856528669595718, Loss: 44.39248275756836, Ranking:49.305049896240234, Reg:3.30865216255188, Gen:42.29421615600586, Disc:1.6235169653100456e-08, Recon_One:0.0, T_Reg:2.0982675552368164,T_MSE:119.71283721923828,  CI:0.935135417210249 Validation RAE:0.07143083173020923 Loss:41.56247141719893, Ranking:47.27423182424641, Reg:3.3305802061451337, Gen:39.09444688513411, Disc:2.1995614116716008e-08, Recon_One:0.0, T_Reg:2.46802456858636, T_MSE:126.68464715978392, CI:0.9243913762197463, \n",
      "it:24400, trainCI:0.9278704349225076, train_ranking:47.91427230834961, train_RAE:0.07377941906452179,  train_Gen:42.88770294189453, train_Disc:1.8648542265964352e-08, train_reg:3.3086342811584473, train_t_reg:2.0682995319366455, train_t_mse:85.78850555419922, train_layer_one_recon:0.0\n",
      "Iteration: 24459 epochs:263, Training: RAE:0.09073526412248611, Loss: 45.535369873046875, Ranking:50.834476470947266, Reg:3.3091206550598145, Gen:42.44895935058594, Disc:1.1511058772839533e-08, Recon_One:0.0, T_Reg:3.086411237716675,T_MSE:132.25814819335938,  CI:0.8895243829018663 Validation RAE:0.07091024961582017 Loss:41.987166095259965, Ranking:47.26456108727693, Reg:3.331051803580281, Gen:39.53147440742549, Disc:9.179321413129911e-09, Recon_One:0.0, T_Reg:2.4556912130544495, T_MSE:126.329157920991, CI:0.924692573129769, \n",
      "it:24500, trainCI:0.9165247018739353, train_ranking:46.83831787109375, train_RAE:0.08817193657159805,  train_Gen:42.71344757080078, train_Disc:9.064201833552943e-09, train_reg:3.309323310852051, train_t_reg:3.188419818878174, train_t_mse:203.4539337158203, train_layer_one_recon:0.0\n",
      "Iteration: 24552 epochs:264, Training: RAE:0.09113789349794388, Loss: 44.73200225830078, Ranking:55.30664825439453, Reg:3.3094143867492676, Gen:42.47932434082031, Disc:6.258487950105973e-09, Recon_One:0.0, T_Reg:2.252676010131836,T_MSE:90.78678131103516,  CI:0.9331346619482213 Validation RAE:0.07236344399501551 Loss:41.58222560541502, Ranking:47.28322021362259, Reg:3.33134748197219, Gen:39.094686299484195, Disc:2.351130967072113e-08, Recon_One:0.0, T_Reg:2.4875395198427053, T_MSE:124.82253076196298, CI:0.9247438451054931, \n",
      "it:24600, trainCI:0.8827415359207267, train_ranking:53.17111587524414, train_RAE:0.11256091296672821,  train_Gen:42.59648132324219, train_Disc:8.096942671897978e-09, train_reg:3.30991792678833, train_t_reg:3.5546324253082275, train_t_mse:141.6536102294922, train_layer_one_recon:0.0\n",
      "Iteration: 24645 epochs:265, Training: RAE:0.08871635794639587, Loss: 45.610076904296875, Ranking:54.03517150878906, Reg:3.310490608215332, Gen:42.928436279296875, Disc:1.133685323395639e-08, Recon_One:0.0, T_Reg:2.6816415786743164,T_MSE:121.21514892578125,  CI:0.9092734225621415 Validation RAE:0.07204747870257008 Loss:41.55620056434737, Ranking:47.283084812619855, Reg:3.3324308360802077, Gen:39.07093419214181, Disc:2.5667718966635467e-08, Recon_One:0.0, T_Reg:2.4852661739457647, T_MSE:125.45543745545815, CI:0.9230853938907261, \n",
      "it:24700, trainCI:0.8954410894020131, train_ranking:43.30390930175781, train_RAE:0.08194371312856674,  train_Gen:43.20429229736328, train_Disc:5.0971675769062585e-09, train_reg:3.3110687732696533, train_t_reg:3.2378835678100586, train_t_mse:179.09991455078125, train_layer_one_recon:0.0\n",
      "Iteration: 24738 epochs:266, Training: RAE:0.07801447808742523, Loss: 45.14089584350586, Ranking:44.681396484375, Reg:3.3118412494659424, Gen:42.38072204589844, Disc:1.2729421072776859e-08, Recon_One:0.0, T_Reg:2.7601723670959473,T_MSE:94.98358917236328,  CI:0.8840223846505254 Validation RAE:0.07038649909474991 Loss:41.88281716712493, Ranking:47.24694192744917, Reg:3.3337904286858615, Gen:39.394215689579575, Disc:1.8011797341715687e-08, Recon_One:0.0, T_Reg:2.4886012531987456, T_MSE:132.1933336104097, CI:0.9244820881767966, \n",
      "it:24800, trainCI:0.9012317387568032, train_ranking:44.712188720703125, train_RAE:0.0764111578464508,  train_Gen:43.243465423583984, train_Disc:8.85555007101857e-09, train_reg:3.3123981952667236, train_t_reg:2.7067089080810547, train_t_mse:93.72953033447266, train_layer_one_recon:0.0\n",
      "Iteration: 24831 epochs:267, Training: RAE:0.09032478928565979, Loss: 45.8847770690918, Ranking:49.38896560668945, Reg:3.312459707260132, Gen:42.99578094482422, Disc:7.185307460133572e-09, Recon_One:0.0, T_Reg:2.8889970779418945,T_MSE:125.42107391357422,  CI:0.9110399338740507 Validation RAE:0.07320496257046573 Loss:41.834687703666766, Ranking:47.29303186113005, Reg:3.3344129852999953, Gen:39.342722070504834, Disc:2.1668468572793318e-08, Recon_One:0.0, T_Reg:2.4919653827285146, T_MSE:119.03512360111421, CI:0.923949700323605, \n",
      "it:24900, trainCI:0.8693559096945551, train_ranking:46.19242858886719, train_RAE:0.08827678859233856,  train_Gen:43.3704948425293, train_Disc:5.556004545326232e-09, train_reg:3.3127238750457764, train_t_reg:3.2693634033203125, train_t_mse:126.82505798339844, train_layer_one_recon:0.0\n",
      "Iteration: 24924 epochs:268, Training: RAE:0.07316388934850693, Loss: 45.552303314208984, Ranking:42.134765625, Reg:3.31268048286438, Gen:43.05877685546875, Disc:8.928534356300588e-09, Recon_One:0.0, T_Reg:2.493525505065918,T_MSE:158.09747314453125,  CI:0.9207306046175177 Validation RAE:0.07066771528270523 Loss:41.793428630669055, Ranking:47.245463201578396, Reg:3.3346352240913166, Gen:39.32848025578714, Disc:2.416640308455174e-08, Recon_One:0.0, T_Reg:2.46494833314301, T_MSE:136.78324495358245, CI:0.9241432157056648, \n",
      "it:25000, trainCI:0.9436182464573631, train_ranking:51.49177169799805, train_RAE:0.07479041814804077,  train_Gen:44.08470153808594, train_Disc:6.3165446206880915e-09, train_reg:3.312976121902466, train_t_reg:2.1329174041748047, train_t_mse:110.16229248046875, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 25017 epochs:269, Training: RAE:0.10164090991020203, Loss: 46.163883209228516, Ranking:54.517112731933594, Reg:3.312950611114502, Gen:43.413002014160156, Disc:1.242029057380023e-08, Recon_One:0.0, T_Reg:2.7508795261383057,T_MSE:138.71856689453125,  CI:0.9012987012987013 Validation RAE:0.06952713175767718 Loss:42.19117183096188, Ranking:47.236868326583775, Reg:3.334907142612447, Gen:39.79099255078015, Disc:1.346764752710877e-08, Recon_One:0.0, T_Reg:2.400179217573373, T_MSE:134.87146927801479, CI:0.9240465358567034, \n",
      "it:25100, trainCI:0.9142738675235824, train_ranking:49.24786376953125, train_RAE:0.08429092168807983,  train_Gen:43.494911193847656, train_Disc:4.151037735766749e-09, train_reg:3.3135039806365967, train_t_reg:2.4215774536132812, train_t_mse:131.4517364501953, train_layer_one_recon:0.0\n",
      "Iteration: 25110 epochs:270, Training: RAE:0.08638466149568558, Loss: 45.55103302001953, Ranking:47.00825119018555, Reg:3.3135876655578613, Gen:43.08803176879883, Disc:1.3964521983211853e-08, Recon_One:0.0, T_Reg:2.463000774383545,T_MSE:92.3516616821289,  CI:0.9303790594113175 Validation RAE:0.07102176504193566 Loss:41.97103651341787, Ranking:47.26708111531051, Reg:3.3355484191247697, Gen:39.58673204081169, Disc:2.0003705826396806e-08, Recon_One:0.0, T_Reg:2.384304336954746, T_MSE:123.63341478045112, CI:0.9231488092291217, \n",
      "it:25200, trainCI:0.9317588158467567, train_ranking:46.993412017822266, train_RAE:0.08512769639492035,  train_Gen:43.65998840332031, train_Disc:2.895082840126406e-09, train_reg:3.3142476081848145, train_t_reg:2.150352716445923, train_t_mse:112.54926300048828, train_layer_one_recon:0.0\n",
      "Iteration: 25203 epochs:271, Training: RAE:0.0824131891131401, Loss: 46.21387481689453, Ranking:39.27070999145508, Reg:3.3142473697662354, Gen:43.501319885253906, Disc:6.225373994084293e-09, Recon_One:0.0, T_Reg:2.7125556468963623,T_MSE:98.9712142944336,  CI:0.9157559198542805 Validation RAE:0.07109577398725311 Loss:41.719558451553425, Ranking:47.26233039332193, Reg:3.3362124955130916, Gen:39.35173850842412, Disc:2.858675699281059e-08, Recon_One:0.0, T_Reg:2.367820078780744, T_MSE:122.61658230021072, CI:0.9245496550921738, \n",
      "Iteration: 25296 epochs:272, Training: RAE:0.0841834619641304, Loss: 46.51027297973633, Ranking:48.46388244628906, Reg:3.314944267272949, Gen:43.781280517578125, Disc:3.6691689686563222e-09, Recon_One:0.0, T_Reg:2.7289938926696777,T_MSE:92.86904907226562,  CI:0.8994395685735435 Validation RAE:0.07083530040387737 Loss:43.11122214539253, Ranking:47.23441725121866, Reg:3.336914011697792, Gen:40.57054220325756, Disc:1.9328083591262874e-09, Recon_One:0.0, T_Reg:2.5406800412648733, T_MSE:150.7289725720204, CI:0.9242253131404781, \n",
      "it:25300, trainCI:0.9102545168118938, train_ranking:52.47425079345703, train_RAE:0.0955817773938179,  train_Gen:43.75755310058594, train_Disc:5.169489281087181e-09, train_reg:3.314905881881714, train_t_reg:2.6680221557617188, train_t_mse:85.5520248413086, train_layer_one_recon:0.0\n",
      "Iteration: 25389 epochs:273, Training: RAE:0.08694671839475632, Loss: 46.07278823852539, Ranking:49.20328903198242, Reg:3.3157670497894287, Gen:43.49706268310547, Disc:1.3570144119512406e-08, Recon_One:0.0, T_Reg:2.575725793838501,T_MSE:107.251220703125,  CI:0.9132720105124835 Validation RAE:0.0721708988465487 Loss:42.05972083109505, Ranking:47.24683874887989, Reg:3.3377422471933103, Gen:39.61410007283615, Disc:2.2874836361584454e-08, Recon_One:0.0, T_Reg:2.4456204452171195, T_MSE:130.46298793245586, CI:0.9234398347755393, \n",
      "it:25400, trainCI:0.8733861291096712, train_ranking:53.6312255859375, train_RAE:0.10972826182842255,  train_Gen:43.744083404541016, train_Disc:8.846814836260819e-09, train_reg:3.315876007080078, train_t_reg:3.5227317810058594, train_t_mse:153.2140655517578, train_layer_one_recon:0.0\n",
      "Iteration: 25482 epochs:274, Training: RAE:0.07706832140684128, Loss: 46.96818923950195, Ranking:43.27356719970703, Reg:3.3165805339813232, Gen:44.07048797607422, Disc:1.8615921248965606e-08, Recon_One:0.0, T_Reg:2.8977015018463135,T_MSE:117.30628204345703,  CI:0.8911036631975069 Validation RAE:0.07146008075591667 Loss:41.959695886399906, Ranking:47.26183353341548, Reg:3.338561122739734, Gen:39.59372814884927, Disc:2.5138529391866158e-08, Recon_One:0.0, T_Reg:2.3659676697249115, T_MSE:117.9354093455517, CI:0.9238470525827324, \n",
      "it:25500, trainCI:0.9330270365789008, train_ranking:43.4273681640625, train_RAE:0.07573578506708145,  train_Gen:43.597747802734375, train_Disc:5.564820604320175e-09, train_reg:3.3166136741638184, train_t_reg:2.1947970390319824, train_t_mse:106.7015380859375, train_layer_one_recon:0.0\n",
      "Iteration: 25575 epochs:275, Training: RAE:0.10349840670824051, Loss: 46.66550827026367, Ranking:53.92710876464844, Reg:3.3171114921569824, Gen:43.91139221191406, Disc:1.3350861749472642e-08, Recon_One:0.0, T_Reg:2.754117727279663,T_MSE:105.17558288574219,  CI:0.9012410501193318 Validation RAE:0.07083559583705322 Loss:42.03395573991797, Ranking:47.268030591885775, Reg:3.339095599832901, Gen:39.65431667498176, Disc:2.4190620734653704e-08, Recon_One:0.0, T_Reg:2.3796392266744673, T_MSE:126.82359396584022, CI:0.9239241681251675, \n",
      "it:25600, trainCI:0.9476359627633513, train_ranking:42.20246505737305, train_RAE:0.06677375733852386,  train_Gen:44.08732604980469, train_Disc:8.476922275235665e-09, train_reg:3.317077875137329, train_t_reg:2.095313787460327, train_t_mse:92.79093170166016, train_layer_one_recon:0.0\n",
      "Iteration: 25668 epochs:276, Training: RAE:0.07865110784769058, Loss: 46.23514938354492, Ranking:52.343017578125, Reg:3.3175854682922363, Gen:43.822330474853516, Disc:6.741836422463621e-09, Recon_One:0.0, T_Reg:2.4128193855285645,T_MSE:141.70758056640625,  CI:0.9270674096355837 Validation RAE:0.07085617556208385 Loss:42.54285815478534, Ranking:47.25782292566255, Reg:3.339572717238027, Gen:40.15498533984699, Disc:8.822362422954466e-09, Recon_One:0.0, T_Reg:2.3878724549403114, T_MSE:126.61673061785376, CI:0.9244200221009201, \n",
      "it:25700, trainCI:0.919615233166451, train_ranking:45.6843376159668, train_RAE:0.06819943338632584,  train_Gen:43.996376037597656, train_Disc:4.284188115377674e-09, train_reg:3.318136215209961, train_t_reg:2.5615906715393066, train_t_mse:127.888916015625, train_layer_one_recon:0.0\n",
      "Iteration: 25761 epochs:277, Training: RAE:0.09031004458665848, Loss: 46.7398796081543, Ranking:46.587867736816406, Reg:3.318577289581299, Gen:44.10334014892578, Disc:5.263786739817533e-09, Recon_One:0.0, T_Reg:2.6365411281585693,T_MSE:142.8753662109375,  CI:0.9138706140350877 Validation RAE:0.07087887500384696 Loss:42.84746917289571, Ranking:47.25650681455955, Reg:3.34057111180811, Gen:40.53785329582364, Disc:4.5156665132739394e-09, Recon_One:0.0, T_Reg:2.3096159292456955, T_MSE:117.53511055567957, CI:0.9246910162884009, *\n",
      "it:25800, trainCI:0.9105123471036234, train_ranking:44.58085250854492, train_RAE:0.08491430431604385,  train_Gen:43.66356658935547, train_Disc:6.180434830582726e-09, train_reg:3.3186588287353516, train_t_reg:3.0743865966796875, train_t_mse:138.00396728515625, train_layer_one_recon:0.0\n",
      "Iteration: 25854 epochs:278, Training: RAE:0.0804758071899414, Loss: 47.10427474975586, Ranking:46.569976806640625, Reg:3.319218873977661, Gen:44.548606872558594, Disc:2.3841861818141297e-09, Recon_One:0.0, T_Reg:2.555668354034424,T_MSE:141.16319274902344,  CI:0.9239106392391064 Validation RAE:0.07020051054105887 Loss:43.12471967198423, Ranking:47.27474421102494, Reg:3.3412169482956324, Gen:40.81664930302843, Disc:1.5162223731905659e-09, Recon_One:0.0, T_Reg:2.308070175913374, T_MSE:112.38707460968945, CI:0.9237259303242911, *\n",
      "it:25900, trainCI:0.9162246567193774, train_ranking:52.1237678527832, train_RAE:0.08347788453102112,  train_Gen:43.86714172363281, train_Disc:3.4133840198791177e-09, train_reg:3.3198165893554688, train_t_reg:2.550747871398926, train_t_mse:128.19265747070312, train_layer_one_recon:0.0\n",
      "Iteration: 25947 epochs:279, Training: RAE:0.09325933456420898, Loss: 46.99524688720703, Ranking:49.325008392333984, Reg:3.3203349113464355, Gen:44.31431198120117, Disc:4.5272403603746625e-09, Recon_One:0.0, T_Reg:2.680936098098755,T_MSE:111.43811798095703,  CI:0.905185416341603 Validation RAE:0.07041057755075217 Loss:43.98282728329947, Ranking:47.27937806408391, Reg:3.3423403821856703, Gen:41.64464930765358, Disc:8.198713086246545e-11, Recon_One:0.0, T_Reg:2.3381776312999434, T_MSE:114.96532941529404, CI:0.9241877413687936, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:26000, trainCI:0.9096250560175273, train_ranking:51.682125091552734, train_RAE:0.09649589657783508,  train_Gen:44.87831115722656, train_Disc:4.962160460308951e-09, train_reg:3.3206303119659424, train_t_reg:3.1162021160125732, train_t_mse:187.8946075439453, train_layer_one_recon:0.0\n",
      "Iteration: 26040 epochs:280, Training: RAE:0.08800823986530304, Loss: 47.538578033447266, Ranking:49.01553726196289, Reg:3.3207225799560547, Gen:44.532188415527344, Disc:3.812888671461678e-09, Recon_One:0.0, T_Reg:3.0063910484313965,T_MSE:119.76174926757812,  CI:0.8871725289635738 Validation RAE:0.0690650322056568 Loss:42.67081210236706, Ranking:47.23524101021678, Reg:3.342730620063304, Gen:40.31100018525013, Disc:1.0656419820037396e-08, Recon_One:0.0, T_Reg:2.3598120371162765, T_MSE:125.86262182875157, CI:0.9239511533755487, \n",
      "it:26100, trainCI:0.9071804714798957, train_ranking:52.23775863647461, train_RAE:0.08802072703838348,  train_Gen:44.71196746826172, train_Disc:4.828125454992005e-09, train_reg:3.320957660675049, train_t_reg:2.4622275829315186, train_t_mse:98.95132446289062, train_layer_one_recon:0.0\n",
      "Iteration: 26133 epochs:281, Training: RAE:0.07992662489414215, Loss: 47.36936569213867, Ranking:54.952362060546875, Reg:3.321169376373291, Gen:44.45274353027344, Disc:5.569778860348151e-09, Recon_One:0.0, T_Reg:2.916621685028076,T_MSE:106.58892059326172,  CI:0.8966455547736336 Validation RAE:0.06827341933704785 Loss:45.002585326759196, Ranking:47.226095181696856, Reg:3.3431803776172306, Gen:42.62230398357697, Disc:1.490675106590281e-11, Recon_One:0.0, T_Reg:2.3802814110079393, T_MSE:134.29001396382407, CI:0.9246574923042736, \n",
      "it:26200, trainCI:0.8885800909550278, train_ranking:50.974464416503906, train_RAE:0.08821313828229904,  train_Gen:44.453636169433594, train_Disc:7.645947874834746e-09, train_reg:3.322117805480957, train_t_reg:2.9467780590057373, train_t_mse:90.18719482421875, train_layer_one_recon:0.0\n",
      "Iteration: 26226 epochs:282, Training: RAE:0.07720580697059631, Loss: 47.13016891479492, Ranking:47.42728042602539, Reg:3.3220221996307373, Gen:44.57969284057617, Disc:1.3016628663820029e-08, Recon_One:0.0, T_Reg:2.550475597381592,T_MSE:110.44845581054688,  CI:0.9221638029161472 Validation RAE:0.06961167830872778 Loss:43.92571761129021, Ranking:47.257341759583795, Reg:3.344038852948285, Gen:41.58181456069403, Disc:1.1180063238689009e-10, Recon_One:0.0, T_Reg:2.3439029619010134, T_MSE:120.94640508806525, CI:0.9236335577364482, \n",
      "it:26300, trainCI:0.9358280733393447, train_ranking:51.183467864990234, train_RAE:0.09651367366313934,  train_Gen:44.963287353515625, train_Disc:3.6545242387830967e-09, train_reg:3.322655439376831, train_t_reg:2.2969560623168945, train_t_mse:107.66927337646484, train_layer_one_recon:0.0\n",
      "Iteration: 26319 epochs:283, Training: RAE:0.08581690490245819, Loss: 47.85016632080078, Ranking:41.734649658203125, Reg:3.3226749897003174, Gen:44.65330505371094, Disc:4.9143427105491355e-09, Recon_One:0.0, T_Reg:3.19686222076416,T_MSE:139.45213317871094,  CI:0.8924902152641878 Validation RAE:0.0698391183217615 Loss:44.37074731614749, Ranking:47.25807436081683, Reg:3.3446959693744596, Gen:41.99374080732851, Disc:5.2173628730659834e-11, Recon_One:0.0, T_Reg:2.377006446210626, T_MSE:124.94032162047034, CI:0.9245169614234429, \n",
      "it:26400, trainCI:0.8939632841536209, train_ranking:45.49112319946289, train_RAE:0.07706038653850555,  train_Gen:44.820613861083984, train_Disc:2.2138868516208277e-09, train_reg:3.3232364654541016, train_t_reg:2.685335397720337, train_t_mse:128.93212890625, train_layer_one_recon:0.0\n",
      "Iteration: 26412 epochs:284, Training: RAE:0.09205833077430725, Loss: 48.07558822631836, Ranking:49.88237380981445, Reg:3.3233351707458496, Gen:44.89089584350586, Disc:3.76205955276987e-09, Recon_One:0.0, T_Reg:3.1846923828125,T_MSE:108.86286926269531,  CI:0.8773477812177503 Validation RAE:0.06996996896880649 Loss:43.13327781674384, Ranking:47.2541562464739, Reg:3.3453605257601713, Gen:40.79952616832905, Disc:5.800834249194679e-09, Recon_One:0.0, T_Reg:2.3337517892835855, T_MSE:119.56244823231135, CI:0.9226546158841619, \n",
      "it:26500, trainCI:0.9179442298406567, train_ranking:42.34839630126953, train_RAE:0.07533080875873566,  train_Gen:45.2092399597168, train_Disc:5.108969358680326e-10, train_reg:3.32418155670166, train_t_reg:2.618206024169922, train_t_mse:116.3414077758789, train_layer_one_recon:0.0\n",
      "Iteration: 26505 epochs:285, Training: RAE:0.08436807990074158, Loss: 47.581092834472656, Ranking:45.62716293334961, Reg:3.324157476425171, Gen:44.868629455566406, Disc:1.6061532104316711e-09, Recon_One:0.0, T_Reg:2.7124617099761963,T_MSE:112.24050903320312,  CI:0.9121296813862493 Validation RAE:0.07080567116284647 Loss:43.44409090199291, Ranking:47.28370254839064, Reg:3.3461882812583, Gen:41.066635115617395, Disc:3.851513015955277e-09, Recon_One:0.0, T_Reg:2.3774559115922287, T_MSE:110.74860594161409, CI:0.924157798119813, \n",
      "Iteration: 26598 epochs:286, Training: RAE:0.09948588907718658, Loss: 47.87491989135742, Ranking:56.15621566772461, Reg:3.32500958442688, Gen:45.128562927246094, Disc:1.0714281906132328e-08, Recon_One:0.0, T_Reg:2.7463560104370117,T_MSE:103.38600158691406,  CI:0.912070711720836 Validation RAE:0.06960849571734111 Loss:43.72030627627633, Ranking:47.268772375677564, Reg:3.3470460365932704, Gen:41.41510887952153, Disc:1.0080627673453343e-09, Recon_One:0.0, T_Reg:2.305197334146446, T_MSE:112.82386522196495, CI:0.9246678193520156, *\n",
      "it:26600, trainCI:0.9224065392475057, train_ranking:42.46572494506836, train_RAE:0.07390020042657852,  train_Gen:45.4061164855957, train_Disc:4.928026875461455e-09, train_reg:3.3249804973602295, train_t_reg:2.7046384811401367, train_t_mse:103.52577209472656, train_layer_one_recon:0.0\n",
      "Iteration: 26691 epochs:287, Training: RAE:0.07730341702699661, Loss: 48.38945770263672, Ranking:41.61354064941406, Reg:3.325690269470215, Gen:45.199127197265625, Disc:2.303614188292613e-09, Recon_One:0.0, T_Reg:3.1903295516967773,T_MSE:140.61526489257812,  CI:0.9111931119311193 Validation RAE:0.07140595273508256 Loss:44.307678831328715, Ranking:47.27481166109288, Reg:3.3477312328667286, Gen:41.94246740270827, Disc:9.689388192836826e-11, Recon_One:0.0, T_Reg:2.365211517315619, T_MSE:112.46255924958982, CI:0.9239228707573608, \n",
      "it:26700, trainCI:0.9420588786799174, train_ranking:40.99759292602539, train_RAE:0.07205691933631897,  train_Gen:45.116615295410156, train_Disc:1.7029899712639462e-09, train_reg:3.325698137283325, train_t_reg:2.4992592334747314, train_t_mse:137.5163116455078, train_layer_one_recon:0.0\n",
      "Iteration: 26784 epochs:288, Training: RAE:0.08276637643575668, Loss: 48.04967498779297, Ranking:43.52354049682617, Reg:3.326591730117798, Gen:44.951927185058594, Disc:2.2990362946728737e-09, Recon_One:0.0, T_Reg:3.0977466106414795,T_MSE:117.68787384033203,  CI:0.8927230046948357 Validation RAE:0.07091704572016289 Loss:44.21849898939, Ranking:47.250392899984895, Reg:3.3486386679315086, Gen:41.80807698230617, Disc:2.1880801630228135e-10, Recon_One:0.0, T_Reg:2.4104216157816136, T_MSE:116.08977280245045, CI:0.9240823432081705, \n",
      "it:26800, trainCI:0.9402268315111884, train_ranking:50.44150924682617, train_RAE:0.08286728709936142,  train_Gen:44.956905364990234, train_Disc:1.7029898324860682e-10, train_reg:3.326692819595337, train_t_reg:2.1912879943847656, train_t_mse:104.74372100830078, train_layer_one_recon:0.0\n",
      "Iteration: 26877 epochs:289, Training: RAE:0.1190374344587326, Loss: 49.16562271118164, Ranking:46.87101364135742, Reg:3.3270437717437744, Gen:45.294586181640625, Disc:5.108969358680326e-10, Recon_One:0.0, T_Reg:3.871037483215332,T_MSE:86.55691528320312,  CI:0.870510708401977 Validation RAE:0.0724637357321727 Loss:44.36728198542898, Ranking:47.30039293413924, Reg:3.349093705456719, Gen:41.95823235348998, Disc:2.608681424385372e-10, Recon_One:0.0, T_Reg:2.409049360636131, T_MSE:106.66595917873805, CI:0.9244318540953179, \n",
      "it:26900, trainCI:0.903443656862198, train_ranking:46.28884506225586, train_RAE:0.08723527938127518,  train_Gen:45.004676818847656, train_Disc:8.514949301208219e-10, train_reg:3.327303409576416, train_t_reg:2.7525577545166016, train_t_mse:123.40552520751953, train_layer_one_recon:0.0\n",
      "Iteration: 26970 epochs:290, Training: RAE:0.09424220770597458, Loss: 48.273197174072266, Ranking:44.22842788696289, Reg:3.3278472423553467, Gen:45.154747009277344, Disc:1.0217938717360653e-09, Recon_One:0.0, T_Reg:3.118450164794922,T_MSE:132.5986785888672,  CI:0.906478578892372 Validation RAE:0.0683992678373847 Loss:45.349386028458184, Ranking:47.246203148858434, Reg:3.349902501057964, Gen:43.06084011679398, Disc:0.0, Recon_One:0.0, T_Reg:2.2885460994892663, T_MSE:115.42583607249935, CI:0.9253261037771774, *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:27000, trainCI:0.9196033121509725, train_ranking:53.722042083740234, train_RAE:0.09585054963827133,  train_Gen:44.8931884765625, train_Disc:7.26092919123289e-09, train_reg:3.327977418899536, train_t_reg:2.334610939025879, train_t_mse:84.71002197265625, train_layer_one_recon:0.0\n",
      "Iteration: 27063 epochs:291, Training: RAE:0.09696140885353088, Loss: 48.669429779052734, Ranking:39.90430450439453, Reg:3.328457832336426, Gen:45.32485580444336, Disc:2.0435881875613404e-09, Recon_One:0.0, T_Reg:3.3445749282836914,T_MSE:130.15869140625,  CI:0.8965894465894466 Validation RAE:0.06749447520388593 Loss:43.67173755259846, Ranking:47.213708410803285, Reg:3.3505171377151717, Gen:41.35600692617367, Disc:4.163224775828512e-09, Recon_One:0.0, T_Reg:2.3157305638164347, T_MSE:124.90271587021219, CI:0.9253762859639437, \n",
      "it:27100, trainCI:0.8942852428359276, train_ranking:46.31208801269531, train_RAE:0.08676932752132416,  train_Gen:45.310237884521484, train_Disc:2.249821662303475e-09, train_reg:3.328737735748291, train_t_reg:3.8371901512145996, train_t_mse:200.17677307128906, train_layer_one_recon:0.0\n",
      "Iteration: 27156 epochs:292, Training: RAE:0.08284115791320801, Loss: 48.299861907958984, Ranking:41.83873748779297, Reg:3.3290610313415527, Gen:44.9677848815918, Disc:3.0653817262304983e-09, Recon_One:0.0, T_Reg:3.3320772647857666,T_MSE:130.6080322265625,  CI:0.8825896122896855 Validation RAE:0.06877119032549861 Loss:44.17438631104248, Ranking:47.21891225032751, Reg:3.3511243344128423, Gen:41.80155502821157, Disc:5.480866038902504e-10, Recon_One:0.0, T_Reg:2.37283113152739, T_MSE:123.8346931292472, CI:0.9255349799940694, \n",
      "it:27200, trainCI:0.8768451675466006, train_ranking:47.45115661621094, train_RAE:0.08712629973888397,  train_Gen:45.591068267822266, train_Disc:2.5708597473084183e-09, train_reg:3.3292737007141113, train_t_reg:2.81933331489563, train_t_mse:99.1122055053711, train_layer_one_recon:0.0\n",
      "Iteration: 27249 epochs:293, Training: RAE:0.09028627723455429, Loss: 48.25999069213867, Ranking:38.80677032470703, Reg:3.329458713531494, Gen:45.19366455078125, Disc:7.071987440099292e-09, Recon_One:0.0, T_Reg:3.066324472427368,T_MSE:120.60368347167969,  CI:0.9299062312961361 Validation RAE:0.06989868104129907 Loss:45.785158879312405, Ranking:47.276191382284715, Reg:3.3515246522356543, Gen:43.450994182709266, Disc:0.0, Recon_One:0.0, T_Reg:2.334164712255234, T_MSE:111.70972867266632, CI:0.9247804308776444, \n",
      "it:27300, trainCI:0.9069044264127107, train_ranking:52.95946502685547, train_RAE:0.08882775902748108,  train_Gen:45.923744201660156, train_Disc:2.2138868516208277e-09, train_reg:3.3300516605377197, train_t_reg:3.0579214096069336, train_t_mse:133.34254455566406, train_layer_one_recon:0.0\n",
      "Iteration: 27342 epochs:294, Training: RAE:0.08329565078020096, Loss: 47.99202346801758, Ranking:49.297000885009766, Reg:3.3302788734436035, Gen:45.40779113769531, Disc:2.5708597473084183e-09, Recon_One:0.0, T_Reg:2.5842323303222656,T_MSE:128.62158203125,  CI:0.9100518026267594 Validation RAE:0.07264397605625678 Loss:45.066559879693656, Ranking:47.27100457223308, Reg:3.3523502477455307, Gen:42.704561177948136, Disc:2.2360126598854216e-11, Recon_One:0.0, T_Reg:2.361998498268361, T_MSE:111.62077171647192, CI:0.9233785990150591, \n",
      "it:27400, trainCI:0.9263152747897516, train_ranking:52.77203369140625, train_RAE:0.09005451947450638,  train_Gen:45.71104431152344, train_Disc:4.212806103964795e-09, train_reg:3.33085298538208, train_t_reg:2.349910020828247, train_t_mse:102.96736907958984, train_layer_one_recon:0.0\n",
      "Iteration: 27435 epochs:295, Training: RAE:0.09535523504018784, Loss: 48.69576644897461, Ranking:46.996925354003906, Reg:3.3308520317077637, Gen:45.917457580566406, Disc:4.995436952981436e-09, Recon_One:0.0, T_Reg:2.7783074378967285,T_MSE:92.03228759765625,  CI:0.8961286804798255 Validation RAE:0.06894015870001728 Loss:46.39135634763488, Ranking:47.243393953701876, Reg:3.3529272046076652, Gen:44.065746790590296, Disc:0.0, Recon_One:0.0, T_Reg:2.3256094057410603, T_MSE:118.4594055496336, CI:0.9254317614113619, \n",
      "it:27500, trainCI:0.9240808375943511, train_ranking:53.08369445800781, train_RAE:0.09625545889139175,  train_Gen:46.218902587890625, train_Disc:2.202340976253936e-09, train_reg:3.3311517238616943, train_t_reg:2.5609841346740723, train_t_mse:103.1387710571289, train_layer_one_recon:0.0\n",
      "Iteration: 27528 epochs:296, Training: RAE:0.09060939401388168, Loss: 48.5268669128418, Ranking:45.195281982421875, Reg:3.3312442302703857, Gen:45.45475769042969, Disc:2.421054468015882e-09, Recon_One:0.0, T_Reg:3.0721077919006348,T_MSE:101.97603607177734,  CI:0.9124864772533167 Validation RAE:0.07184399600489312 Loss:45.76626835248612, Ranking:47.30224180060565, Reg:3.3533220024604984, Gen:43.37982701497986, Disc:0.0, Recon_One:0.0, T_Reg:2.3864410296818517, T_MSE:104.06098646626884, CI:0.9251516337545213, \n",
      "it:27600, trainCI:0.9000576701268743, train_ranking:44.535804748535156, train_RAE:0.07886089384555817,  train_Gen:46.208316802978516, train_Disc:1.19209286886246e-09, train_reg:3.331538677215576, train_t_reg:2.6813340187072754, train_t_mse:96.35785675048828, train_layer_one_recon:0.0\n",
      "Iteration: 27621 epochs:297, Training: RAE:0.09074970334768295, Loss: 48.659236907958984, Ranking:41.60330581665039, Reg:3.331818103790283, Gen:46.0347900390625, Disc:1.8732890794126433e-09, Recon_One:0.0, T_Reg:2.624447822570801,T_MSE:109.71430969238281,  CI:0.9061196958547952 Validation RAE:0.06980403612125691 Loss:44.74156441592538, Ranking:47.27762336058365, Reg:3.353899679318717, Gen:42.43484421701778, Disc:1.2670738284541193e-10, Recon_One:0.0, T_Reg:2.3067198023880153, T_MSE:109.65688518692556, CI:0.9250336251788162, \n",
      "it:27700, trainCI:0.8951176321780926, train_ranking:50.74031448364258, train_RAE:0.08449015021324158,  train_Gen:46.23138427734375, train_Disc:3.405981052750917e-09, train_reg:3.331960678100586, train_t_reg:2.7988643646240234, train_t_mse:151.81092834472656, train_layer_one_recon:0.0\n",
      "Iteration: 27714 epochs:298, Training: RAE:0.08085132390260696, Loss: 48.82412338256836, Ranking:44.40665054321289, Reg:3.332324743270874, Gen:46.25176239013672, Disc:1.2230563228854407e-09, Recon_One:0.0, T_Reg:2.5723602771759033,T_MSE:111.90699005126953,  CI:0.9030635838150289 Validation RAE:0.06926360145179543 Loss:45.7017116253266, Ranking:47.26447911207059, Reg:3.3544096765450213, Gen:43.40748538281659, Disc:0.0, Recon_One:0.0, T_Reg:2.2942261277280243, T_MSE:112.60143326299853, CI:0.9257402235811025, \n",
      "it:27800, trainCI:0.9011047095512448, train_ranking:48.877784729003906, train_RAE:0.10648350417613983,  train_Gen:46.23286819458008, train_Disc:4.43981562625595e-09, train_reg:3.33323073387146, train_t_reg:3.3420796394348145, train_t_mse:116.67308044433594, train_layer_one_recon:0.0\n",
      "Iteration: 27807 epochs:299, Training: RAE:0.06991789489984512, Loss: 48.48685073852539, Ranking:40.23080825805664, Reg:3.333282947540283, Gen:45.779502868652344, Disc:3.4297422679685496e-09, Recon_One:0.0, T_Reg:2.7073466777801514,T_MSE:102.56440734863281,  CI:0.9132827324478179 Validation RAE:0.07119401644207737 Loss:45.640694691089294, Ranking:47.28406133600454, Reg:3.3553742312991472, Gen:43.28657495866675, Disc:7.453375532951405e-12, Recon_One:0.0, T_Reg:2.354119429815497, T_MSE:108.56126234563303, CI:0.9244179982071414, \n",
      "Iteration: 27900 epochs:300, Training: RAE:0.06626494228839874, Loss: 48.40419006347656, Ranking:42.384883880615234, Reg:3.3339121341705322, Gen:46.16277313232422, Disc:1.3623918659888545e-09, Recon_One:0.0, T_Reg:2.2414183616638184,T_MSE:171.0522918701172,  CI:0.9281498434112262 Validation RAE:0.07036687104932603 Loss:45.20215521876001, Ranking:47.27439627552593, Reg:3.3560075878545437, Gen:42.8699041674014, Disc:5.2173628730659834e-11, Recon_One:0.0, T_Reg:2.3322508791856382, T_MSE:110.84146732179109, CI:0.9240807863668025, \n",
      "it:27900, trainCI:0.8794124968882251, train_ranking:51.359092712402344, train_RAE:0.08551535755395889,  train_Gen:45.88483428955078, train_Disc:3.4147886740498734e-09, train_reg:3.3338990211486816, train_t_reg:3.0150880813598633, train_t_mse:90.91133880615234, train_layer_one_recon:0.0\n",
      "Iteration: 27993 epochs:301, Training: RAE:0.08970858156681061, Loss: 48.95330047607422, Ranking:46.44642639160156, Reg:3.3344852924346924, Gen:46.13709259033203, Disc:2.9376576726747317e-09, Recon_One:0.0, T_Reg:2.816206455230713,T_MSE:120.36122131347656,  CI:0.8924410579206007 Validation RAE:0.07047756457773763 Loss:45.1561572776223, Ranking:47.273842483755196, Reg:3.3565845447166778, Gen:42.83158785405123, Disc:7.453375532951405e-12, Recon_One:0.0, T_Reg:2.324569757482298, T_MSE:109.91237869825574, CI:0.924762008254788, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:28000, trainCI:0.9126150864157648, train_ranking:47.76310348510742, train_RAE:0.08062457293272018,  train_Gen:45.77656555175781, train_Disc:1.740667876504176e-08, train_reg:3.33451509475708, train_t_reg:3.0085787773132324, train_t_mse:123.62860107421875, train_layer_one_recon:0.0\n",
      "Iteration: 28086 epochs:302, Training: RAE:0.08680878579616547, Loss: 50.015541076660156, Ranking:48.11418533325195, Reg:3.3349156379699707, Gen:46.72138214111328, Disc:2.80677969755061e-09, Recon_One:0.0, T_Reg:3.2941575050354004,T_MSE:124.72013092041016,  CI:0.8650061336604619 Validation RAE:0.07056081396193002 Loss:45.97337812695844, Ranking:47.27068902612314, Reg:3.3570177423606684, Gen:43.603043665330794, Disc:0.0, Recon_One:0.0, T_Reg:2.3703350720591017, T_MSE:113.86774083860549, CI:0.9247777323526063, \n",
      "it:28100, trainCI:0.9218676401318888, train_ranking:43.552574157714844, train_RAE:0.08397326618432999,  train_Gen:46.336578369140625, train_Disc:3.4059796649721363e-10, train_reg:3.335064649581909, train_t_reg:2.432605266571045, train_t_mse:119.57698059082031, train_layer_one_recon:0.0\n",
      "Iteration: 28179 epochs:303, Training: RAE:0.0989648625254631, Loss: 49.297393798828125, Ranking:48.26837158203125, Reg:3.335559368133545, Gen:46.169189453125, Disc:9.598680961175887e-09, Recon_One:0.0, T_Reg:3.1282036304473877,T_MSE:118.0651626586914,  CI:0.8845804139701556 Validation RAE:0.06988173520954845 Loss:45.29433408438809, Ranking:47.25614602347829, Reg:3.357665738836443, Gen:42.93576097792501, Disc:2.2360126598854216e-11, Recon_One:0.0, T_Reg:2.35857315863671, T_MSE:117.52377760861984, CI:0.9247909136095233, \n",
      "it:28200, trainCI:0.8983738138037708, train_ranking:61.875755310058594, train_RAE:0.10340052843093872,  train_Gen:46.34552001953125, train_Disc:2.872543536369676e-09, train_reg:3.335970640182495, train_t_reg:2.821213483810425, train_t_mse:120.88924407958984, train_layer_one_recon:0.0\n",
      "Iteration: 28272 epochs:304, Training: RAE:0.09052247554063797, Loss: 49.54335021972656, Ranking:52.22890853881836, Reg:3.33634090423584, Gen:46.589393615722656, Disc:5.108969913791839e-10, Recon_One:0.0, T_Reg:2.9539575576782227,T_MSE:143.14834594726562,  CI:0.9094521018295972 Validation RAE:0.07065113841633924 Loss:46.385124395441316, Ranking:47.237071845476905, Reg:3.358452454557773, Gen:43.965060367753566, Disc:0.0, Recon_One:0.0, T_Reg:2.4200644033378818, T_MSE:125.09999496423707, CI:0.9239471574827037, \n",
      "it:28300, trainCI:0.9083078491335372, train_ranking:50.27460479736328, train_RAE:0.09628651291131973,  train_Gen:46.672672271728516, train_Disc:2.9309350502160214e-09, train_reg:3.3366963863372803, train_t_reg:2.7601914405822754, train_t_mse:142.78317260742188, train_layer_one_recon:0.0\n",
      "Iteration: 28365 epochs:305, Training: RAE:0.07364272326231003, Loss: 49.261409759521484, Ranking:43.45222091674805, Reg:3.337042808532715, Gen:46.410972595214844, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.850435972213745,T_MSE:113.84085083007812,  CI:0.925680473372781 Validation RAE:0.07059662512586133 Loss:47.236234396118455, Ranking:47.277676285513195, Reg:3.3591590107150626, Gen:44.90591819336731, Disc:0.0, Recon_One:0.0, T_Reg:2.330316244490045, T_MSE:111.38762087319304, CI:0.9240052795604476, \n",
      "it:28400, trainCI:0.9292293034088503, train_ranking:48.80023956298828, train_RAE:0.0930505022406578,  train_Gen:46.56454849243164, train_Disc:2.6207958025992184e-09, train_reg:3.3374738693237305, train_t_reg:2.431428909301758, train_t_mse:122.47891998291016, train_layer_one_recon:0.0\n",
      "Iteration: 28458 epochs:306, Training: RAE:0.0843343436717987, Loss: 48.71339416503906, Ranking:49.622684478759766, Reg:3.3379995822906494, Gen:46.37717056274414, Disc:8.514949301208219e-10, Recon_One:0.0, T_Reg:2.3362231254577637,T_MSE:96.68222045898438,  CI:0.918960797479469 Validation RAE:0.07175501453231033 Loss:46.60126212777026, Ranking:47.29325942163156, Reg:3.36012212547702, Gen:44.23842514188823, Disc:0.0, Recon_One:0.0, T_Reg:2.3628369493604944, T_MSE:111.4379092396923, CI:0.9229610022654118, \n",
      "it:28500, trainCI:0.9054782855520863, train_ranking:44.94390106201172, train_RAE:0.08696086704730988,  train_Gen:46.51850128173828, train_Disc:5.530329083569541e-09, train_reg:3.33821702003479, train_t_reg:2.4884791374206543, train_t_mse:106.84854125976562, train_layer_one_recon:0.0\n",
      "Iteration: 28551 epochs:307, Training: RAE:0.08814264833927155, Loss: 50.177276611328125, Ranking:50.44808578491211, Reg:3.3384904861450195, Gen:47.15217208862305, Disc:6.811959329944273e-10, Recon_One:0.0, T_Reg:3.0251057147979736,T_MSE:72.86395263671875,  CI:0.8838319051772795 Validation RAE:0.07055512410157082 Loss:46.27257510842689, Ranking:47.26813226785453, Reg:3.360616282789472, Gen:43.949147661253704, Disc:0.0, Recon_One:0.0, T_Reg:2.3234274784773605, T_MSE:113.61588929703314, CI:0.9243627822332848, \n",
      "it:28600, trainCI:0.9035817077070675, train_ranking:48.22608947753906, train_RAE:0.07571086287498474,  train_Gen:46.60100555419922, train_Disc:2.724784176066919e-09, train_reg:3.339083433151245, train_t_reg:2.653817892074585, train_t_mse:112.72283935546875, train_layer_one_recon:0.0\n",
      "Iteration: 28644 epochs:308, Training: RAE:0.08917614817619324, Loss: 49.660858154296875, Ranking:51.22623825073242, Reg:3.339463710784912, Gen:46.54669952392578, Disc:2.54293919255133e-09, Recon_One:0.0, T_Reg:3.1141583919525146,T_MSE:136.47808837890625,  CI:0.9021101699162949 Validation RAE:0.07084774609705918 Loss:46.44843780414543, Ranking:47.27387570792233, Reg:3.3615959574613656, Gen:44.08272333826082, Disc:0.0, Recon_One:0.0, T_Reg:2.365714523275599, T_MSE:115.51024515777584, CI:0.9247720758289687, \n",
      "it:28700, trainCI:0.9158421108628577, train_ranking:48.47300338745117, train_RAE:0.08406911790370941,  train_Gen:46.78192138671875, train_Disc:2.059962866951537e-09, train_reg:3.3397216796875, train_t_reg:2.8311705589294434, train_t_mse:69.45787811279297, train_layer_one_recon:0.0\n",
      "Iteration: 28737 epochs:309, Training: RAE:0.09449455142021179, Loss: 48.937599182128906, Ranking:50.4708251953125, Reg:3.3398783206939697, Gen:46.38985061645508, Disc:1.5326908631152492e-09, Recon_One:0.0, T_Reg:2.547747850418091,T_MSE:143.9012451171875,  CI:0.9169728516023679 Validation RAE:0.07018506095117072 Loss:45.80665842151439, Ranking:47.26078071131533, Reg:3.3620133151915037, Gen:43.51832103741173, Disc:7.453375532951405e-12, Recon_One:0.0, T_Reg:2.2883373788852936, T_MSE:114.9573449300232, CI:0.9242233411414117, *\n",
      "it:28800, trainCI:0.908037794460264, train_ranking:39.18115997314453, train_RAE:0.06542640179395676,  train_Gen:47.4080810546875, train_Disc:5.108969358680326e-10, train_reg:3.340284824371338, train_t_reg:2.5400712490081787, train_t_mse:98.60377502441406, train_layer_one_recon:0.0\n",
      "Iteration: 28830 epochs:310, Training: RAE:0.09713078290224075, Loss: 49.61186218261719, Ranking:48.06828689575195, Reg:3.3405044078826904, Gen:47.03369903564453, Disc:2.7368249888581886e-09, Recon_One:0.0, T_Reg:2.578162908554077,T_MSE:99.44281005859375,  CI:0.8911128903122498 Validation RAE:0.0704450623632014 Loss:46.33269348755112, Ranking:47.26517715349158, Reg:3.3626435517638686, Gen:44.0213182322216, Disc:0.0, Recon_One:0.0, T_Reg:2.311375203155884, T_MSE:116.41635100543685, CI:0.9242781938522825, \n",
      "it:28900, trainCI:0.9174712267495773, train_ranking:46.87667465209961, train_RAE:0.08875632286071777,  train_Gen:47.23469924926758, train_Disc:3.4059796649721363e-10, train_reg:3.340613603591919, train_t_reg:3.02364444732666, train_t_mse:126.1124496459961, train_layer_one_recon:0.0\n",
      "Iteration: 28923 epochs:311, Training: RAE:0.07530827075242996, Loss: 49.97523498535156, Ranking:39.06263732910156, Reg:3.3408591747283936, Gen:47.03643798828125, Disc:3.2356812784684053e-09, Recon_One:0.0, T_Reg:2.938796043395996,T_MSE:145.6103973388672,  CI:0.9190182438640242 Validation RAE:0.07083240753917586 Loss:46.37668278570009, Ranking:47.24458568287265, Reg:3.3630006698216293, Gen:44.01042504624842, Disc:2.2360126598854216e-11, Recon_One:0.0, T_Reg:2.366257562061332, T_MSE:118.64509258148624, CI:0.9244994210106952, \n",
      "it:29000, trainCI:0.9033635187580854, train_ranking:39.57028579711914, train_RAE:0.08324628323316574,  train_Gen:47.85120391845703, train_Disc:1.3152878786115707e-09, train_reg:3.341515064239502, train_t_reg:2.547332525253296, train_t_mse:89.3958969116211, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29016 epochs:312, Training: RAE:0.08223027735948563, Loss: 49.312583923339844, Ranking:51.05017852783203, Reg:3.341811180114746, Gen:46.749168395996094, Disc:3.164722928161723e-09, Recon_One:0.0, T_Reg:2.5634148120880127,T_MSE:120.36531066894531,  CI:0.9187694782346436 Validation RAE:0.06942281987934064 Loss:46.0876428829039, Ranking:47.25963005322553, Reg:3.363958984609692, Gen:43.79327856810134, Disc:0.0, Recon_One:0.0, T_Reg:2.29436410089068, T_MSE:115.38653806014047, CI:0.9246925212350567, \n",
      "it:29100, trainCI:0.9083866271512504, train_ranking:49.24452209472656, train_RAE:0.07986056059598923,  train_Gen:47.298133850097656, train_Disc:2.14640971663016e-09, train_reg:3.34210205078125, train_t_reg:2.3350093364715576, train_t_mse:87.9350814819336, train_layer_one_recon:0.0\n",
      "Iteration: 29109 epochs:313, Training: RAE:0.08551257103681564, Loss: 49.79695129394531, Ranking:53.54292297363281, Reg:3.342233657836914, Gen:47.415618896484375, Disc:1.7177983480110015e-09, Recon_One:0.0, T_Reg:2.381333112716675,T_MSE:109.4869155883789,  CI:0.909584956475737 Validation RAE:0.06861277520880187 Loss:46.54004768504193, Ranking:47.249257267900326, Reg:3.364384262296756, Gen:44.23749019045136, Disc:7.453375532951405e-12, Recon_One:0.0, T_Reg:2.302557625024635, T_MSE:119.46120901943759, CI:0.9251669426946413, \n",
      "it:29200, trainCI:0.8940553575172993, train_ranking:48.87436294555664, train_RAE:0.09559447318315506,  train_Gen:47.876739501953125, train_Disc:2.0658008637042258e-09, train_reg:3.342930316925049, train_t_reg:3.0618820190429688, train_t_mse:137.76466369628906, train_layer_one_recon:0.0\n",
      "Iteration: 29202 epochs:314, Training: RAE:0.09243720769882202, Loss: 50.29474639892578, Ranking:50.875919342041016, Reg:3.3429369926452637, Gen:47.4041633605957, Disc:8.514949301208219e-10, Recon_One:0.0, T_Reg:2.89058256149292,T_MSE:149.79180908203125,  CI:0.8882692892629017 Validation RAE:0.06858921963039064 Loss:46.15773368779161, Ranking:47.256808002486714, Reg:3.365092258446214, Gen:43.88611173277961, Disc:0.0, Recon_One:0.0, T_Reg:2.271621506318787, T_MSE:112.15826160716641, CI:0.9250227791839515, *\n",
      "Iteration: 29295 epochs:315, Training: RAE:0.08539745956659317, Loss: 50.608551025390625, Ranking:50.7021369934082, Reg:3.3437671661376953, Gen:47.31608581542969, Disc:8.874295742700156e-10, Recon_One:0.0, T_Reg:3.292463779449463,T_MSE:154.9558563232422,  CI:0.8980089394555059 Validation RAE:0.0696556447000448 Loss:46.47463731382942, Ranking:47.26338855800173, Reg:3.365927933901269, Gen:44.14384311715618, Disc:0.0, Recon_One:0.0, T_Reg:2.330793821023109, T_MSE:117.73288216876495, CI:0.9251995325739476, \n",
      "it:29300, trainCI:0.8907591504744691, train_ranking:45.2512092590332, train_RAE:0.08225953578948975,  train_Gen:47.50736999511719, train_Disc:-0.0, train_reg:3.3438167572021484, train_t_reg:2.818392515182495, train_t_mse:115.03817749023438, train_layer_one_recon:0.0\n",
      "Iteration: 29388 epochs:316, Training: RAE:0.10782032459974289, Loss: 50.50115966796875, Ranking:60.83824920654297, Reg:3.344355583190918, Gen:47.660911560058594, Disc:2.095193574191967e-09, Recon_One:0.0, T_Reg:2.8402462005615234,T_MSE:120.37544250488281,  CI:0.9229122972221033 Validation RAE:0.07006264661693924 Loss:46.434010501740886, Ranking:47.27865164020859, Reg:3.366520250679866, Gen:44.11671316383689, Disc:0.0, Recon_One:0.0, T_Reg:2.317297317034545, T_MSE:112.638634312849, CI:0.9255059708499098, \n",
      "it:29400, trainCI:0.9108267419013553, train_ranking:50.89248275756836, train_RAE:0.08428699523210526,  train_Gen:47.14920425415039, train_Disc:6.811960440167297e-10, train_reg:3.344627857208252, train_t_reg:2.7982547283172607, train_t_mse:125.93121337890625, train_layer_one_recon:0.0\n",
      "Iteration: 29481 epochs:317, Training: RAE:0.08167480677366257, Loss: 50.84056854248047, Ranking:47.00141525268555, Reg:3.3450517654418945, Gen:48.420936584472656, Disc:6.811959329944273e-10, Recon_One:0.0, T_Reg:2.419633626937866,T_MSE:107.7135009765625,  CI:0.9123181271195712 Validation RAE:0.06969170450392821 Loss:47.320016563065394, Ranking:47.26412483225826, Reg:3.3672210468684822, Gen:45.003873556274705, Disc:0.0, Recon_One:0.0, T_Reg:2.3161427772267245, T_MSE:113.11944978481921, CI:0.924832948326463, \n",
      "it:29500, trainCI:0.9117566155031083, train_ranking:46.861759185791016, train_RAE:0.09071553498506546,  train_Gen:47.83073806762695, train_Disc:4.3497880852783055e-09, train_reg:3.3454372882843018, train_t_reg:2.728123903274536, train_t_mse:116.46524047851562, train_layer_one_recon:0.0\n",
      "Iteration: 29574 epochs:318, Training: RAE:0.07989071309566498, Loss: 49.725093841552734, Ranking:52.56729507446289, Reg:3.3464951515197754, Gen:47.62120056152344, Disc:-0.0, Recon_One:0.0, T_Reg:2.1038930416107178,T_MSE:85.48696899414062,  CI:0.931149307085843 Validation RAE:0.07065533937175258 Loss:45.76185922168323, Ranking:47.260454146134876, Reg:3.3686739989663863, Gen:43.41415726305232, Disc:7.453375411475209e-11, Recon_One:0.0, T_Reg:2.3477023447157666, T_MSE:115.86932928484352, CI:0.9245939212817412, \n",
      "it:29600, trainCI:0.927536231884058, train_ranking:49.65428924560547, train_RAE:0.08659390360116959,  train_Gen:47.995357513427734, train_Disc:1.7029898324860682e-10, train_reg:3.3468289375305176, train_t_reg:2.3741307258605957, train_t_mse:153.4266357421875, train_layer_one_recon:0.0\n",
      "Iteration: 29667 epochs:319, Training: RAE:0.08405859023332596, Loss: 50.65290832519531, Ranking:52.08806610107422, Reg:3.347062110900879, Gen:48.066650390625, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.5862598419189453,T_MSE:124.77615356445312,  CI:0.9176656307039613 Validation RAE:0.07025237259595592 Loss:46.647751753190406, Ranking:47.28575259637159, Reg:3.369244715862458, Gen:44.34202777842991, Disc:0.0, Recon_One:0.0, T_Reg:2.3057242043244623, T_MSE:109.52300214463358, CI:0.9251500250184408, \n",
      "it:29700, trainCI:0.8795091570574088, train_ranking:41.12665939331055, train_RAE:0.07954847067594528,  train_Gen:47.385719299316406, train_Disc:1.19209286886246e-09, train_reg:3.347120761871338, train_t_reg:3.105135679244995, train_t_mse:134.2595672607422, train_layer_one_recon:0.0\n",
      "Iteration: 29760 epochs:320, Training: RAE:0.08877280354499817, Loss: 50.16362380981445, Ranking:50.67544174194336, Reg:3.3476736545562744, Gen:47.75215530395508, Disc:1.56365431713823e-09, Recon_One:0.0, T_Reg:2.4114670753479004,T_MSE:86.6382827758789,  CI:0.9073005265289591 Validation RAE:0.07020021282528674 Loss:47.975104979400236, Ranking:47.24819042152862, Reg:3.369860312514444, Gen:45.58099720706728, Disc:0.0, Recon_One:0.0, T_Reg:2.3941078036371373, T_MSE:117.491846345761, CI:0.9253096012586751, \n",
      "it:29800, trainCI:0.9047460818519134, train_ranking:46.31159973144531, train_RAE:0.07564514130353928,  train_Gen:48.473411560058594, train_Disc:-0.0, train_reg:3.3477296829223633, train_t_reg:2.66780424118042, train_t_mse:103.3223648071289, train_layer_one_recon:0.0\n",
      "Iteration: 29853 epochs:321, Training: RAE:0.07807415723800659, Loss: 50.347660064697266, Ranking:49.16581344604492, Reg:3.3483145236968994, Gen:48.02017593383789, Disc:6.977737276869789e-10, Recon_One:0.0, T_Reg:2.3274834156036377,T_MSE:110.07005310058594,  CI:0.9098364937575093 Validation RAE:0.07015246319367585 Loss:47.137324214056164, Ranking:47.264688641365815, Reg:3.370505429005882, Gen:44.819175903389, Disc:0.0, Recon_One:0.0, T_Reg:2.318148248058804, T_MSE:111.28557993946217, CI:0.9252613391762627, \n",
      "it:29900, trainCI:0.9075033054208903, train_ranking:46.69430160522461, train_RAE:0.08727975934743881,  train_Gen:48.01923370361328, train_Disc:3.4059796649721363e-10, train_reg:3.3484151363372803, train_t_reg:2.7699460983276367, train_t_mse:113.62020874023438, train_layer_one_recon:0.0\n",
      "Iteration: 29946 epochs:322, Training: RAE:0.08831939101219177, Loss: 50.86363983154297, Ranking:47.628089904785156, Reg:3.348231315612793, Gen:47.718910217285156, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:3.1447300910949707,T_MSE:130.67294311523438,  CI:0.8932121859967932 Validation RAE:0.07106530377253512 Loss:47.399765750207166, Ranking:47.287644537386335, Reg:3.370421669461421, Gen:45.02137668195092, Disc:0.0, Recon_One:0.0, T_Reg:2.378389136081966, T_MSE:111.09692644026482, CI:0.9254707862349898, \n",
      "it:30000, trainCI:0.9257888683302495, train_ranking:51.614715576171875, train_RAE:0.07702477276325226,  train_Gen:48.04113006591797, train_Disc:2.02355288081435e-09, train_reg:3.348433494567871, train_t_reg:2.4887356758117676, train_t_mse:152.51397705078125, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 30039 epochs:323, Training: RAE:0.06111913546919823, Loss: 50.74469757080078, Ranking:42.6590690612793, Reg:3.3490943908691406, Gen:48.344810485839844, Disc:1.6355128362732785e-09, Recon_One:0.0, T_Reg:2.3998868465423584,T_MSE:180.79058837890625,  CI:0.9504843270561338 Validation RAE:0.06888654083945206 Loss:47.433504808451424, Ranking:47.25131933668546, Reg:3.371290464736349, Gen:45.15563938130852, Disc:0.0, Recon_One:0.0, T_Reg:2.2778654271429057, T_MSE:115.20241740585581, CI:0.9251133354568649, \n",
      "it:30100, trainCI:0.9063236324269248, train_ranking:40.125831604003906, train_RAE:0.06537528336048126,  train_Gen:48.31440734863281, train_Disc:1.0217939827583677e-09, train_reg:3.349536895751953, train_t_reg:2.5440635681152344, train_t_mse:72.86380767822266, train_layer_one_recon:0.0\n",
      "Iteration: 30132 epochs:324, Training: RAE:0.07555617392063141, Loss: 50.699615478515625, Ranking:44.452972412109375, Reg:3.3497414588928223, Gen:48.43750762939453, Disc:-0.0, Recon_One:0.0, T_Reg:2.26210618019104,T_MSE:138.32687377929688,  CI:0.9276809419369734 Validation RAE:0.07126076412253847 Loss:46.52955636123098, Ranking:47.28079384768831, Reg:3.37194182119385, Gen:44.15563285477507, Disc:7.453375532951405e-12, Recon_One:0.0, T_Reg:2.373923464717009, T_MSE:110.45931026281767, CI:0.9249599865821032, \n",
      "it:30200, trainCI:0.9217410064182083, train_ranking:47.60211944580078, train_RAE:0.07870718091726303,  train_Gen:48.1169319152832, train_Disc:1.7597563406468453e-09, train_reg:3.350088596343994, train_t_reg:2.27211856842041, train_t_mse:133.3141326904297, train_layer_one_recon:0.0\n",
      "Iteration: 30225 epochs:325, Training: RAE:0.08093108236789703, Loss: 50.915096282958984, Ranking:50.6060676574707, Reg:3.3499813079833984, Gen:48.36033630371094, Disc:3.2218729906219323e-09, Recon_One:0.0, T_Reg:2.5547590255737305,T_MSE:113.42997741699219,  CI:0.9218694437388875 Validation RAE:0.06939565209231408 Loss:47.53228743642483, Ranking:47.26059021496007, Reg:3.37218325988075, Gen:45.24857104979888, Disc:0.0, Recon_One:0.0, T_Reg:2.2837160474973515, T_MSE:113.49901569266758, CI:0.924919975758942, \n",
      "it:30300, trainCI:0.9138431752178122, train_ranking:50.18296813964844, train_RAE:0.08427943289279938,  train_Gen:48.12615966796875, train_Disc:6.811959329944273e-10, train_reg:3.3505640029907227, train_t_reg:2.426321268081665, train_t_mse:92.35113525390625, train_layer_one_recon:0.0\n",
      "Iteration: 30318 epochs:326, Training: RAE:0.08686060458421707, Loss: 50.76441192626953, Ranking:45.07804870605469, Reg:3.3504724502563477, Gen:48.25135040283203, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.5130615234375,T_MSE:94.52371215820312,  CI:0.905779394214923 Validation RAE:0.06989826039141292 Loss:46.906341957243974, Ranking:47.26468296487495, Reg:3.372677657191897, Gen:44.619117499262416, Disc:7.453375532951405e-12, Recon_One:0.0, T_Reg:2.287224499720461, T_MSE:111.86980070643862, CI:0.9247723353025301, \n",
      "it:30400, trainCI:0.9277414473328649, train_ranking:47.56566619873047, train_RAE:0.09152146428823471,  train_Gen:49.06338882446289, train_Disc:-0.0, train_reg:3.3510782718658447, train_t_reg:2.6562492847442627, train_t_mse:144.28790283203125, train_layer_one_recon:0.0\n",
      "Iteration: 30411 epochs:327, Training: RAE:0.08210233598947525, Loss: 51.14659118652344, Ranking:50.730655670166016, Reg:3.3512990474700928, Gen:48.45082092285156, Disc:5.369787947628879e-10, Recon_One:0.0, T_Reg:2.695770025253296,T_MSE:147.310546875,  CI:0.9059559534103047 Validation RAE:0.06891468394726116 Loss:46.840086122803555, Ranking:47.22039131010951, Reg:3.373509732666531, Gen:44.48811627781897, Disc:0.0, Recon_One:0.0, T_Reg:2.351970048461748, T_MSE:124.15963349766294, CI:0.9251080940909255, \n",
      "it:30500, trainCI:0.9202301352822267, train_ranking:49.2353401184082, train_RAE:0.09084130078554153,  train_Gen:48.50053024291992, train_Disc:-0.0, train_reg:3.3519914150238037, train_t_reg:2.139193534851074, train_t_mse:116.01689147949219, train_layer_one_recon:0.0\n",
      "Iteration: 30504 epochs:328, Training: RAE:0.08952593058347702, Loss: 50.775516510009766, Ranking:46.017005920410156, Reg:3.351991653442383, Gen:48.55015563964844, Disc:-0.0, Recon_One:0.0, T_Reg:2.2253623008728027,T_MSE:115.28471374511719,  CI:0.9341494773324389 Validation RAE:0.070090950321701 Loss:47.501910196418564, Ranking:47.2644537348173, Reg:3.3742069288747256, Gen:45.242539778253025, Disc:0.0, Recon_One:0.0, T_Reg:2.2593703920787256, T_MSE:113.56070746149557, CI:0.9252526727593134, *\n",
      "Iteration: 30597 epochs:329, Training: RAE:0.08522514998912811, Loss: 51.55109405517578, Ranking:51.09632873535156, Reg:3.3529157638549805, Gen:49.04899215698242, Disc:6.811960440167297e-10, Recon_One:0.0, T_Reg:2.502100706100464,T_MSE:114.0108871459961,  CI:0.9053328027061984 Validation RAE:0.0691112396173944 Loss:48.76776465448988, Ranking:47.222528842832055, Reg:3.3751371638155048, Gen:46.442442428056516, Disc:0.0, Recon_One:0.0, T_Reg:2.325322231650725, T_MSE:121.30793411314033, CI:0.9254084606855519, \n",
      "it:30600, trainCI:0.9199264376957105, train_ranking:51.9103889465332, train_RAE:0.093106210231781,  train_Gen:48.75716781616211, train_Disc:1.7029898324860682e-10, train_reg:3.352884292602539, train_t_reg:2.523042678833008, train_t_mse:112.31459045410156, train_layer_one_recon:0.0\n",
      "Iteration: 30690 epochs:330, Training: RAE:0.08580467849969864, Loss: 51.405479431152344, Ranking:45.83413314819336, Reg:3.353250741958618, Gen:48.825904846191406, Disc:-0.0, Recon_One:0.0, T_Reg:2.579573392868042,T_MSE:138.81837463378906,  CI:0.9099219620958752 Validation RAE:0.06986359231909081 Loss:47.62110965943894, Ranking:47.257785861516304, Reg:3.3754743619816026, Gen:45.31639526527465, Disc:0.0, Recon_One:0.0, T_Reg:2.304714477642098, T_MSE:114.41721113022975, CI:0.9252225219314838, \n",
      "it:30700, trainCI:0.905803012998314, train_ranking:47.146095275878906, train_RAE:0.08966652303934097,  train_Gen:48.627254486083984, train_Disc:1.0217938717360653e-09, train_reg:3.353205680847168, train_t_reg:2.8092453479766846, train_t_mse:120.31918334960938, train_layer_one_recon:0.0\n",
      "Iteration: 30783 epochs:331, Training: RAE:0.08661806583404541, Loss: 51.43428421020508, Ranking:49.21983337402344, Reg:3.353923797607422, Gen:48.9569091796875, Disc:1.3623920880334595e-09, Recon_One:0.0, T_Reg:2.4773757457733154,T_MSE:86.97848510742188,  CI:0.9358386323360783 Validation RAE:0.07334760152296348 Loss:48.66791100625442, Ranking:47.30465848311433, Reg:3.3761518782968296, Gen:46.30245431983741, Disc:0.0, Recon_One:0.0, T_Reg:2.365456535113488, T_MSE:105.46869142243038, CI:0.9250606623239096, \n",
      "it:30800, trainCI:0.9266059817945383, train_ranking:49.489219665527344, train_RAE:0.08253338932991028,  train_Gen:48.86565399169922, train_Disc:5.468315800172263e-10, train_reg:3.353994846343994, train_t_reg:2.7398486137390137, train_t_mse:108.55763244628906, train_layer_one_recon:0.0\n",
      "Iteration: 30876 epochs:332, Training: RAE:0.09677055478096008, Loss: 51.227684020996094, Ranking:40.6818962097168, Reg:3.3547825813293457, Gen:48.459739685058594, Disc:8.514949301208219e-10, Recon_One:0.0, T_Reg:2.7679431438446045,T_MSE:136.3292999267578,  CI:0.925916529240137 Validation RAE:0.06756663687664136 Loss:48.85258812359963, Ranking:47.248665243294056, Reg:3.3770163535952524, Gen:46.61405443384958, Disc:0.0, Recon_One:0.0, T_Reg:2.238533569750703, T_MSE:114.91072791746979, CI:0.9257283396919924, *\n",
      "it:30900, trainCI:0.8937982280651615, train_ranking:44.7696647644043, train_RAE:0.08417712152004242,  train_Gen:48.71855926513672, train_Disc:3.4059796649721363e-10, train_reg:3.3548905849456787, train_t_reg:3.0031747817993164, train_t_mse:131.25953674316406, train_layer_one_recon:0.0\n",
      "Iteration: 30969 epochs:333, Training: RAE:0.08139186352491379, Loss: 51.5933723449707, Ranking:40.61957550048828, Reg:3.35538911819458, Gen:48.88875198364258, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.704620122909546,T_MSE:103.76729583740234,  CI:0.9326603548811838 Validation RAE:0.07186808196085459 Loss:46.962522521262855, Ranking:47.3000980905254, Reg:3.3776269102746492, Gen:44.624588634724226, Disc:0.0, Recon_One:0.0, T_Reg:2.3379338343649994, T_MSE:104.8873225912476, CI:0.9243517805542832, \n",
      "it:31000, trainCI:0.9345753355915193, train_ranking:40.79815673828125, train_RAE:0.07364609092473984,  train_Gen:49.000457763671875, train_Disc:1.19209286886246e-09, train_reg:3.3554556369781494, train_t_reg:2.2082715034484863, train_t_mse:132.08506774902344, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31062 epochs:334, Training: RAE:0.08400285243988037, Loss: 51.55592727661133, Ranking:46.05029296875, Reg:3.3556439876556396, Gen:48.98506164550781, Disc:-0.0, Recon_One:0.0, T_Reg:2.570863962173462,T_MSE:107.7196044921875,  CI:0.9225971711771912 Validation RAE:0.06943165042914047 Loss:47.6861071494187, Ranking:47.275097322147964, Reg:3.377883468879317, Gen:45.41290295605542, Disc:0.0, Recon_One:0.0, T_Reg:2.273204386405711, T_MSE:108.40227619117239, CI:0.9259637860015675, \n",
      "it:31100, trainCI:0.9095673505798394, train_ranking:45.86496353149414, train_RAE:0.0832575261592865,  train_Gen:48.88985824584961, train_Disc:1.7029898324860682e-10, train_reg:3.3559231758117676, train_t_reg:2.3896820545196533, train_t_mse:84.61874389648438, train_layer_one_recon:0.0\n",
      "Iteration: 31155 epochs:335, Training: RAE:0.0861467719078064, Loss: 51.9666862487793, Ranking:49.37324905395508, Reg:3.356520652770996, Gen:48.97696304321289, Disc:-0.0, Recon_One:0.0, T_Reg:2.9897241592407227,T_MSE:136.50682067871094,  CI:0.9100589862713369 Validation RAE:0.06984801392555536 Loss:47.87655692406411, Ranking:47.2804933275836, Reg:3.3787659440798445, Gen:45.58200879113084, Disc:0.0, Recon_One:0.0, T_Reg:2.2945479555429333, T_MSE:110.52987405295907, CI:0.9256583856198507, \n",
      "it:31200, trainCI:0.896316575410652, train_ranking:51.56710433959961, train_RAE:0.09598645567893982,  train_Gen:48.539642333984375, train_Disc:1.8703778525974712e-09, train_reg:3.3569579124450684, train_t_reg:3.001681089401245, train_t_mse:120.0517578125, train_layer_one_recon:0.0\n",
      "Iteration: 31248 epochs:336, Training: RAE:0.08811559528112411, Loss: 52.13956832885742, Ranking:51.37187194824219, Reg:3.357393264770508, Gen:49.43229293823242, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.707275867462158,T_MSE:122.7004623413086,  CI:0.9136007237635706 Validation RAE:0.06926139499640425 Loss:47.5798235396318, Ranking:47.26304796854973, Reg:3.379644339302562, Gen:45.30506632514964, Disc:0.0, Recon_One:0.0, T_Reg:2.2747575692628432, T_MSE:116.60398173454449, CI:0.923982964834171, \n",
      "it:31300, trainCI:0.9066120218579234, train_ranking:47.00712203979492, train_RAE:0.07852810621261597,  train_Gen:48.45640182495117, train_Disc:6.811959329944273e-10, train_reg:3.3580210208892822, train_t_reg:3.2828521728515625, train_t_mse:137.29391479492188, train_layer_one_recon:0.0\n",
      "Iteration: 31341 epochs:337, Training: RAE:0.0886269137263298, Loss: 51.75529861450195, Ranking:48.47726058959961, Reg:3.358149766921997, Gen:49.16102981567383, Disc:1.0527573257590461e-09, Recon_One:0.0, T_Reg:2.594269037246704,T_MSE:113.68064880371094,  CI:0.9068765622507047 Validation RAE:0.0686531114568185 Loss:47.45284745107968, Ranking:47.26663384122134, Reg:3.380405855160945, Gen:45.17706512912923, Disc:0.0, Recon_One:0.0, T_Reg:2.275782431515065, T_MSE:112.476573503806, CI:0.9244972933274921, \n",
      "it:31400, trainCI:0.9057059474690551, train_ranking:51.03387451171875, train_RAE:0.09075025469064713,  train_Gen:49.641693115234375, train_Disc:1.7029898324860682e-10, train_reg:3.3584442138671875, train_t_reg:2.8525612354278564, train_t_mse:132.58607482910156, train_layer_one_recon:0.0\n",
      "Iteration: 31434 epochs:338, Training: RAE:0.08022086322307587, Loss: 51.341617584228516, Ranking:53.88922119140625, Reg:3.35868501663208, Gen:49.409976959228516, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:1.931640386581421,T_MSE:112.94892120361328,  CI:0.939628779181018 Validation RAE:0.06849331814109556 Loss:47.66011282818398, Ranking:47.258898787637406, Reg:3.380944652230617, Gen:45.42479403573184, Disc:0.0, Recon_One:0.0, T_Reg:2.235319016798744, T_MSE:113.4331286631779, CI:0.9248814179877244, *\n",
      "it:31500, trainCI:0.9024176051244963, train_ranking:49.55134582519531, train_RAE:0.07472897320985794,  train_Gen:49.513179779052734, train_Disc:2.5766975220165023e-09, train_reg:3.35935115814209, train_t_reg:2.373368978500366, train_t_mse:95.64012908935547, train_layer_one_recon:0.0\n",
      "Iteration: 31527 epochs:339, Training: RAE:0.067421093583107, Loss: 51.67523193359375, Ranking:46.870235443115234, Reg:3.359015941619873, Gen:49.24018478393555, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.4350452423095703,T_MSE:99.45868682861328,  CI:0.9217648023618172 Validation RAE:0.06886728290071097 Loss:49.528053472589754, Ranking:47.25365972047867, Reg:3.381277770418904, Gen:47.21737959779351, Disc:0.0, Recon_One:0.0, T_Reg:2.3106740104476855, T_MSE:115.0519810483741, CI:0.9256593197246715, \n",
      "it:31600, trainCI:0.9070972469381346, train_ranking:48.94448471069336, train_RAE:0.08968765288591385,  train_Gen:49.87928009033203, train_Disc:1.7029898324860682e-10, train_reg:3.3594610691070557, train_t_reg:2.791034460067749, train_t_mse:124.31240844726562, train_layer_one_recon:0.0\n",
      "Iteration: 31620 epochs:340, Training: RAE:0.08034772425889969, Loss: 52.401092529296875, Ranking:51.151004791259766, Reg:3.3596134185791016, Gen:49.3065071105957, Disc:1.3955474553739577e-09, Recon_One:0.0, T_Reg:3.094586133956909,T_MSE:188.7372589111328,  CI:0.9057030778515389 Validation RAE:0.06867478014331796 Loss:48.09926102068091, Ranking:47.21921661041134, Reg:3.3818792071479016, Gen:45.711899089920564, Disc:0.0, Recon_One:0.0, T_Reg:2.3873614611976874, T_MSE:126.1874767158931, CI:0.9255045177979662, \n",
      "it:31700, trainCI:0.902381735331423, train_ranking:54.63684844970703, train_RAE:0.08146446943283081,  train_Gen:49.59333801269531, train_Disc:-0.0, train_reg:3.3608639240264893, train_t_reg:2.3991611003875732, train_t_mse:124.65898132324219, train_layer_one_recon:0.0\n",
      "Iteration: 31713 epochs:341, Training: RAE:0.09598993510007858, Loss: 51.729793548583984, Ranking:46.94438552856445, Reg:3.3607611656188965, Gen:48.938743591308594, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.791050434112549,T_MSE:106.86973571777344,  CI:0.9108217529270161 Validation RAE:0.06870723051031008 Loss:47.92142056876217, Ranking:47.25863199256667, Reg:3.383034560864339, Gen:45.615376206178944, Disc:0.0, Recon_One:0.0, T_Reg:2.306044305192242, T_MSE:114.23217656091555, CI:0.9253881179583416, \n",
      "it:31800, trainCI:0.9040902056157417, train_ranking:59.116363525390625, train_RAE:0.17023338377475739,  train_Gen:49.4537467956543, train_Disc:1.7029898324860682e-10, train_reg:3.3610010147094727, train_t_reg:4.4479475021362305, train_t_mse:111.42365264892578, train_layer_one_recon:0.0\n",
      "Iteration: 31806 epochs:342, Training: RAE:0.08482768386602402, Loss: 52.22535705566406, Ranking:51.8931999206543, Reg:3.3609728813171387, Gen:49.728736877441406, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.496621608734131,T_MSE:115.4454116821289,  CI:0.9172389940214437 Validation RAE:0.06861133684705939 Loss:48.28838884077684, Ranking:47.254510526286225, Reg:3.3832476797052604, Gen:45.976062773227156, Disc:0.0, Recon_One:0.0, T_Reg:2.3123260884191357, T_MSE:116.98742101263132, CI:0.9256509127812836, \n",
      "Iteration: 31899 epochs:343, Training: RAE:0.09623599797487259, Loss: 52.192359924316406, Ranking:50.873329162597656, Reg:3.3614044189453125, Gen:49.261146545410156, Disc:1.0936631600344526e-09, Recon_One:0.0, T_Reg:2.9312140941619873,T_MSE:110.37258911132812,  CI:0.8955322278005984 Validation RAE:0.06871690399030812 Loss:48.05229757522902, Ranking:47.25850961410181, Reg:3.383682077342724, Gen:45.77423363786139, Disc:0.0, Recon_One:0.0, T_Reg:2.278064365191386, T_MSE:113.30564770084986, CI:0.9257109030686692, \n",
      "it:31900, trainCI:0.9042053689905073, train_ranking:50.54847717285156, train_RAE:0.08373630791902542,  train_Gen:49.448158264160156, train_Disc:3.4059796649721363e-10, train_reg:3.3614025115966797, train_t_reg:2.9053080081939697, train_t_mse:135.37911987304688, train_layer_one_recon:0.0\n",
      "Iteration: 31992 epochs:344, Training: RAE:0.07744108140468597, Loss: 52.28023910522461, Ranking:40.757999420166016, Reg:3.362351894378662, Gen:49.49266815185547, Disc:2.5636408551577006e-09, Recon_One:0.0, T_Reg:2.7875709533691406,T_MSE:108.3710708618164,  CI:0.8938242131054847 Validation RAE:0.06998657648717968 Loss:47.634000803241584, Ranking:47.28229761690114, Reg:3.384635832155587, Gen:45.31789536146398, Disc:0.0, Recon_One:0.0, T_Reg:2.316105238300451, T_MSE:109.73528821095387, CI:0.9249112055525681, \n",
      "it:32000, trainCI:0.8950288030723277, train_ranking:48.40313720703125, train_RAE:0.10260284692049026,  train_Gen:49.576576232910156, train_Disc:5.108969913791839e-10, train_reg:3.3624722957611084, train_t_reg:3.2173941135406494, train_t_mse:128.86627197265625, train_layer_one_recon:0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32085 epochs:345, Training: RAE:0.08044478297233582, Loss: 52.0742301940918, Ranking:50.70451354980469, Reg:3.3633010387420654, Gen:49.61857604980469, Disc:5.369787947628879e-10, Recon_One:0.0, T_Reg:2.455652952194214,T_MSE:137.78207397460938,  CI:0.920338725216774 Validation RAE:0.06888987734304512 Loss:48.08572893427717, Ranking:47.27280852763939, Reg:3.385591266959313, Gen:45.788202146239406, Disc:0.0, Recon_One:0.0, T_Reg:2.2975269549933763, T_MSE:110.97023350843358, CI:0.9253720305975375, \n",
      "it:32100, trainCI:0.9134565733760198, train_ranking:49.90132522583008, train_RAE:0.07561703771352768,  train_Gen:50.035308837890625, train_Disc:-0.0, train_reg:3.3632607460021973, train_t_reg:2.566418170928955, train_t_mse:116.78558349609375, train_layer_one_recon:0.0\n",
      "Iteration: 32178 epochs:346, Training: RAE:0.08163265138864517, Loss: 52.063133239746094, Ranking:50.20442199707031, Reg:3.363837957382202, Gen:49.787010192871094, Disc:8.514949301208219e-10, Recon_One:0.0, T_Reg:2.2761247158050537,T_MSE:135.63995361328125,  CI:0.9352079491907396 Validation RAE:0.06891138706301785 Loss:49.11894510280375, Ranking:47.26832309812102, Reg:3.386131744019848, Gen:46.83291320877104, Disc:0.0, Recon_One:0.0, T_Reg:2.2860322279439385, T_MSE:113.06209251763478, CI:0.9252102747793878, \n",
      "it:32200, trainCI:0.9169918410783966, train_ranking:43.57386779785156, train_RAE:0.08339172601699829,  train_Gen:49.124755859375, train_Disc:3.4059796649721363e-10, train_reg:3.3638651371002197, train_t_reg:2.962691307067871, train_t_mse:69.72129821777344, train_layer_one_recon:0.0\n",
      "Iteration: 32271 epochs:347, Training: RAE:0.08647648245096207, Loss: 52.20602035522461, Ranking:51.53811264038086, Reg:3.3644628524780273, Gen:49.47480010986328, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.7312216758728027,T_MSE:132.01145935058594,  CI:0.9323971915747242 Validation RAE:0.06963021347966063 Loss:49.262758998911394, Ranking:47.29098231401595, Reg:3.3867607805987396, Gen:46.96873577442768, Disc:0.0, Recon_One:0.0, T_Reg:2.2940233027441614, T_MSE:106.13172525642246, CI:0.9257281840078556, \n",
      "it:32300, trainCI:0.928101644245142, train_ranking:52.0924072265625, train_RAE:0.09520763158798218,  train_Gen:49.709896087646484, train_Disc:5.051241092068892e-10, train_reg:3.3648035526275635, train_t_reg:2.6826744079589844, train_t_mse:110.04889678955078, train_layer_one_recon:0.0\n",
      "Iteration: 32364 epochs:348, Training: RAE:0.0761152133345604, Loss: 52.519622802734375, Ranking:44.071197509765625, Reg:3.364884376525879, Gen:49.798858642578125, Disc:-0.0, Recon_One:0.0, T_Reg:2.720762252807617,T_MSE:145.77960205078125,  CI:0.9224642773483251 Validation RAE:0.06776438683375756 Loss:49.42418370706611, Ranking:47.24340246843818, Reg:3.3871850982910248, Gen:47.1348397475683, Disc:0.0, Recon_One:0.0, T_Reg:2.2893440116714414, T_MSE:118.37756524342991, CI:0.9258269915400202, \n",
      "it:32400, trainCI:0.92897204854726, train_ranking:56.41640853881836, train_RAE:0.08063221722841263,  train_Gen:49.87143325805664, train_Disc:3.4059796649721363e-10, train_reg:3.3651108741760254, train_t_reg:2.1884727478027344, train_t_mse:106.86922454833984, train_layer_one_recon:0.0\n",
      "Iteration: 32457 epochs:349, Training: RAE:0.07749113440513611, Loss: 52.434906005859375, Ranking:50.28227233886719, Reg:3.3654885292053223, Gen:49.75043869018555, Disc:-0.0, Recon_One:0.0, T_Reg:2.6844682693481445,T_MSE:135.97071838378906,  CI:0.927558490759228 Validation RAE:0.06869692540331246 Loss:49.469439363545206, Ranking:47.25065034554126, Reg:3.387793254983474, Gen:47.15226407019484, Disc:0.0, Recon_One:0.0, T_Reg:2.317175209872556, T_MSE:117.31964799185253, CI:0.9255641967170782, \n",
      "it:32500, trainCI:0.9096315025518565, train_ranking:55.152584075927734, train_RAE:0.09454112499952316,  train_Gen:49.528350830078125, train_Disc:3.4059796649721363e-10, train_reg:3.3657476902008057, train_t_reg:2.4618611335754395, train_t_mse:73.27436828613281, train_layer_one_recon:0.0\n",
      "Iteration: 32550 epochs:350, Training: RAE:0.09427807480096817, Loss: 52.364200592041016, Ranking:47.55545425415039, Reg:3.3658971786499023, Gen:49.56867218017578, Disc:-0.0, Recon_One:0.0, T_Reg:2.7955267429351807,T_MSE:130.65638732910156,  CI:0.8979514620831306 Validation RAE:0.07119938298897757 Loss:49.20340961734399, Ranking:47.277398805283184, Reg:3.388204612746244, Gen:46.85109016730426, Disc:0.0, Recon_One:0.0, T_Reg:2.3523189961291617, T_MSE:110.7366362258436, CI:0.9240840038389633, \n",
      "it:32600, trainCI:0.908821165852754, train_ranking:41.19252395629883, train_RAE:0.0819530263543129,  train_Gen:49.71720886230469, train_Disc:1.5954326748612857e-09, train_reg:3.3662829399108887, train_t_reg:2.397526979446411, train_t_mse:97.70626831054688, train_layer_one_recon:0.0\n",
      "Iteration: 32643 epochs:351, Training: RAE:0.07695743441581726, Loss: 52.66439437866211, Ranking:46.70005798339844, Reg:3.3667259216308594, Gen:50.009090423583984, Disc:-0.0, Recon_One:0.0, T_Reg:2.6553046703338623,T_MSE:122.52901458740234,  CI:0.9138488518660601 Validation RAE:0.06867530823827192 Loss:48.23810598381284, Ranking:47.250976743766095, Reg:3.3890388482091307, Gen:45.934838426997096, Disc:0.0, Recon_One:0.0, T_Reg:2.3032675515983767, T_MSE:116.53665053899607, CI:0.9262575619677353, \n",
      "it:32700, trainCI:0.8971877282688093, train_ranking:41.818546295166016, train_RAE:0.0772976353764534,  train_Gen:49.87849426269531, train_Disc:1.3165422085847922e-09, train_reg:3.366894006729126, train_t_reg:2.5278995037078857, train_t_mse:115.90176391601562, train_layer_one_recon:0.0\n",
      "Iteration: 32736 epochs:352, Training: RAE:0.0962357297539711, Loss: 52.993011474609375, Ranking:48.395904541015625, Reg:3.367175579071045, Gen:49.80132293701172, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:3.191688060760498,T_MSE:151.40545654296875,  CI:0.8928458037887607 Validation RAE:0.0705471055038768 Loss:49.55744684316433, Ranking:47.26509718175261, Reg:3.3894914857473943, Gen:47.2182686364366, Disc:0.0, Recon_One:0.0, T_Reg:2.339178227597182, T_MSE:112.55350097412018, CI:0.924503987745375, \n",
      "it:32800, trainCI:0.9308908852704473, train_ranking:55.10090637207031, train_RAE:0.08824341744184494,  train_Gen:49.610931396484375, train_Disc:1.7029898324860682e-10, train_reg:3.367802381515503, train_t_reg:2.1547040939331055, train_t_mse:103.72465515136719, train_layer_one_recon:0.0\n",
      "Iteration: 32829 epochs:353, Training: RAE:0.08506292849779129, Loss: 53.080352783203125, Ranking:49.72123336791992, Reg:3.367647171020508, Gen:49.89243698120117, Disc:-0.0, Recon_One:0.0, T_Reg:3.1879146099090576,T_MSE:169.32379150390625,  CI:0.912333985380418 Validation RAE:0.06951445943529314 Loss:50.59957810755266, Ranking:47.23018943421227, Reg:3.389966203165573, Gen:48.20951266453924, Disc:0.0, Recon_One:0.0, T_Reg:2.390065453448146, T_MSE:120.08738639996591, CI:0.9253306705118572, \n",
      "it:32900, trainCI:0.9395976400038688, train_ranking:53.24404525756836, train_RAE:0.09353359788656235,  train_Gen:50.07476806640625, train_Disc:-0.0, train_reg:3.36776065826416, train_t_reg:2.3533120155334473, train_t_mse:114.87925720214844, train_layer_one_recon:0.0\n",
      "Iteration: 32922 epochs:354, Training: RAE:0.0927836149930954, Loss: 52.50425338745117, Ranking:50.145381927490234, Reg:3.367906332015991, Gen:49.89912414550781, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.6051275730133057,T_MSE:96.34041595458984,  CI:0.9132642593352482 Validation RAE:0.06950398753572437 Loss:50.66506360879134, Ranking:47.2788902197806, Reg:3.390227081746746, Gen:48.31965895940531, Disc:0.0, Recon_One:0.0, T_Reg:2.3454046285165853, T_MSE:110.64348868374468, CI:0.9254301007805691, \n",
      "it:33000, trainCI:0.9364844903988183, train_ranking:43.58073806762695, train_RAE:0.07165036350488663,  train_Gen:50.447998046875, train_Disc:-0.0, train_reg:3.368142604827881, train_t_reg:2.3886876106262207, train_t_mse:114.77415466308594, train_layer_one_recon:0.0\n",
      "Iteration: 33015 epochs:355, Training: RAE:0.0827968567609787, Loss: 52.679473876953125, Ranking:45.91376876831055, Reg:3.3681888580322266, Gen:50.1487922668457, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.5306835174560547,T_MSE:107.72345733642578,  CI:0.9134114218461021 Validation RAE:0.06891303248885156 Loss:50.077244447472246, Ranking:47.27718927598796, Reg:3.390511480200003, Gen:47.79838763789503, Disc:0.0, Recon_One:0.0, T_Reg:2.278856861750841, T_MSE:112.37250405936832, CI:0.9252323300321031, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:33100, trainCI:0.9299965401914427, train_ranking:44.488197326660156, train_RAE:0.06879902631044388,  train_Gen:50.226470947265625, train_Disc:6.811959329944273e-10, train_reg:3.3684792518615723, train_t_reg:2.2390589714050293, train_t_mse:131.14695739746094, train_layer_one_recon:0.0\n",
      "Iteration: 33108 epochs:356, Training: RAE:0.07376903295516968, Loss: 52.477813720703125, Ranking:37.47503662109375, Reg:3.368527412414551, Gen:50.034576416015625, Disc:-0.0, Recon_One:0.0, T_Reg:2.4432384967803955,T_MSE:102.61448669433594,  CI:0.921281807048578 Validation RAE:0.0710303357018446 Loss:49.136573612145874, Ranking:47.290679623488266, Reg:3.3908522783465216, Gen:46.77327315748013, Disc:0.0, Recon_One:0.0, T_Reg:2.3633004181441986, T_MSE:108.2305055775463, CI:0.925491284646337, \n",
      "it:33200, trainCI:0.9269018743109151, train_ranking:46.97172546386719, train_RAE:0.0916629210114479,  train_Gen:50.64384841918945, train_Disc:-0.0, train_reg:3.3685097694396973, train_t_reg:2.4747564792633057, train_t_mse:90.9629135131836, train_layer_one_recon:0.0\n",
      "Iteration: 33201 epochs:357, Training: RAE:0.0916629210114479, Loss: 53.11860656738281, Ranking:46.97172546386719, Reg:3.3685097694396973, Gen:50.64384841918945, Disc:-0.0, Recon_One:0.0, T_Reg:2.4747564792633057,T_MSE:90.9629135131836,  CI:0.9269018743109151 Validation RAE:0.07009675154015022 Loss:48.986396703687895, Ranking:47.30064921100631, Reg:3.3908345184431115, Gen:46.67933207534918, Disc:0.0, Recon_One:0.0, T_Reg:2.307064732685974, T_MSE:104.85624814459841, CI:0.9251915407882578, \n",
      "Iteration: 33294 epochs:358, Training: RAE:0.08773646503686905, Loss: 54.234619140625, Ranking:42.95756149291992, Reg:3.369309902191162, Gen:50.49748611450195, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:3.737133264541626,T_MSE:131.4043731689453,  CI:0.8759866060751017 Validation RAE:0.0692967670866366 Loss:49.55600918837453, Ranking:47.27404750524885, Reg:3.3916399540626303, Gen:47.24938298547746, Disc:0.0, Recon_One:0.0, T_Reg:2.3066263072443287, T_MSE:112.06975943806381, CI:0.9245672992943461, \n",
      "it:33300, trainCI:0.9261272141706924, train_ranking:37.972408294677734, train_RAE:0.06318513303995132,  train_Gen:50.01765060424805, train_Disc:-0.0, train_reg:3.3694653511047363, train_t_reg:2.113834857940674, train_t_mse:85.403076171875, train_layer_one_recon:0.0\n",
      "Iteration: 33387 epochs:359, Training: RAE:0.07238714396953583, Loss: 54.20329284667969, Ranking:41.64113998413086, Reg:3.3697991371154785, Gen:50.72850036621094, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:3.4747941493988037,T_MSE:157.46250915527344,  CI:0.8750922509225092 Validation RAE:0.0699076076231853 Loss:49.91080322399189, Ranking:47.28041085151042, Reg:3.392132431384219, Gen:47.57229651274257, Disc:0.0, Recon_One:0.0, T_Reg:2.338506732118775, T_MSE:108.81749012775238, CI:0.9257769650373907, \n",
      "it:33400, trainCI:0.9287900005186454, train_ranking:49.87324905395508, train_RAE:0.09055575728416443,  train_Gen:50.21115493774414, train_Disc:6.811960440167297e-10, train_reg:3.370067596435547, train_t_reg:2.287517786026001, train_t_mse:125.87348937988281, train_layer_one_recon:0.0\n",
      "Iteration: 33480 epochs:360, Training: RAE:0.08880431950092316, Loss: 53.32572937011719, Ranking:48.5762939453125, Reg:3.370511293411255, Gen:50.55572509765625, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.7700047492980957,T_MSE:102.36783599853516,  CI:0.9083678014635699 Validation RAE:0.06901962386566027 Loss:49.748086112431324, Ranking:47.26926205649262, Reg:3.392849307485382, Gen:47.46341206840505, Disc:0.0, Recon_One:0.0, T_Reg:2.2846741848950747, T_MSE:112.7690800729656, CI:0.9248442613737381, \n",
      "it:33500, trainCI:0.9197780265783966, train_ranking:53.08761215209961, train_RAE:0.07817590236663818,  train_Gen:50.732200622558594, train_Disc:-0.0, train_reg:3.370847463607788, train_t_reg:2.609527349472046, train_t_mse:136.9766082763672, train_layer_one_recon:0.0\n",
      "Iteration: 33573 epochs:361, Training: RAE:0.0790741816163063, Loss: 52.67030715942383, Ranking:44.948482513427734, Reg:3.3711893558502197, Gen:50.34376525878906, Disc:-0.0, Recon_One:0.0, T_Reg:2.3265411853790283,T_MSE:114.85572052001953,  CI:0.9279361459521095 Validation RAE:0.07153688734906218 Loss:49.251309349877666, Ranking:47.25763977535429, Reg:3.3935318637731986, Gen:46.836721132408904, Disc:0.0, Recon_One:0.0, T_Reg:2.4145881079041365, T_MSE:116.33091714660331, CI:0.9243578003409068, \n",
      "it:33600, trainCI:0.8927536231884058, train_ranking:55.94483184814453, train_RAE:0.09130672365427017,  train_Gen:50.51038360595703, train_Disc:-0.0, train_reg:3.3716444969177246, train_t_reg:2.822495460510254, train_t_mse:118.30331420898438, train_layer_one_recon:0.0\n",
      "Iteration: 33666 epochs:362, Training: RAE:0.08359923213720322, Loss: 53.795963287353516, Ranking:48.3476448059082, Reg:3.371886730194092, Gen:50.66789245605469, Disc:2.187326764158115e-09, Recon_One:0.0, T_Reg:3.1280720233917236,T_MSE:159.47860717773438,  CI:0.8983688168626205 Validation RAE:0.06982079233447358 Loss:49.55915797124941, Ranking:47.27951129466366, Reg:3.394233859955288, Gen:47.27923164401067, Disc:0.0, Recon_One:0.0, T_Reg:2.2799258055024496, T_MSE:109.87738146250645, CI:0.9254356535147822, \n",
      "it:33700, trainCI:0.9179856866739801, train_ranking:48.929786682128906, train_RAE:0.0734463483095169,  train_Gen:50.18779373168945, train_Disc:-0.0, train_reg:3.3720579147338867, train_t_reg:2.4804484844207764, train_t_mse:140.12579345703125, train_layer_one_recon:0.0\n",
      "Iteration: 33759 epochs:363, Training: RAE:0.1037139892578125, Loss: 52.873477935791016, Ranking:53.90056228637695, Reg:3.372274160385132, Gen:50.53928756713867, Disc:5.108969358680326e-10, Recon_One:0.0, T_Reg:2.3341896533966064,T_MSE:94.34461212158203,  CI:0.9235723899250144 Validation RAE:0.07075902630783579 Loss:48.68228705328555, Ranking:47.289396068729936, Reg:3.394623857834227, Gen:46.3568883611811, Disc:0.0, Recon_One:0.0, T_Reg:2.3253983164543177, T_MSE:112.80564235063795, CI:0.9250116218208132, \n",
      "it:33800, trainCI:0.9188997434917863, train_ranking:46.79026794433594, train_RAE:0.08176858723163605,  train_Gen:50.37749481201172, train_Disc:3.4059796649721363e-10, train_reg:3.3724660873413086, train_t_reg:2.6337854862213135, train_t_mse:151.74598693847656, train_layer_one_recon:0.0\n",
      "Iteration: 33852 epochs:364, Training: RAE:0.08578774333000183, Loss: 53.04903793334961, Ranking:56.325313568115234, Reg:3.3727810382843018, Gen:50.48035430908203, Disc:5.108969913791839e-10, Recon_One:0.0, T_Reg:2.568683624267578,T_MSE:100.62177276611328,  CI:0.9176735425184913 Validation RAE:0.06821694301376793 Loss:50.41996492092738, Ranking:47.254575472019965, Reg:3.395134095059226, Gen:48.14969296900797, Disc:0.0, Recon_One:0.0, T_Reg:2.2702717275728026, T_MSE:118.76279428569588, CI:0.9257274574818838, \n",
      "it:33900, trainCI:0.8908695249560145, train_ranking:55.36459732055664, train_RAE:0.0995246022939682,  train_Gen:50.49329376220703, train_Disc:-0.0, train_reg:3.373138427734375, train_t_reg:2.8971526622772217, train_t_mse:140.01080322265625, train_layer_one_recon:0.0\n",
      "Iteration: 33945 epochs:365, Training: RAE:0.08303157985210419, Loss: 53.202701568603516, Ranking:47.903778076171875, Reg:3.3731038570404053, Gen:50.65263366699219, Disc:-0.0, Recon_One:0.0, T_Reg:2.5500686168670654,T_MSE:157.6204071044922,  CI:0.933065164923572 Validation RAE:0.06994795283854448 Loss:49.20522409095397, Ranking:47.269963937892726, Reg:3.3954590532918925, Gen:46.902148867005245, Disc:0.0, Recon_One:0.0, T_Reg:2.3030753387307112, T_MSE:110.50966307418382, CI:0.9264239364152773, \n",
      "it:34000, trainCI:0.93565, train_ranking:51.591094970703125, train_RAE:0.08369947224855423,  train_Gen:50.6351318359375, train_Disc:5.369787947628879e-10, train_reg:3.3735735416412354, train_t_reg:2.2721824645996094, train_t_mse:89.78682708740234, train_layer_one_recon:0.0\n",
      "Iteration: 34038 epochs:366, Training: RAE:0.08717206865549088, Loss: 53.600685119628906, Ranking:51.1765251159668, Reg:3.3739607334136963, Gen:50.684322357177734, Disc:-0.0, Recon_One:0.0, T_Reg:2.9163641929626465,T_MSE:126.18550109863281,  CI:0.9052142279708973 Validation RAE:0.068995603289778 Loss:49.25003597941178, Ranking:47.272571951534744, Reg:3.3963216086007573, Gen:46.9922573160675, Disc:0.0, Recon_One:0.0, T_Reg:2.2577786894310887, T_MSE:109.42588272848411, CI:0.9258285483813884, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:34100, trainCI:0.9014688268297295, train_ranking:40.88160705566406, train_RAE:0.07121888548135757,  train_Gen:50.70185089111328, train_Disc:-0.0, train_reg:3.3744235038757324, train_t_reg:2.984325885772705, train_t_mse:110.04647827148438, train_layer_one_recon:0.0\n",
      "Iteration: 34131 epochs:367, Training: RAE:0.096030592918396, Loss: 53.4439582824707, Ranking:57.085350036621094, Reg:3.374875783920288, Gen:50.821533203125, Disc:-0.0, Recon_One:0.0, T_Reg:2.622424840927124,T_MSE:155.85174560546875,  CI:0.9209859791949344 Validation RAE:0.06815608019260551 Loss:49.00753679045352, Ranking:47.25164306362048, Reg:3.3972427235911367, Gen:46.7276009467448, Disc:0.0, Recon_One:0.0, T_Reg:2.2799357393614663, T_MSE:118.6027930411038, CI:0.9255227847366857, \n",
      "it:34200, trainCI:0.9187796451367336, train_ranking:43.96411895751953, train_RAE:0.08449907600879669,  train_Gen:50.839576721191406, train_Disc:-0.0, train_reg:3.374997138977051, train_t_reg:2.6387410163879395, train_t_mse:102.75399780273438, train_layer_one_recon:0.0\n",
      "Iteration: 34224 epochs:368, Training: RAE:0.07400649785995483, Loss: 53.5701789855957, Ranking:44.48044967651367, Reg:3.3755452632904053, Gen:50.94844055175781, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.6217379570007324,T_MSE:119.94097900390625,  CI:0.9061798076369291 Validation RAE:0.06850909169661308 Loss:49.31156479956076, Ranking:47.243446377764585, Reg:3.3979166399259424, Gen:47.00213107106327, Disc:0.0, Recon_One:0.0, T_Reg:2.309433864148927, T_MSE:117.13443411220919, CI:0.9258093473378479, \n",
      "it:34300, trainCI:0.8997026879436928, train_ranking:42.01640701293945, train_RAE:0.07183857262134552,  train_Gen:50.901729583740234, train_Disc:-0.0, train_reg:3.3754167556762695, train_t_reg:2.6179091930389404, train_t_mse:100.77388000488281, train_layer_one_recon:0.0\n",
      "Iteration: 34317 epochs:369, Training: RAE:0.07975547015666962, Loss: 53.63011169433594, Ranking:50.525150299072266, Reg:3.375655174255371, Gen:51.088111877441406, Disc:2.0674895129246806e-09, Recon_One:0.0, T_Reg:2.542001485824585,T_MSE:119.48487854003906,  CI:0.9263963274674828 Validation RAE:0.06720228706473363 Loss:49.16019115326359, Ranking:47.24979185977548, Reg:3.398027279324214, Gen:46.93550826818388, Disc:0.0, Recon_One:0.0, T_Reg:2.2246828433408044, T_MSE:111.59444982832306, CI:0.926308937732884, *\n",
      "it:34400, trainCI:0.8894448288710278, train_ranking:48.35243606567383, train_RAE:0.09972356259822845,  train_Gen:50.29988098144531, train_Disc:1.497969748243122e-09, train_reg:3.3764312267303467, train_t_reg:3.2990293502807617, train_t_mse:110.11975860595703, train_layer_one_recon:0.0\n",
      "Iteration: 34410 epochs:370, Training: RAE:0.09859469532966614, Loss: 53.59157180786133, Ranking:54.11674880981445, Reg:3.376505136489868, Gen:50.63835906982422, Disc:-0.0, Recon_One:0.0, T_Reg:2.9532132148742676,T_MSE:123.23420715332031,  CI:0.9207317073170732 Validation RAE:0.07040058564857288 Loss:48.88260306992411, Ranking:47.28624144240858, Reg:3.398882874670931, Gen:46.56444824798802, Disc:0.0, Recon_One:0.0, T_Reg:2.3181546393283923, T_MSE:107.00861954817223, CI:0.9252973541065791, \n",
      "it:34500, trainCI:0.906796886619404, train_ranking:51.96143341064453, train_RAE:0.11207309365272522,  train_Gen:50.785552978515625, train_Disc:-0.0, train_reg:3.376775026321411, train_t_reg:3.301988124847412, train_t_mse:168.76321411132812, train_layer_one_recon:0.0\n",
      "Iteration: 34503 epochs:371, Training: RAE:0.0960066094994545, Loss: 52.9542350769043, Ranking:51.36284637451172, Reg:3.3768372535705566, Gen:50.49951934814453, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.454714059829712,T_MSE:108.72563934326172,  CI:0.9111611611611612 Validation RAE:0.06774718078603086 Loss:48.856112222694165, Ranking:47.23032166305834, Reg:3.399217192852692, Gen:46.58631859860808, Disc:0.0, Recon_One:0.0, T_Reg:2.2697935875645427, T_MSE:116.07397178925618, CI:0.9259821567297115, \n",
      "Iteration: 34596 epochs:372, Training: RAE:0.06915093213319778, Loss: 52.67184066772461, Ranking:46.31888961791992, Reg:3.3772499561309814, Gen:50.43280029296875, Disc:-0.0, Recon_One:0.0, T_Reg:2.239039182662964,T_MSE:99.05816650390625,  CI:0.9295227524972253 Validation RAE:0.06824607562706503 Loss:49.894220691569764, Ranking:47.25665623983383, Reg:3.3996326305932727, Gen:47.641558716919356, Disc:0.0, Recon_One:0.0, T_Reg:2.2526618703031476, T_MSE:113.37861932485241, CI:0.9252273481397251, \n",
      "it:34600, trainCI:0.9423904711362698, train_ranking:43.34303283691406, train_RAE:0.0646735355257988,  train_Gen:50.559722900390625, train_Disc:5.676633052509317e-10, train_reg:3.3772594928741455, train_t_reg:1.9003558158874512, train_t_mse:120.40098571777344, train_layer_one_recon:0.0\n",
      "Iteration: 34689 epochs:373, Training: RAE:0.0792519748210907, Loss: 53.363182067871094, Ranking:50.034427642822266, Reg:3.3773629665374756, Gen:51.0169563293457, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.3462257385253906,T_MSE:99.65580749511719,  CI:0.9147154597612033 Validation RAE:0.06808637345215075 Loss:49.795152569496885, Ranking:47.27308333657959, Reg:3.3997463899745752, Gen:47.549138099562605, Disc:0.0, Recon_One:0.0, T_Reg:2.2460143708043865, T_MSE:111.66282382863483, CI:0.9256790916100469, \n",
      "it:34700, trainCI:0.9359451988943637, train_ranking:42.423221588134766, train_RAE:0.0649835616350174,  train_Gen:51.352638244628906, train_Disc:3.4059796649721363e-10, train_reg:3.3774242401123047, train_t_reg:2.063082456588745, train_t_mse:114.771240234375, train_layer_one_recon:0.0\n",
      "Iteration: 34782 epochs:374, Training: RAE:0.0862417221069336, Loss: 52.86140823364258, Ranking:53.194793701171875, Reg:3.3778913021087646, Gen:50.730628967285156, Disc:5.051241092068892e-10, Recon_One:0.0, T_Reg:2.1307809352874756,T_MSE:110.10984802246094,  CI:0.9245301298198023 Validation RAE:0.06828141021750131 Loss:50.12809662307905, Ranking:47.27873244672563, Reg:3.4002782270821004, Gen:47.88833530870127, Disc:0.0, Recon_One:0.0, T_Reg:2.239761272638876, T_MSE:110.12502071394448, CI:0.9255206051587703, \n",
      "it:34800, trainCI:0.9207903088820347, train_ranking:58.09180450439453, train_RAE:0.09068690240383148,  train_Gen:50.90884017944336, train_Disc:3.4059796649721363e-10, train_reg:3.3779478073120117, train_t_reg:2.1728765964508057, train_t_mse:82.04309844970703, train_layer_one_recon:0.0\n",
      "Iteration: 34875 epochs:375, Training: RAE:0.0709080919623375, Loss: 52.40088653564453, Ranking:45.13606643676758, Reg:3.3785548210144043, Gen:50.30649948120117, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.0943856239318848,T_MSE:114.67118835449219,  CI:0.9367894497498863 Validation RAE:0.06851221216877237 Loss:49.66701363509515, Ranking:47.27419459314455, Reg:3.400946143449538, Gen:47.385198538998324, Disc:0.0, Recon_One:0.0, T_Reg:2.281815179574634, T_MSE:109.43448494952575, CI:0.9257788332470325, \n",
      "it:34900, trainCI:0.8764463995409774, train_ranking:53.75198745727539, train_RAE:0.09851272404193878,  train_Gen:51.1279296875, train_Disc:9.852006987998152e-10, train_reg:3.3788180351257324, train_t_reg:3.6429824829101562, train_t_mse:138.36367797851562, train_layer_one_recon:0.0\n",
      "Iteration: 34968 epochs:376, Training: RAE:0.06771796941757202, Loss: 52.57565689086914, Ranking:46.96804428100586, Reg:3.3788061141967773, Gen:50.37382888793945, Disc:1.3623918659888545e-09, Recon_One:0.0, T_Reg:2.201828718185425,T_MSE:101.13179779052734,  CI:0.9117101386008949 Validation RAE:0.0683791840879175 Loss:49.15024226824164, Ranking:47.267898363039706, Reg:3.401199102073785, Gen:46.894238510026895, Disc:0.0, Recon_One:0.0, T_Reg:2.2560039825613565, T_MSE:113.40537763497554, CI:0.9248659533634676, \n",
      "it:35000, trainCI:0.9132393547449499, train_ranking:53.11186218261719, train_RAE:0.09205890446901321,  train_Gen:51.083595275878906, train_Disc:-0.0, train_reg:3.3787646293640137, train_t_reg:2.514464855194092, train_t_mse:113.98302459716797, train_layer_one_recon:0.0\n",
      "Iteration: 35061 epochs:377, Training: RAE:0.08551273494958878, Loss: 53.24421691894531, Ranking:50.25852584838867, Reg:3.379042625427246, Gen:50.69294738769531, Disc:1.6255813362064941e-09, Recon_One:0.0, T_Reg:2.5512707233428955,T_MSE:117.78853607177734,  CI:0.901755639481474 Validation RAE:0.07017527676525304 Loss:49.77387941910712, Ranking:47.273814435212095, Reg:3.4014371807789585, Gen:47.41691543084913, Disc:0.0, Recon_One:0.0, T_Reg:2.356964358690755, T_MSE:112.49699317709839, CI:0.9260823135243952, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:35100, trainCI:0.9174912308256112, train_ranking:49.04694366455078, train_RAE:0.08620825409889221,  train_Gen:50.57366180419922, train_Disc:-0.0, train_reg:3.379270553588867, train_t_reg:2.985414505004883, train_t_mse:177.96343994140625, train_layer_one_recon:0.0\n",
      "Iteration: 35154 epochs:378, Training: RAE:0.08900274336338043, Loss: 53.96311569213867, Ranking:48.530574798583984, Reg:3.380375385284424, Gen:51.32167053222656, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.641446352005005,T_MSE:132.66024780273438,  CI:0.8994419346266277 Validation RAE:0.06949637116410366 Loss:49.59381528536916, Ranking:47.25442220676656, Reg:3.4027787734825075, Gen:47.259623041089746, Disc:0.0, Recon_One:0.0, T_Reg:2.3341922755835873, T_MSE:115.40813510442086, CI:0.9265579285623619, \n",
      "it:35200, trainCI:0.9278941335834114, train_ranking:49.38185119628906, train_RAE:0.08318078517913818,  train_Gen:51.40362548828125, train_Disc:3.4059796649721363e-10, train_reg:3.380250930786133, train_t_reg:2.460845470428467, train_t_mse:106.53204345703125, train_layer_one_recon:0.0\n",
      "Iteration: 35247 epochs:379, Training: RAE:0.0794091448187828, Loss: 53.57683181762695, Ranking:48.246673583984375, Reg:3.3804306983947754, Gen:51.36505126953125, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.211780309677124,T_MSE:119.09368896484375,  CI:0.9002477988084568 Validation RAE:0.0708052069805884 Loss:50.620790820010264, Ranking:47.29398133770531, Reg:3.4028344531796852, Gen:48.25127527566795, Disc:0.0, Recon_One:0.0, T_Reg:2.3695156539069333, T_MSE:107.250439060827, CI:0.9264852240704697, \n",
      "it:35300, trainCI:0.8962403243641726, train_ranking:41.43242263793945, train_RAE:0.08169112354516983,  train_Gen:50.842933654785156, train_Disc:1.7029898324860682e-10, train_reg:3.3806753158569336, train_t_reg:2.8442790508270264, train_t_mse:100.17766571044922, train_layer_one_recon:0.0\n",
      "Iteration: 35340 epochs:380, Training: RAE:0.08166621625423431, Loss: 53.54034423828125, Ranking:51.357696533203125, Reg:3.380948305130005, Gen:50.76340866088867, Disc:1.7029898324860682e-10, Recon_One:0.0, T_Reg:2.7769365310668945,T_MSE:95.78730010986328,  CI:0.8800159712517469 Validation RAE:0.06922240417585293 Loss:51.93687454229357, Ranking:47.25377942765372, Reg:3.4033554903459473, Gen:49.584883160034806, Disc:0.0, Recon_One:0.0, T_Reg:2.351991350954587, T_MSE:111.56718430704544, CI:0.927002666246527, \n",
      "it:35400, trainCI:0.9329483107132545, train_ranking:44.60304641723633, train_RAE:0.0750487819314003,  train_Gen:51.24639129638672, train_Disc:1.362392199055762e-09, train_reg:3.381133794784546, train_t_reg:2.1781163215637207, train_t_mse:104.27924346923828, train_layer_one_recon:0.0\n",
      "Iteration: 35433 epochs:381, Training: RAE:0.07026312500238419, Loss: 52.7056884765625, Ranking:43.936038970947266, Reg:3.381223678588867, Gen:50.792755126953125, Disc:-0.0, Recon_One:0.0, T_Reg:1.9129319190979004,T_MSE:79.17457580566406,  CI:0.9497647947035252 Validation RAE:0.06905879240263636 Loss:50.290740775036426, Ranking:47.29087429373387, Reg:3.403632688838362, Gen:48.00754946381566, Disc:0.0, Recon_One:0.0, T_Reg:2.283191170351974, T_MSE:108.77398450001637, CI:0.9253565659732806, \n",
      "it:35500, trainCI:0.9070807836684321, train_ranking:49.84077453613281, train_RAE:0.0864056795835495,  train_Gen:51.19236755371094, train_Disc:-0.0, train_reg:3.381831407546997, train_t_reg:2.792998790740967, train_t_mse:144.3241729736328, train_layer_one_recon:0.0\n",
      "Iteration: 35526 epochs:382, Training: RAE:0.10129818320274353, Loss: 54.49048614501953, Ranking:48.09284591674805, Reg:3.3816909790039062, Gen:51.676265716552734, Disc:-0.0, Recon_One:0.0, T_Reg:2.8142223358154297,T_MSE:121.47838592529297,  CI:0.9002842890092796 Validation RAE:0.06808979392267844 Loss:50.03851141291021, Ranking:47.27857751191609, Reg:3.4041030862800357, Gen:47.802589075914454, Disc:0.0, Recon_One:0.0, T_Reg:2.235922550907638, T_MSE:110.01371541320793, CI:0.9255241339992047, \n",
      "it:35600, trainCI:0.9205571712842492, train_ranking:50.3569221496582, train_RAE:0.07110757380723953,  train_Gen:51.757198333740234, train_Disc:-0.0, train_reg:3.3824126720428467, train_t_reg:2.195586681365967, train_t_mse:98.52448272705078, train_layer_one_recon:0.0\n",
      "Iteration: 35619 epochs:383, Training: RAE:0.07232427597045898, Loss: 53.43461990356445, Ranking:45.909725189208984, Reg:3.3824622631073, Gen:51.185367584228516, Disc:-0.0, Recon_One:0.0, T_Reg:2.2492518424987793,T_MSE:121.11111450195312,  CI:0.9260496714556187 Validation RAE:0.06767457840915052 Loss:50.304366356583856, Ranking:47.25852096708354, Reg:3.404879482057492, Gen:48.05550980123711, Disc:0.0, Recon_One:0.0, T_Reg:2.248857066648311, T_MSE:112.9456600100007, CI:0.9257533529433072, \n",
      "it:35700, trainCI:0.9055271615996627, train_ranking:48.85179138183594, train_RAE:0.089174784719944,  train_Gen:51.00202941894531, train_Disc:-0.0, train_reg:3.3830111026763916, train_t_reg:2.8078014850616455, train_t_mse:114.36375427246094, train_layer_one_recon:0.0\n",
      "Iteration: 35712 epochs:384, Training: RAE:0.08503242582082748, Loss: 53.38625717163086, Ranking:48.69991683959961, Reg:3.383009195327759, Gen:50.769859313964844, Disc:-0.0, Recon_One:0.0, T_Reg:2.6163980960845947,T_MSE:95.51876831054688,  CI:0.8748627307430843 Validation RAE:0.06673623747984826 Loss:50.29574126262314, Ranking:47.22379787245199, Reg:3.405430039063206, Gen:48.03442046897805, Disc:0.0, Recon_One:0.0, T_Reg:2.261320861470808, T_MSE:119.83784585799874, CI:0.9264873517536728, \n",
      "it:35800, trainCI:0.8962840627580512, train_ranking:46.91550064086914, train_RAE:0.09146573394536972,  train_Gen:52.14792251586914, train_Disc:-0.0, train_reg:3.3836686611175537, train_t_reg:2.988616943359375, train_t_mse:93.82463836669922, train_layer_one_recon:0.0\n",
      "Iteration: 35805 epochs:385, Training: RAE:0.09543778747320175, Loss: 54.11904525756836, Ranking:48.00468063354492, Reg:3.383765459060669, Gen:51.675453186035156, Disc:-0.0, Recon_One:0.0, T_Reg:2.4435935020446777,T_MSE:87.49893188476562,  CI:0.9264027464864285 Validation RAE:0.0663552791713118 Loss:49.459604342251815, Ranking:47.23971558762026, Reg:3.406191314922894, Gen:47.23865525251748, Disc:0.0, Recon_One:0.0, T_Reg:2.220949319298303, T_MSE:116.17934448921459, CI:0.9260517475388673, *\n",
      "Iteration: 35898 epochs:386, Training: RAE:0.08628008514642715, Loss: 54.35466003417969, Ranking:48.8192024230957, Reg:3.383765935897827, Gen:51.70478820800781, Disc:-0.0, Recon_One:0.0, T_Reg:2.6498703956604004,T_MSE:105.08983612060547,  CI:0.8935492295638547 Validation RAE:0.06909479677203866 Loss:50.11725318987876, Ranking:47.26576099727278, Reg:3.4061917949202836, Gen:47.823762887714054, Disc:0.0, Recon_One:0.0, T_Reg:2.2934905056418575, T_MSE:113.7173522304293, CI:0.9255233036838084, \n",
      "it:35900, trainCI:0.9152108656070075, train_ranking:52.584228515625, train_RAE:0.09544704109430313,  train_Gen:51.87555694580078, train_Disc:-0.0, train_reg:3.383758306503296, train_t_reg:2.735600471496582, train_t_mse:124.82601928710938, train_layer_one_recon:0.0\n",
      "Iteration: 35991 epochs:387, Training: RAE:0.07044531404972076, Loss: 53.372459411621094, Ranking:44.6119270324707, Reg:3.384129285812378, Gen:51.05515670776367, Disc:1.1573717539903328e-09, Recon_One:0.0, T_Reg:2.317300796508789,T_MSE:140.4093475341797,  CI:0.9157123224919835 Validation RAE:0.06858284971938217 Loss:50.37914694466113, Ranking:47.23672374302229, Reg:3.4065575529310546, Gen:48.064105677965415, Disc:0.0, Recon_One:0.0, T_Reg:2.315041021479656, T_MSE:124.04295155834194, CI:0.9257367466353804, \n",
      "it:36000, trainCI:0.906828803877445, train_ranking:59.57952117919922, train_RAE:0.10155635327100754,  train_Gen:51.51706314086914, train_Disc:-0.0, train_reg:3.384139060974121, train_t_reg:2.808359384536743, train_t_mse:160.64991760253906, train_layer_one_recon:0.0\n",
      "Iteration: 36084 epochs:388, Training: RAE:0.08329226821660995, Loss: 53.54804992675781, Ranking:40.52781677246094, Reg:3.384620189666748, Gen:51.19404602050781, Disc:-0.0, Recon_One:0.0, T_Reg:2.3540048599243164,T_MSE:107.96892547607422,  CI:0.9242615501136077 Validation RAE:0.06954318509428177 Loss:49.9277685856363, Ranking:47.270151262091325, Reg:3.4070517102435067, Gen:47.626223009020535, Disc:0.0, Recon_One:0.0, T_Reg:2.30154579574501, T_MSE:117.9219557282864, CI:0.9247831812973948, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:36100, trainCI:0.911957671957672, train_ranking:48.44377517700195, train_RAE:0.08209730684757233,  train_Gen:51.69170379638672, train_Disc:1.7029898324860682e-10, train_reg:3.3846139907836914, train_t_reg:2.5975472927093506, train_t_mse:112.16943359375, train_layer_one_recon:0.0\n",
      "Iteration: 36177 epochs:389, Training: RAE:0.076658695936203, Loss: 53.16130828857422, Ranking:46.70570755004883, Reg:3.3846147060394287, Gen:51.00152587890625, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.1597814559936523,T_MSE:107.5919189453125,  CI:0.9333187581985133 Validation RAE:0.06976249678195738 Loss:50.34378057004989, Ranking:47.2540759408237, Reg:3.407046190273528, Gen:47.97534623026207, Disc:0.0, Recon_One:0.0, T_Reg:2.368434204136385, T_MSE:120.36629777349978, CI:0.9259203501273964, \n",
      "it:36200, trainCI:0.9153934205942368, train_ranking:51.61296081542969, train_RAE:0.08566116541624069,  train_Gen:51.212860107421875, train_Disc:-0.0, train_reg:3.384782075881958, train_t_reg:2.6497626304626465, train_t_mse:88.54655456542969, train_layer_one_recon:0.0\n",
      "Iteration: 36270 epochs:390, Training: RAE:0.08658695220947266, Loss: 53.928768157958984, Ranking:44.35885238647461, Reg:3.3849234580993652, Gen:51.37007141113281, Disc:-0.0, Recon_One:0.0, T_Reg:2.558696746826172,T_MSE:120.76757049560547,  CI:0.9177767570050528 Validation RAE:0.0688220098860654 Loss:50.14268286722786, Ranking:47.282956590708515, Reg:3.407356988583205, Gen:47.876593654299135, Disc:0.0, Recon_One:0.0, T_Reg:2.2660892129287253, T_MSE:111.8376931384517, CI:0.9257519517860758, \n",
      "it:36300, trainCI:0.9165272072620315, train_ranking:50.75969314575195, train_RAE:0.08779855817556381,  train_Gen:52.04523468017578, train_Disc:-0.0, train_reg:3.38491153717041, train_t_reg:2.82011342048645, train_t_mse:134.15830993652344, train_layer_one_recon:0.0\n",
      "Iteration: 36363 epochs:391, Training: RAE:0.08271051198244095, Loss: 54.13023376464844, Ranking:47.221309661865234, Reg:3.3855011463165283, Gen:51.529144287109375, Disc:-0.0, Recon_One:0.0, T_Reg:2.601090908050537,T_MSE:122.56021118164062,  CI:0.9233735201477137 Validation RAE:0.06928049152297974 Loss:50.00856141231947, Ranking:47.28063724332263, Reg:3.4079385054205393, Gen:47.69968731903919, Disc:0.0, Recon_One:0.0, T_Reg:2.30887427067062, T_MSE:111.78166817706482, CI:0.9258973088751479, \n",
      "it:36400, trainCI:0.9159971186346761, train_ranking:46.19685745239258, train_RAE:0.07653188705444336,  train_Gen:51.214874267578125, train_Disc:1.362392199055762e-09, train_reg:3.385908365249634, train_t_reg:2.2300937175750732, train_t_mse:106.537353515625, train_layer_one_recon:0.0\n",
      "Iteration: 36456 epochs:392, Training: RAE:0.07658010721206665, Loss: 53.467315673828125, Ranking:48.72248840332031, Reg:3.3865621089935303, Gen:51.24687194824219, Disc:6.811960440167297e-10, Recon_One:0.0, T_Reg:2.220442056655884,T_MSE:73.73128509521484,  CI:0.9166185047023591 Validation RAE:0.07208954515856804 Loss:49.98556678259657, Ranking:47.29134360596405, Reg:3.4090064996120946, Gen:47.59201129943382, Disc:0.0, Recon_One:0.0, T_Reg:2.3935551283820744, T_MSE:110.69491034494992, CI:0.9254358610936313, \n",
      "it:36500, trainCI:0.916101034828085, train_ranking:46.11698913574219, train_RAE:0.07792604714632034,  train_Gen:51.61549377441406, train_Disc:1.7029898324860682e-10, train_reg:3.3870058059692383, train_t_reg:2.485457181930542, train_t_mse:100.50890350341797, train_layer_one_recon:0.0\n",
      "Iteration: 36549 epochs:393, Training: RAE:0.08576765656471252, Loss: 54.204856872558594, Ranking:47.739784240722656, Reg:3.3872082233428955, Gen:51.39717483520508, Disc:-0.0, Recon_One:0.0, T_Reg:2.8076839447021484,T_MSE:125.25383758544922,  CI:0.9061224489795918 Validation RAE:0.06735059419292591 Loss:50.82100816588111, Ranking:47.25963005322553, Reg:3.4096568960748166, Gen:48.58357888751586, Disc:0.0, Recon_One:0.0, T_Reg:2.2374293409736064, T_MSE:114.88437430775433, CI:0.9265312546802543, \n",
      "it:36600, trainCI:0.9069575730929875, train_ranking:46.8967170715332, train_RAE:0.09969623386859894,  train_Gen:51.60973358154297, train_Disc:-0.0, train_reg:3.3875746726989746, train_t_reg:3.5158841609954834, train_t_mse:159.5299530029297, train_layer_one_recon:0.0\n",
      "Iteration: 36642 epochs:394, Training: RAE:0.06815899163484573, Loss: 54.17129898071289, Ranking:46.22970962524414, Reg:3.3878650665283203, Gen:51.94786071777344, Disc:-0.0, Recon_One:0.0, T_Reg:2.223439931869507,T_MSE:103.07917022705078,  CI:0.9404517453798767 Validation RAE:0.06719405162039288 Loss:50.4355231806593, Ranking:47.24311413609327, Reg:3.4103180924788017, Gen:48.15777712678021, Disc:0.0, Recon_One:0.0, T_Reg:2.277746022574914, T_MSE:123.3904903555447, CI:0.9249372566981283, \n",
      "it:36700, trainCI:0.9144663631765301, train_ranking:50.70450973510742, train_RAE:0.08132588118314743,  train_Gen:52.03624725341797, train_Disc:-0.0, train_reg:3.388077974319458, train_t_reg:2.348104953765869, train_t_mse:123.9556655883789, train_layer_one_recon:0.0\n",
      "Iteration: 36735 epochs:395, Training: RAE:0.10766594856977463, Loss: 56.006752014160156, Ranking:45.98634719848633, Reg:3.3881568908691406, Gen:51.804168701171875, Disc:-0.0, Recon_One:0.0, T_Reg:4.2025837898254395,T_MSE:147.32977294921875,  CI:0.8233258928571429 Validation RAE:0.0668128971716188 Loss:49.47799967872779, Ranking:47.25984525901162, Reg:3.4106118508811534, Gen:47.251186106105706, Disc:0.0, Recon_One:0.0, T_Reg:2.2268136039262596, T_MSE:118.09550608875485, CI:0.9244855651225188, \n",
      "it:36800, trainCI:0.9244777475022706, train_ranking:56.5557746887207, train_RAE:0.0852748453617096,  train_Gen:51.83002471923828, train_Disc:-0.0, train_reg:3.3886609077453613, train_t_reg:2.490213394165039, train_t_mse:164.42784118652344, train_layer_one_recon:0.0\n",
      "Iteration: 36828 epochs:396, Training: RAE:0.10224346816539764, Loss: 54.35186767578125, Ranking:58.16648483276367, Reg:3.388723373413086, Gen:51.51442337036133, Disc:-0.0, Recon_One:0.0, T_Reg:2.8374452590942383,T_MSE:101.99662780761719,  CI:0.9065865598575878 Validation RAE:0.06739670508344933 Loss:50.255407290681084, Ranking:47.21923898246358, Reg:3.411182087779835, Gen:47.93012146057152, Disc:0.0, Recon_One:0.0, T_Reg:2.3252857414144, T_MSE:122.95506410454458, CI:0.9262486360772247, \n",
      "it:36900, trainCI:0.9029723442750065, train_ranking:49.44778060913086, train_RAE:0.08023402094841003,  train_Gen:51.27165603637695, train_Disc:3.4059796649721363e-10, train_reg:3.3893420696258545, train_t_reg:2.3868408203125, train_t_mse:101.1208724975586, train_layer_one_recon:0.0\n",
      "Iteration: 36921 epochs:397, Training: RAE:0.08772607147693634, Loss: 54.5846061706543, Ranking:52.09552764892578, Reg:3.3893442153930664, Gen:51.81371307373047, Disc:5.108969913791839e-10, Recon_One:0.0, T_Reg:2.7708940505981445,T_MSE:124.35050964355469,  CI:0.8855179185076092 Validation RAE:0.06713518117969895 Loss:51.423470837124526, Ranking:47.24761459161687, Reg:3.411807044380916, Gen:49.14415640221009, Disc:0.0, Recon_One:0.0, T_Reg:2.2793142888282736, T_MSE:119.74272289707822, CI:0.9253661146003386, \n",
      "it:37000, trainCI:0.9110828642333999, train_ranking:42.18626022338867, train_RAE:0.08219115436077118,  train_Gen:51.84516143798828, train_Disc:3.4059796649721363e-10, train_reg:3.3891584873199463, train_t_reg:2.619285821914673, train_t_mse:130.65577697753906, train_layer_one_recon:0.0\n",
      "Iteration: 37014 epochs:398, Training: RAE:0.08624213188886642, Loss: 54.348609924316406, Ranking:50.34072494506836, Reg:3.3894450664520264, Gen:51.401222229003906, Disc:-0.0, Recon_One:0.0, T_Reg:2.9473867416381836,T_MSE:123.95726776123047,  CI:0.8913484971567831 Validation RAE:0.06706228027183353 Loss:49.55321318271146, Ranking:47.26446492084342, Reg:3.411908563828787, Gen:47.307789067827315, Disc:0.0, Recon_One:0.0, T_Reg:2.245423843581274, T_MSE:115.62188637320722, CI:0.925993729250548, \n",
      "it:37100, trainCI:0.9066724187517975, train_ranking:53.843505859375, train_RAE:0.08380987495183945,  train_Gen:51.87558364868164, train_Disc:-0.0, train_reg:3.389774799346924, train_t_reg:2.6027379035949707, train_t_mse:79.27713012695312, train_layer_one_recon:0.0\n",
      "Iteration: 37107 epochs:399, Training: RAE:0.07475059479475021, Loss: 53.97150802612305, Ranking:47.92063903808594, Reg:3.389802932739258, Gen:51.57539367675781, Disc:-0.0, Recon_One:0.0, T_Reg:2.3961143493652344,T_MSE:147.98199462890625,  CI:0.9430454350621518 Validation RAE:0.0677031876557288 Loss:50.77115071182089, Ranking:47.26174955474178, Reg:3.4122688018695793, Gen:48.507442285943895, Disc:0.0, Recon_One:0.0, T_Reg:2.263708592832603, T_MSE:115.17470244006603, CI:0.9265829418136766, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 37200 epochs:400, Training: RAE:0.0848420038819313, Loss: 54.813026428222656, Ranking:42.179527282714844, Reg:3.389857530593872, Gen:52.0964469909668, Disc:-0.0, Recon_One:0.0, T_Reg:2.7165801525115967,T_MSE:79.5716323852539,  CI:0.9189768068049691 Validation RAE:0.07015578665386159 Loss:50.51564117275179, Ranking:47.30607059369523, Reg:3.412323761570673, Gen:48.22252251378325, Disc:0.0, Recon_One:0.0, T_Reg:2.2931186067949194, T_MSE:104.04670207786965, CI:0.9258171315446887, \n",
      "it:37200, trainCI:0.939377881405331, train_ranking:48.51142120361328, train_RAE:0.07319232076406479,  train_Gen:51.47178649902344, train_Disc:1.0456955301663129e-09, train_reg:3.3898816108703613, train_t_reg:2.0538489818573, train_t_mse:142.8609619140625, train_layer_one_recon:0.0\n",
      "Iteration: 37293 epochs:401, Training: RAE:0.09108443558216095, Loss: 55.14377975463867, Ranking:46.773284912109375, Reg:3.3903894424438477, Gen:52.36774444580078, Disc:-0.0, Recon_One:0.0, T_Reg:2.776036262512207,T_MSE:160.84149169921875,  CI:0.8900120865838919 Validation RAE:0.06837857169994373 Loss:50.418839807046474, Ranking:47.27461615606921, Reg:3.4128591986586185, Gen:48.14448612428269, Disc:0.0, Recon_One:0.0, T_Reg:2.274353531460263, T_MSE:111.37520538593391, CI:0.926078473315687, \n",
      "it:37300, trainCI:0.9453202295363102, train_ranking:38.58768844604492, train_RAE:0.06126997247338295,  train_Gen:51.73584747314453, train_Disc:-0.0, train_reg:3.390587091445923, train_t_reg:2.1523492336273193, train_t_mse:122.68234252929688, train_layer_one_recon:0.0\n",
      "Iteration: 37386 epochs:402, Training: RAE:0.0771913230419159, Loss: 55.660240173339844, Ranking:44.038692474365234, Reg:3.3907880783081055, Gen:51.90296173095703, Disc:-0.0, Recon_One:0.0, T_Reg:3.757277250289917,T_MSE:252.70028686523438,  CI:0.9112889198121412 Validation RAE:0.0695721455346022 Loss:50.36018128780867, Ranking:47.25787384712474, Reg:3.41326047647621, Gen:48.0087213252684, Disc:0.0, Recon_One:0.0, T_Reg:2.35146009819171, T_MSE:112.0541223752822, CI:0.9271487498615708, \n",
      "it:37400, trainCI:0.8894306385655867, train_ranking:49.15251922607422, train_RAE:0.08267996460199356,  train_Gen:51.95905303955078, train_Disc:-0.0, train_reg:3.3908333778381348, train_t_reg:2.909562587738037, train_t_mse:117.68006134033203, train_layer_one_recon:0.0\n",
      "Iteration: 37479 epochs:403, Training: RAE:0.08241520822048187, Loss: 54.619590759277344, Ranking:39.242530822753906, Reg:3.391679525375366, Gen:51.92741394042969, Disc:9.550787938295002e-10, Recon_One:0.0, T_Reg:2.69217586517334,T_MSE:142.45631408691406,  CI:0.9323722149410223 Validation RAE:0.06729793143586187 Loss:50.037004638496335, Ranking:47.25543996818784, Reg:3.4141578315958108, Gen:47.799705418554176, Disc:0.0, Recon_One:0.0, T_Reg:2.2372990738559966, T_MSE:112.16710691558163, CI:0.9266998087057117, \n",
      "it:37500, trainCI:0.8991310918020401, train_ranking:47.456146240234375, train_RAE:0.08447802066802979,  train_Gen:51.541481018066406, train_Disc:-0.0, train_reg:3.3919730186462402, train_t_reg:2.7709178924560547, train_t_mse:136.4995880126953, train_layer_one_recon:0.0\n",
      "Iteration: 37572 epochs:404, Training: RAE:0.10828187316656113, Loss: 56.267478942871094, Ranking:47.36095428466797, Reg:3.3919665813446045, Gen:52.016441345214844, Disc:-0.0, Recon_One:0.0, T_Reg:4.251038551330566,T_MSE:260.7156066894531,  CI:0.8922758695770507 Validation RAE:0.06572049648236733 Loss:50.81134995058267, Ranking:47.22729141866921, Reg:3.414446790024267, Gen:48.591843691262156, Disc:0.0, Recon_One:0.0, T_Reg:2.219506118451713, T_MSE:118.4592522843802, CI:0.926187867369155, *\n",
      "it:37600, trainCI:0.9172227599205338, train_ranking:50.42616653442383, train_RAE:0.08936163038015366,  train_Gen:51.796852111816406, train_Disc:-0.0, train_reg:3.391929864883423, train_t_reg:2.4391932487487793, train_t_mse:106.98576354980469, train_layer_one_recon:0.0\n",
      "Iteration: 37665 epochs:405, Training: RAE:0.06736666709184647, Loss: 53.566368103027344, Ranking:41.0543212890625, Reg:3.392582654953003, Gen:51.446414947509766, Disc:2.5636408551577006e-09, Recon_One:0.0, T_Reg:2.1199517250061035,T_MSE:106.78312683105469,  CI:0.9357729648991785 Validation RAE:0.06765676779949444 Loss:50.92562806297723, Ranking:47.240048831025256, Reg:3.4150669466514536, Gen:48.63737866448301, Disc:0.0, Recon_One:0.0, T_Reg:2.288249414146312, T_MSE:117.40562645989804, CI:0.9270973222017099, \n",
      "it:37700, trainCI:0.903857047221793, train_ranking:50.05400848388672, train_RAE:0.08883985877037048,  train_Gen:51.69145202636719, train_Disc:-0.0, train_reg:3.392735004425049, train_t_reg:3.259629726409912, train_t_mse:158.76499938964844, train_layer_one_recon:0.0\n",
      "Iteration: 37758 epochs:406, Training: RAE:0.07849031686782837, Loss: 55.0644416809082, Ranking:44.49700164794922, Reg:3.3930344581604004, Gen:52.07509994506836, Disc:-0.0, Recon_One:0.0, T_Reg:2.989342212677002,T_MSE:100.82743072509766,  CI:0.9126979556579327 Validation RAE:0.06900351183372273 Loss:50.03763222464833, Ranking:47.276504591016064, Reg:3.4155217441779695, Gen:47.72389571607388, Disc:0.0, Recon_One:0.0, T_Reg:2.3137367903120416, T_MSE:110.29084637207703, CI:0.9273242058837602, \n",
      "it:37800, trainCI:0.9372595609866485, train_ranking:45.56712341308594, train_RAE:0.0742618516087532,  train_Gen:52.40556335449219, train_Disc:-0.0, train_reg:3.393343210220337, train_t_reg:2.348644256591797, train_t_mse:124.64827728271484, train_layer_one_recon:0.0\n",
      "Iteration: 37851 epochs:407, Training: RAE:0.07131413370370865, Loss: 54.093841552734375, Ranking:42.03565216064453, Reg:3.3936209678649902, Gen:51.43470001220703, Disc:-0.0, Recon_One:0.0, T_Reg:2.659141778945923,T_MSE:96.81840515136719,  CI:0.8994219653179191 Validation RAE:0.0694657925260623 Loss:49.92763285072234, Ranking:47.2912359195932, Reg:3.416112140967009, Gen:47.623701812297654, Disc:0.0, Recon_One:0.0, T_Reg:2.3039306106009274, T_MSE:109.04764812469959, CI:0.9258424561642771, \n",
      "it:37900, trainCI:0.9184090298306907, train_ranking:47.71485900878906, train_RAE:0.07508804649114609,  train_Gen:51.88522720336914, train_Disc:-0.0, train_reg:3.3940412998199463, train_t_reg:2.3418424129486084, train_t_mse:127.33399200439453, train_layer_one_recon:0.0\n",
      "Iteration: 37944 epochs:408, Training: RAE:0.08377303183078766, Loss: 54.76459503173828, Ranking:43.35904312133789, Reg:3.3940351009368896, Gen:51.97711944580078, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.7874765396118164,T_MSE:122.61573028564453,  CI:0.9111045481393976 Validation RAE:0.07140920429348543 Loss:50.81816608046865, Ranking:47.31870729714256, Reg:3.4165290186997574, Gen:48.44515365079685, Disc:0.0, Recon_One:0.0, T_Reg:2.37301257575797, T_MSE:103.38927160818547, CI:0.9267851236126857, \n",
      "it:38000, trainCI:0.9161703845765621, train_ranking:50.47272872924805, train_RAE:0.08202556520700455,  train_Gen:52.024845123291016, train_Disc:3.1370868125435436e-09, train_reg:3.3944153785705566, train_t_reg:3.037722110748291, train_t_mse:181.99090576171875, train_layer_one_recon:0.0\n",
      "Iteration: 38037 epochs:409, Training: RAE:0.08453283458948135, Loss: 54.82017517089844, Ranking:54.44235610961914, Reg:3.394127368927002, Gen:52.297019958496094, Disc:-0.0, Recon_One:0.0, T_Reg:2.5231544971466064,T_MSE:116.9210205078125,  CI:0.932470855843048 Validation RAE:0.06853957397648286 Loss:50.75647330990699, Ranking:47.2623494262619, Reg:3.416621898194619, Gen:48.46165470887948, Disc:0.0, Recon_One:0.0, T_Reg:2.294819138415891, T_MSE:114.00217349877786, CI:0.9257302079016342, \n",
      "it:38100, trainCI:0.9246266064605766, train_ranking:51.62237548828125, train_RAE:0.08382509648799896,  train_Gen:52.65028762817383, train_Disc:-0.0, train_reg:3.394644021987915, train_t_reg:2.2010772228240967, train_t_mse:123.49372100830078, train_layer_one_recon:0.0\n",
      "Iteration: 38130 epochs:410, Training: RAE:0.08494435995817184, Loss: 55.16170883178711, Ranking:47.03083038330078, Reg:3.394782304763794, Gen:51.93212127685547, Disc:-0.0, Recon_One:0.0, T_Reg:3.229586124420166,T_MSE:162.0811004638672,  CI:0.8773262438283327 Validation RAE:0.07007502285397707 Loss:51.89640500239317, Ranking:47.28335160769059, Reg:3.417281174609046, Gen:49.55377632399656, Disc:0.0, Recon_One:0.0, T_Reg:2.3426282349207614, T_MSE:110.01501232441535, CI:0.926287712795565, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:38200, trainCI:0.932221354457213, train_ranking:46.001461029052734, train_RAE:0.07432575523853302,  train_Gen:52.017086029052734, train_Disc:-0.0, train_reg:3.3953051567077637, train_t_reg:2.2822370529174805, train_t_mse:108.25910949707031, train_layer_one_recon:0.0\n",
      "Iteration: 38223 epochs:411, Training: RAE:0.06347177922725677, Loss: 53.53707504272461, Ranking:39.61127471923828, Reg:3.395414352416992, Gen:51.41246795654297, Disc:1.3546510579942606e-09, Recon_One:0.0, T_Reg:2.1246073246002197,T_MSE:90.35317993164062,  CI:0.917830255453317 Validation RAE:0.07013506671220224 Loss:51.44088497545863, Ranking:47.28008528806365, Reg:3.417917411148779, Gen:49.07801476540946, Disc:0.0, Recon_One:0.0, T_Reg:2.362870241353344, T_MSE:111.28073221626201, CI:0.9263512319233851, \n",
      "it:38300, trainCI:0.9461170848267623, train_ranking:42.8410758972168, train_RAE:0.06991789489984512,  train_Gen:52.274169921875, train_Disc:-0.0, train_reg:3.3957087993621826, train_t_reg:2.267603874206543, train_t_mse:150.97421264648438, train_layer_one_recon:0.0\n",
      "Iteration: 38316 epochs:412, Training: RAE:0.06513797491788864, Loss: 53.86914825439453, Ranking:45.264198303222656, Reg:3.395808219909668, Gen:51.74866485595703, Disc:5.786858769951664e-10, Recon_One:0.0, T_Reg:2.1204817295074463,T_MSE:118.84326934814453,  CI:0.9294654939106901 Validation RAE:0.06811105011142134 Loss:50.495704502049904, Ranking:47.250721301677096, Reg:3.4183138889924756, Gen:48.212292141596556, Disc:0.0, Recon_One:0.0, T_Reg:2.2834122717581766, T_MSE:113.82631915084, CI:0.9262604161769104, \n",
      "it:38400, trainCI:0.9381961717313724, train_ranking:47.372886657714844, train_RAE:0.06836215406656265,  train_Gen:51.80727005004883, train_Disc:-0.0, train_reg:3.3960518836975098, train_t_reg:2.4497406482696533, train_t_mse:138.82398986816406, train_layer_one_recon:0.0\n",
      "Iteration: 38409 epochs:413, Training: RAE:0.08173555880784988, Loss: 54.79138946533203, Ranking:48.03437423706055, Reg:3.3959522247314453, Gen:52.55604553222656, Disc:-0.0, Recon_One:0.0, T_Reg:2.235344409942627,T_MSE:104.47615814208984,  CI:0.9250906376626147 Validation RAE:0.06774521628584551 Loss:51.85979931626124, Ranking:47.272513684025554, Reg:3.4184588482040934, Gen:49.598553151775484, Disc:0.0, Recon_One:0.0, T_Reg:2.261246623613692, T_MSE:111.51024609845147, CI:0.9261829373714893, \n",
      "it:38500, trainCI:0.9395159067100403, train_ranking:46.28744125366211, train_RAE:0.06142474710941315,  train_Gen:52.20171356201172, train_Disc:-0.0, train_reg:3.396568775177002, train_t_reg:2.1796882152557373, train_t_mse:145.537353515625, train_layer_one_recon:0.0\n",
      "Iteration: 38502 epochs:414, Training: RAE:0.07813475281000137, Loss: 54.941619873046875, Ranking:47.67447280883789, Reg:3.396548271179199, Gen:52.3641242980957, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.5774941444396973,T_MSE:111.92311096191406,  CI:0.9019818465008862 Validation RAE:0.06814727882742956 Loss:50.604081568277316, Ranking:47.24674892675971, Reg:3.419058844940922, Gen:48.301206524109446, Disc:0.0, Recon_One:0.0, T_Reg:2.3028748719948924, T_MSE:115.95787653196182, CI:0.9273281498818928, \n",
      "Iteration: 38595 epochs:415, Training: RAE:0.08466192334890366, Loss: 54.632354736328125, Ranking:50.60878372192383, Reg:3.3966236114501953, Gen:52.58949279785156, Disc:-0.0, Recon_One:0.0, T_Reg:2.042863607406616,T_MSE:92.73202514648438,  CI:0.9394648489164716 Validation RAE:0.0679688091458895 Loss:50.523133973740215, Ranking:47.263847185072635, Reg:3.419134684528457, Gen:48.25403254762864, Disc:0.0, Recon_One:0.0, T_Reg:2.2691011861128794, T_MSE:113.21326014070462, CI:0.9267289216392959, \n",
      "it:38600, trainCI:0.9344103912833449, train_ranking:47.932350158691406, train_RAE:0.07338066399097443,  train_Gen:52.11714172363281, train_Disc:-0.0, train_reg:3.396728038787842, train_t_reg:2.015070915222168, train_t_mse:81.10985565185547, train_layer_one_recon:0.0\n",
      "Iteration: 38688 epochs:416, Training: RAE:0.06825312972068787, Loss: 55.08112335205078, Ranking:39.182395935058594, Reg:3.3972201347351074, Gen:52.94272994995117, Disc:-0.0, Recon_One:0.0, T_Reg:2.1383936405181885,T_MSE:121.17208099365234,  CI:0.9151016707680353 Validation RAE:0.07060098146086441 Loss:50.56756436862065, Ranking:47.28108752261285, Reg:3.4197351612626754, Gen:48.221098883265, Disc:0.0, Recon_One:0.0, T_Reg:2.3464657983974293, T_MSE:110.3470486403257, CI:0.9257475407355328, \n",
      "it:38700, trainCI:0.8851664881954006, train_ranking:50.39122009277344, train_RAE:0.09178441762924194,  train_Gen:52.696144104003906, train_Disc:3.4059796649721363e-10, train_reg:3.397357940673828, train_t_reg:2.5828988552093506, train_t_mse:84.81270599365234, train_layer_one_recon:0.0\n",
      "Iteration: 38781 epochs:417, Training: RAE:0.08843682706356049, Loss: 55.30858612060547, Ranking:52.26299285888672, Reg:3.3975632190704346, Gen:52.81725311279297, Disc:-0.0, Recon_One:0.0, T_Reg:2.4913318157196045,T_MSE:81.01715087890625,  CI:0.9016433894290086 Validation RAE:0.06944390454727724 Loss:51.515403276266746, Ranking:47.274095588465606, Reg:3.4200805193843937, Gen:49.19380566262, Disc:0.0, Recon_One:0.0, T_Reg:2.321597707559276, T_MSE:111.72485618691482, CI:0.9267813871934022, \n",
      "it:38800, trainCI:0.9108842188739096, train_ranking:51.96681213378906, train_RAE:0.08501941710710526,  train_Gen:52.696022033691406, train_Disc:1.7029898324860682e-10, train_reg:3.397594451904297, train_t_reg:2.882028818130493, train_t_mse:146.9245147705078, train_layer_one_recon:0.0\n",
      "Iteration: 38874 epochs:418, Training: RAE:0.07612261176109314, Loss: 55.15435791015625, Ranking:48.11041259765625, Reg:3.3980712890625, Gen:52.52899932861328, Disc:-0.0, Recon_One:0.0, T_Reg:2.6253573894500732,T_MSE:111.97621154785156,  CI:0.9068296571884135 Validation RAE:0.07381509533912461 Loss:51.19196550837454, Ranking:47.31426126914903, Reg:3.4205919566028666, Gen:48.770767685113974, Disc:0.0, Recon_One:0.0, T_Reg:2.421197682391767, T_MSE:104.47019434160063, CI:0.9252399066600947, \n",
      "it:38900, trainCI:0.9039321511179645, train_ranking:50.05866241455078, train_RAE:0.0814240351319313,  train_Gen:51.70751190185547, train_Disc:-0.0, train_reg:3.3983516693115234, train_t_reg:2.626570463180542, train_t_mse:130.17947387695312, train_layer_one_recon:0.0\n",
      "Iteration: 38967 epochs:419, Training: RAE:0.0833904892206192, Loss: 54.8975715637207, Ranking:43.900211334228516, Reg:3.3989980220794678, Gen:52.333377838134766, Disc:-0.0, Recon_One:0.0, T_Reg:2.564192295074463,T_MSE:110.72062683105469,  CI:0.9143903289550157 Validation RAE:0.0679890045795319 Loss:50.93661023629253, Ranking:47.27470147038782, Reg:3.421524831529288, Gen:48.68330531557366, Disc:0.0, Recon_One:0.0, T_Reg:2.2533047433285263, T_MSE:114.16788796447166, CI:0.925485939490973, \n",
      "it:39000, trainCI:0.9026517794836009, train_ranking:51.51592254638672, train_RAE:0.08606407791376114,  train_Gen:52.13505554199219, train_Disc:-0.0, train_reg:3.3990366458892822, train_t_reg:2.7588627338409424, train_t_mse:96.32331848144531, train_layer_one_recon:0.0\n",
      "Iteration: 39060 epochs:420, Training: RAE:0.07013113796710968, Loss: 54.559940338134766, Ranking:47.107452392578125, Reg:3.3989884853363037, Gen:52.15800476074219, Disc:3.4059796649721363e-10, Recon_One:0.0, T_Reg:2.4019360542297363,T_MSE:82.82730102539062,  CI:0.9353179380540659 Validation RAE:0.0712574488144823 Loss:50.706119997673994, Ranking:47.2999144393503, Reg:3.4215152315814987, Gen:48.35889352863097, Disc:0.0, Recon_One:0.0, T_Reg:2.3472263125221295, T_MSE:107.25149856115172, CI:0.9262819524825029, \n",
      "it:39100, trainCI:0.9333512641204949, train_ranking:47.71208190917969, train_RAE:0.06793343275785446,  train_Gen:52.339263916015625, train_Disc:-0.0, train_reg:3.399240016937256, train_t_reg:2.0273382663726807, train_t_mse:131.7399139404297, train_layer_one_recon:0.0\n",
      "Iteration: 39153 epochs:421, Training: RAE:0.0770508199930191, Loss: 54.496280670166016, Ranking:49.980953216552734, Reg:3.3996825218200684, Gen:52.27660369873047, Disc:-0.0, Recon_One:0.0, T_Reg:2.219675302505493,T_MSE:110.82042694091797,  CI:0.9328627370156637 Validation RAE:0.06805092766666704 Loss:51.50926815832915, Ranking:47.2727733000049, Reg:3.422213867781862, Gen:49.27233039729071, Disc:0.0, Recon_One:0.0, T_Reg:2.236937781907893, T_MSE:111.26809701541521, CI:0.9261006323578269, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it:39200, trainCI:0.9152797974901707, train_ranking:47.667877197265625, train_RAE:0.07529573887586594,  train_Gen:53.07205581665039, train_Disc:-0.0, train_reg:3.3996028900146484, train_t_reg:2.4665212631225586, train_t_mse:98.89799499511719, train_layer_one_recon:0.0\n",
      "Iteration: 39246 epochs:422, Training: RAE:0.06906548887491226, Loss: 54.601924896240234, Ranking:34.102264404296875, Reg:3.3997695446014404, Gen:52.28199768066406, Disc:-0.0, Recon_One:0.0, T_Reg:2.319925546646118,T_MSE:126.28117370605469,  CI:0.9163538068779096 Validation RAE:0.0685337292256617 Loss:50.79091074348346, Ranking:47.28978924920026, Reg:3.422301467305439, Gen:48.53885047686492, Disc:0.0, Recon_One:0.0, T_Reg:2.2520601987928184, T_MSE:107.2046431359819, CI:0.9267430888957459, \n",
      "it:39300, trainCI:0.9250670021331291, train_ranking:47.11091995239258, train_RAE:0.0774175301194191,  train_Gen:52.18832015991211, train_Disc:1.7029898324860682e-10, train_reg:3.4002482891082764, train_t_reg:2.7195777893066406, train_t_mse:115.6197509765625, train_layer_one_recon:0.0\n",
      "Iteration: 39339 epochs:423, Training: RAE:0.06553525477647781, Loss: 55.1011848449707, Ranking:42.139034271240234, Reg:3.400522232055664, Gen:52.792762756347656, Disc:-0.0, Recon_One:0.0, T_Reg:2.3084237575531006,T_MSE:143.8798370361328,  CI:0.9288776187888668 Validation RAE:0.06811711268714477 Loss:50.12681540569932, Ranking:47.27950294688297, Reg:3.423059143184706, Gen:47.8473503768213, Disc:0.0, Recon_One:0.0, T_Reg:2.2794653262677036, T_MSE:112.60799895946393, CI:0.9265101335323599, \n",
      "it:39400, trainCI:0.9346214028165182, train_ranking:37.829105377197266, train_RAE:0.07303673028945923,  train_Gen:52.698272705078125, train_Disc:-0.0, train_reg:3.4007067680358887, train_t_reg:2.5871100425720215, train_t_mse:110.07877349853516, train_layer_one_recon:0.0\n",
      "Iteration: 39432 epochs:424, Training: RAE:0.0961560308933258, Loss: 55.61619186401367, Ranking:51.81155014038086, Reg:3.400852918624878, Gen:52.59259033203125, Disc:-0.0, Recon_One:0.0, T_Reg:3.023601531982422,T_MSE:138.53907775878906,  CI:0.9003317324355102 Validation RAE:0.06556492548063723 Loss:51.425942448030135, Ranking:47.23953694511357, Reg:3.4233920213742985, Gen:49.2186381397388, Disc:0.0, Recon_One:0.0, T_Reg:2.2073041100315383, T_MSE:117.36689375924725, CI:0.9275241562101416, *\n",
      "it:39500, trainCI:0.9147370035270664, train_ranking:50.48849868774414, train_RAE:0.08887388557195663,  train_Gen:52.75556945800781, train_Disc:-0.0, train_reg:3.4007275104522705, train_t_reg:2.7260308265686035, train_t_mse:96.05203247070312, train_layer_one_recon:0.0\n",
      "Iteration: 39525 epochs:425, Training: RAE:0.07640337944030762, Loss: 55.133670806884766, Ranking:43.3205680847168, Reg:3.4009547233581543, Gen:52.66923522949219, Disc:-0.0, Recon_One:0.0, T_Reg:2.4644360542297363,T_MSE:156.07997131347656,  CI:0.9152871870397643 Validation RAE:0.06948779789551326 Loss:50.645676055103, Ranking:47.258155334289484, Reg:3.423494500816949, Gen:48.334001281402465, Disc:0.0, Recon_One:0.0, T_Reg:2.311674789352627, T_MSE:120.87161965827518, CI:0.9273417981912202, \n",
      "it:39600, trainCI:0.9194792671166827, train_ranking:42.41705322265625, train_RAE:0.05881494656205177,  train_Gen:52.10588073730469, train_Disc:-0.0, train_reg:3.401543140411377, train_t_reg:2.4913125038146973, train_t_mse:139.0186004638672, train_layer_one_recon:0.0\n",
      "Iteration: 39618 epochs:426, Training: RAE:0.0988357663154602, Loss: 55.36155319213867, Ranking:51.76996994018555, Reg:3.4017863273620605, Gen:52.794437408447266, Disc:-0.0, Recon_One:0.0, T_Reg:2.5671141147613525,T_MSE:110.19518280029297,  CI:0.9142672756155679 Validation RAE:0.0667448831393493 Loss:51.20390750951315, Ranking:47.25839107561606, Reg:3.4243316162641726, Gen:48.99422124548079, Disc:0.0, Recon_One:0.0, T_Reg:2.209686008381578, T_MSE:114.99916163477076, CI:0.9274626609761001, \n",
      "it:39700, trainCI:0.9227076104007226, train_ranking:54.32416915893555, train_RAE:0.0871613398194313,  train_Gen:52.65883255004883, train_Disc:3.4059796649721363e-10, train_reg:3.4020915031433105, train_t_reg:2.4553914070129395, train_t_mse:116.35311126708984, train_layer_one_recon:0.0\n",
      "Iteration: 39711 epochs:427, Training: RAE:0.10544981807470322, Loss: 55.143035888671875, Ranking:56.88974380493164, Reg:3.402226448059082, Gen:52.178382873535156, Disc:-0.0, Recon_One:0.0, T_Reg:2.964651346206665,T_MSE:148.62789916992188,  CI:0.8936457863902659 Validation RAE:0.0696289262584005 Loss:51.010543858541375, Ranking:47.24352968861584, Reg:3.4247746538546466, Gen:48.66123161301608, Disc:0.0, Recon_One:0.0, T_Reg:2.3493120263960563, T_MSE:117.34517717474742, CI:0.9281238515051491, \n",
      "it:39800, trainCI:0.9168963016678753, train_ranking:53.501441955566406, train_RAE:0.10806723684072495,  train_Gen:53.0873908996582, train_Disc:-0.0, train_reg:3.4029181003570557, train_t_reg:2.8104076385498047, train_t_mse:117.49396514892578, train_layer_one_recon:0.0\n",
      "Iteration: 39804 epochs:428, Training: RAE:0.08038356900215149, Loss: 55.176910400390625, Ranking:48.66958999633789, Reg:3.4029760360717773, Gen:52.88216781616211, Disc:-0.0, Recon_One:0.0, T_Reg:2.2947440147399902,T_MSE:113.2421646118164,  CI:0.9186729456585004 Validation RAE:0.06973937669030812 Loss:50.98565111044602, Ranking:47.26520586985714, Reg:3.4255292097508825, Gen:48.65512587926649, Disc:0.0, Recon_One:0.0, T_Reg:2.3305250172676466, T_MSE:113.30800478020444, CI:0.9267389373187642, \n",
      "Iteration: 39897 epochs:429, Training: RAE:0.07658638805150986, Loss: 54.747596740722656, Ranking:48.08734130859375, Reg:3.403036117553711, Gen:52.48369216918945, Disc:-0.0, Recon_One:0.0, T_Reg:2.2639060020446777,T_MSE:112.41071319580078,  CI:0.9324757126080923 Validation RAE:0.0692998159830982 Loss:51.05831369960757, Ranking:47.29182243466422, Reg:3.4255896894219546, Gen:48.780704382376115, Disc:0.0, Recon_One:0.0, T_Reg:2.2776092337536427, T_MSE:106.61528948561704, CI:0.9268273140137623, \n",
      "it:39900, trainCI:0.9079493957703928, train_ranking:54.687042236328125, train_RAE:0.07753083854913712,  train_Gen:52.43963623046875, train_Disc:4.926003493999076e-10, train_reg:3.4030263423919678, train_t_reg:2.397021532058716, train_t_mse:104.14104461669922, train_layer_one_recon:0.0\n",
      "Iteration: 39990 epochs:430, Training: RAE:0.07527707517147064, Loss: 54.76396560668945, Ranking:50.57099151611328, Reg:3.4033687114715576, Gen:52.761138916015625, Disc:-0.0, Recon_One:0.0, T_Reg:2.002828359603882,T_MSE:99.17452239990234,  CI:0.9299994886741321 Validation RAE:0.06721382395851026 Loss:50.853932647685994, Ranking:47.275350426858374, Reg:3.425924487601105, Gen:48.63190335513085, Disc:0.0, Recon_One:0.0, T_Reg:2.222029553423289, T_MSE:112.09674781302266, CI:0.9271756313225274, \n",
      "Iteration: 40000 epochs:430, Training: RAE:0.06716252118349075, Loss: 55.50019073486328, Ranking:40.526084899902344, Reg:3.4034245014190674, Gen:53.0611686706543, Disc:-0.0, Recon_One:0.0, T_Reg:2.4390227794647217,T_MSE:108.24917602539062,  CI:0.9027708747514911 Validation RAE:0.07112037091869644 Loss:50.780899250106366, Ranking:47.289531469732665, Reg:3.425980647295672, Gen:48.40354213449856, Disc:0.0, Recon_One:0.0, T_Reg:2.3773572303897903, T_MSE:107.85210201468068, CI:0.9275903219682875, \n",
      "Time usage: 16:33:41\n",
      "finished enqueueing\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\raibe\\Desktop\\Thesis Code\\DATE\\summaries\\mort_d\\DATE_AE_model\n",
      "Test observed_death:(3061,), percentage:0.3061918575572672\n",
      "observed_samples:(3061, 200), empirical_observed:(3061,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\ipykernel_launcher.py:83: MatplotlibDeprecationWarning: Setting whis to 'range' is deprecated since 3.2 and support for it will be removed two minor releases later; set it to [0, 100] to achieve the same effect.\n",
      "C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\ipykernel_launcher.py:64: MatplotlibDeprecationWarning: Setting whis to 'range' is deprecated since 3.2 and support for it will be removed two minor releases later; set it to [0, 100] to achieve the same effect.\n",
      "C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\ipykernel_launcher.py:64: MatplotlibDeprecationWarning: Setting whis to 'range' is deprecated since 3.2 and support for it will be removed two minor releases later; set it to [0, 100] to achieve the same effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed_samples:(6936, 200), empirical_observed:(6936,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\ipykernel_launcher.py:83: MatplotlibDeprecationWarning: Setting whis to 'range' is deprecated since 3.2 and support for it will be removed two minor releases later; set it to [0, 100] to achieve the same effect.\n",
      "C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\ipykernel_launcher.py:64: MatplotlibDeprecationWarning: Setting whis to 'range' is deprecated since 3.2 and support for it will be removed two minor releases later; set it to [0, 100] to achieve the same effect.\n",
      "C:\\Users\\raibe\\Anaconda3\\envs\\NewDate\\lib\\site-packages\\ipykernel_launcher.py:64: MatplotlibDeprecationWarning: Setting whis to 'range' is deprecated since 3.2 and support for it will be removed two minor releases later; set it to [0, 100] to achieve the same effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":Test RAE:0.06566639405313678, Loss:51.82656344144454, Gen:49.6198159450887, Disc:0.0, Reg:3.4529015828791145, Ranking48.34178159675014, Recon:0.0, T_Reg:2.206747462967223,T_MSE:118.77730337991778, CI:0.9269061937671988, Observed: CI:0, Correlation:SpearmanrResult(correlation=0.898323425519687, pvalue=0.0)\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\raibe\\Desktop\\Thesis Code\\DATE\\summaries\\mort_d\\DATE_AE_model\n",
      "Valid observed_death:(2394,), percentage:0.2993622608478179\n",
      ":Valid RAE:0.06593590770212579, Loss:51.44379050400431, Gen:49.21875450780157, Disc:0.0, Reg:3.4233920213742985, Ranking47.23902405746821, Recon:0.0, T_Reg:2.225036126636812,T_MSE:118.53132535326968, CI:0.9274160595244805, Observed: CI:0, Correlation:SpearmanrResult(correlation=0.9053197082777253, pvalue=0.0)\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\raibe\\Desktop\\Thesis Code\\DATE\\summaries\\mort_d\\DATE_AE_model\n",
      "Train observed_death:(9694,), percentage:0.30305114417906714\n",
      ":Train RAE:0.06275828683191469, Loss:51.302786387397866, Gen:49.20382274901016, Disc:0.0, Reg:3.4233920213742985, Ranking47.41923758517627, Recon:0.0, T_Reg:2.0989635066492967,T_MSE:115.96459983452657, CI:0.9285132151819725, Observed: CI:0, Correlation:SpearmanrResult(correlation=0.900493276485727, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    r_epochs = 600\n",
    "    \n",
    "    # Two date models to choose\n",
    "    simple = True\n",
    "    if simple:\n",
    "        model = DATE\n",
    "    else:\n",
    "        model = DATE_AE\n",
    "\n",
    "    \n",
    "    data_set = generate_data()\n",
    "    train_data, valid_data, test_data, end_t, covariates, one_hot_indices, imputation_values \\\n",
    "        = data_set['train'], \\\n",
    "          data_set['valid'], \\\n",
    "          data_set['test'], \\\n",
    "          data_set['end_t'], \\\n",
    "          data_set['covariates'], \\\n",
    "          data_set[\n",
    "              'one_hot_indices'], \\\n",
    "          data_set[\n",
    "              'imputation_values']\n",
    "\n",
    "    print(\"imputation_values:{}, one_hot_indices:{}\".format(imputation_values, one_hot_indices))\n",
    "    print(\"end_t:{}\".format(end_t))\n",
    "    train = {'x': train_data['x'], 'e': train_data['e'], 't': train_data['t']}\n",
    "    valid = {'x': valid_data['x'], 'e': valid_data['e'], 't': valid_data['t']}\n",
    "    test = {'x': test_data['x'], 'e': test_data['e'], 't': test_data['t']}\n",
    "\n",
    "    perfomance_record = []\n",
    "\n",
    "    date = model(batch_size=350,\n",
    "                 learning_rate=3e-4,\n",
    "                 beta1=0.9,\n",
    "                 beta2=0.999,\n",
    "                 require_improvement=10000,\n",
    "                 num_iterations=40000, seed=31415,\n",
    "                 l2_reg=0.001,\n",
    "                 hidden_dim=[50, 50],\n",
    "                 train_data=train, test_data=test, valid_data=valid,\n",
    "                 input_dim=train['x'].shape[1],\n",
    "                 num_examples=train['x'].shape[0], keep_prob=0.8,\n",
    "                 latent_dim=50, end_t=end_t,\n",
    "                 path_large_data='C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE',\n",
    "                 covariates=covariates,\n",
    "                 categorical_indices=one_hot_indices,\n",
    "                 disc_updates=1,\n",
    "                 sample_size=200, imputation_values=imputation_values,\n",
    "                 max_epochs=r_epochs,  gen_updates=2)\n",
    "\n",
    "    with date.session:\n",
    "        date.train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.load('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\Test_empirical_time.npy')\n",
    "ee = np.load('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\Test_data_e.npy')\n",
    "pp1 = np.load('C:\\\\Users\\\\raibe\\\\Desktop\\\\Thesis Code\\\\DATE\\\\matrix\\\\mort_d\\\\Test_predicted_time.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9294537998189213\n"
     ]
    }
   ],
   "source": [
    "print(concordance_index(tt, pp1, ee))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NewDate)",
   "language": "python",
   "name": "newdate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
