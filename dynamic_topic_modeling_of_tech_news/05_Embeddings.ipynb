{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqwzLFX_1YTf"
   },
   "source": [
    "# Create Embeddings\n",
    "To speed up the D-ETM training process, the construction of the word embedding matrices is placed in this separate notebook. It includes the creation of (smaller) embedding matrices for Word2Vec, GloVe and fastText. They include embeddings for bigrams and trigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI1TV-V11epO"
   },
   "source": [
    "## Directories & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28986,
     "status": "ok",
     "timestamp": 1609144970412,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "bwhzzlLqDJvw",
    "outputId": "45705a24-42dd-4f20-d2d7-5f1643544a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28978,
     "status": "ok",
     "timestamp": 1609144970416,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "r1uStYoQQXQG",
    "outputId": "3f05ea31-a9ed-49de-887c-59cb9ea9faf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Masterarbeit/Topic-Modeling\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/Thesis/Topic-Modeling/'\n",
    "data_path = 'Data/Technology-Data/processed/preprocessed/texts.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49577,
     "status": "ok",
     "timestamp": 1609145557504,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "PgSAtiswDJv-",
    "outputId": "ba97104b-ce2c-4536-ef4e-e8f5ea1b899d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (51.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.19.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3040949 sha256=8fbf608c8da48d313a299fcf09b9d8bdc9b65d1db8794dba5ddca36bff67eb7a\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
      "Successfully built fasttext\n",
      "Installing collected packages: fasttext\n",
      "Successfully installed fasttext-0.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jh7e-7glQVLf"
   },
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import gensim\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwvEDisjmaHt"
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mI-E1mMNmaHt"
   },
   "outputs": [],
   "source": [
    "emb_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL4X-ngkDJwT"
   },
   "source": [
    "## Get Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZRuEfW-gYnS"
   },
   "outputs": [],
   "source": [
    "vocab, full, train, valid, test = utils.get_data('Data/Technology-Data/processed/final/grouped_years/min_df_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8011,
     "status": "ok",
     "timestamp": 1609144983704,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "2NyK158UhmcN",
    "outputId": "beffff46-3c5b-4bfa-a1c7-86c9b0d542e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18863"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqF8iAQ5maHu"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnBmky2-maHu"
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "with open(data_path) as articles:\n",
    "    a = articles.readlines()\n",
    "    for line in a:\n",
    "        tokens = line.split()\n",
    "        docs.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11838212,
     "status": "ok",
     "timestamp": 1609157741950,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "MCs3mlxnFhIV",
    "outputId": "46eb37b0-9038-4fad-81f0-76b574709bff",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11837.076303720474 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_word2vec = gensim.models.Word2Vec(docs,\n",
    "                                        min_count=50,\n",
    "                                        sg=1,\n",
    "                                        size=emb_size,\n",
    "                                        iter=100,\n",
    "                                        workers=6,\n",
    "                                        negative=10,\n",
    "                                        window=5)\n",
    "\n",
    "calc_time = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % calc_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxOM49UFmaHu"
   },
   "outputs": [],
   "source": [
    "word2vec_file = 'Data/Embeddings/Word2Vec/Word2Vec_{}'.format(emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fV1Z6CmWmaHu"
   },
   "outputs": [],
   "source": [
    "model_word2vec.save(word2vec_file + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8HZkq3nFhId",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(word2vec_file + '.txt','w') as f:\n",
    "    for word in list(model_word2vec.wv.vocab):\n",
    "        vector = list(model_word2vec.wv.__getitem__(word))\n",
    "        vector_str = \" \".join(['%.9f' % val for val in vector])\n",
    "        f.write(word + ' ' + vector_str + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXxCiBATwLmH"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rEOBXI3maHu"
   },
   "source": [
    "Load original cased (!) GloVe vectors (https://nlp.stanford.edu/projects/glove/, 11/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2Z1xQeRxq9g"
   },
   "outputs": [],
   "source": [
    "glove_orig = {}\n",
    "with open('Data/Embeddings/GloVe/glove.840B.300d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        try:\n",
    "            vect = np.array(line[1:]).astype(np.float)\n",
    "        except ValueError:\n",
    "            if len(line[1:])==301: # a few GloVe lines contain more than 1 string token\n",
    "                vect = np.array(line[2:]).astype(np.float)\n",
    "        glove_orig[word] = vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1609145468161,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "FdGf3c1M1jnO",
    "outputId": "6c8af970-0c83-4fc0-e91c-efca33933cfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2195884"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZMps1EHmaHv"
   },
   "source": [
    "Create data-/task-specific GloVe embeddings by iterating through the vocabulary. Account for bigrams and trigrams by averaging word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1609145476347,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "rtJIhCGwzepv",
    "outputId": "697d07cf-61b6-4855-fef5-4fe308696013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embedding available for: ride-hailing, Onlineblog, book-apps, DeepMind, wouldo, GDPR, H.264, Netbytes, USB-C, 000-strong, Margrethe_Vestager, wouldigital, Chromecast, Technobile, OneDrive, 802.11b, cryptocurrencies, Gamesblog, e-envoy, WannaCry, alt-right, book-app, Google+, areilly, Brexit, Waymo, gamesblog, OnePlus, Sky+, Facebook-owned\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = {}\n",
    "words_no_glove_emb = []\n",
    "for v in vocab:\n",
    "    try:\n",
    "        tokens = v.split('_')\n",
    "        if len(tokens) == 3:\n",
    "            glove_embeddings[v] = np.mean(np.array([glove_orig[tokens[0]],glove_orig[tokens[1]],glove_orig[tokens[2]]]), axis=0)\n",
    "        elif len(tokens) == 2:\n",
    "            glove_embeddings[v] = np.mean(np.array([glove_orig[tokens[0]],glove_orig[tokens[1]]]), axis=0)\n",
    "        else:\n",
    "            glove_embeddings[v] = glove_orig[v]\n",
    "    except KeyError:\n",
    "        words_no_glove_emb.append(v)\n",
    "        \n",
    "print('No embedding available for:', ', '.join(words_no_glove_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tcLNQuomaHv"
   },
   "source": [
    "Save data/task-specific GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rzdr0aTU2GIw"
   },
   "outputs": [],
   "source": [
    "with open('Data/Embeddings/GloVe/GloVe_300.txt', 'w') as f:\n",
    "  for word in glove_embeddings.keys():\n",
    "      vec = ['%.9f' % val for val in glove_embeddings[word]]\n",
    "      vec_str = \" \".join(vec)\n",
    "      emb_line = word + \" \" + vec_str + '\\n'\n",
    "      f.write(emb_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-qJKsGtDJwm"
   },
   "source": [
    "## fastText\n",
    "https://fasttext.cc/, https://fasttext.cc/docs/en/crawl-vectors.html (11/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXOrWBmfDJwn"
   },
   "outputs": [],
   "source": [
    "#fasttext.util.download_model('en', if_exists='ignore') # download the model if it has not been done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78023,
     "status": "ok",
     "timestamp": 1609145769219,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "neTjCOl68TgG",
    "outputId": "d1b9e791-15df-43b5-d1d4-79f0b57169ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastText_model = fasttext.load_model('Data/Embeddings/fastText/cc.en.300.bin')\n",
    "fastText_model.get_dimension()\n",
    "if emb_size < 300:\n",
    "    fasttext.util.reduce_model(fastText_model, emb_size)\n",
    "fastText_model.get_dimension()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2513,
     "status": "ok",
     "timestamp": 1609145857977,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "d6WVz3fCuup7",
    "outputId": "6ce06ad5-2e48-4561-d323-27cd2ef0bf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbouring Example for ai:  [(0.6824304461479187, 'ai.'), (0.658112645149231, 'lu'), (0.6302372813224792, \"'hl\"), (0.6282903552055359, 'Ai'), (0.6257882118225098, ',o'), (0.6223296523094177, 'il'), (0.6184976696968079, 'iav'), (0.6163771748542786, 't-i'), (0.6162423491477966, ',y'), (0.615196704864502, 'uai')]\n",
      "Neighbouring Example for AI:  [(0.7377923130989075, 'A.I.'), (0.6971256732940674, 'AIs'), (0.6795729994773865, 'AI.'), (0.6684409976005554, 'A.I'), (0.6131572723388672, 'non-AI'), (0.6108188629150391, 'AI-driven'), (0.5958052277565002, 'AI-'), (0.5889711976051331, '-AI'), (0.5875733494758606, 'ANs'), (0.5865451693534851, 'AI-based')]\n"
     ]
    }
   ],
   "source": [
    "print('Neighbouring Example for ai: ', fastText_model.get_nearest_neighbors(\"ai\"))\n",
    "print('Neighbouring Example for AI: ', fastText_model.get_nearest_neighbors(\"AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2673,
     "status": "ok",
     "timestamp": 1609145860655,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "UpC5gsmhkQ3M",
    "outputId": "28146524-0987-4410-e88d-b684c3b8360f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbouring Example for Apple:  [(0.7653286457061768, 'it.Apple'), (0.7601998448371887, 'Appple'), (0.7555220127105713, '.Apple'), (0.7497225999832153, 'Apple.The'), (0.7486265897750854, 'Apple.Apple'), (0.7334216237068176, 'Apple.I'), (0.7238132357597351, 'Apple.'), (0.7206739187240601, 'APple'), (0.709655225276947, 'Apple-'), (0.7031973600387573, '-Apple')]\n",
      "Neighbouring Example for apple:  [(0.7626952528953552, 'apples'), (0.7096020579338074, 'apple-'), (0.6859333515167236, 'apple.I'), (0.6751999855041504, 'apple.'), (0.6751177906990051, 'non-apple'), (0.6668474674224854, 'pear'), (0.6600887179374695, 'apple.The'), (0.642498791217804, 'apples.'), (0.6265839338302612, 'honeycrisp'), (0.610177755355835, 'apple-pear')]\n"
     ]
    }
   ],
   "source": [
    "print('Neighbouring Example for Apple: ', fastText_model.get_nearest_neighbors(\"Apple\"))\n",
    "print('Neighbouring Example for apple: ', fastText_model.get_nearest_neighbors(\"apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1775,
     "status": "ok",
     "timestamp": 1609145874071,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "S7nZcGiKkRPX",
    "outputId": "ad5e9829-c353-4331-de5b-1989e31632fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy Example for PS1, PS2, 4G:  [(0.664808988571167, '3G'), (0.5942748785018921, '4g'), (0.5793185234069824, '5G'), (0.5652352571487427, 'LTE'), (0.5615310072898865, '2G'), (0.5493701696395874, '3G-'), (0.5400305390357971, '4GLTE'), (0.5382450222969055, 'hspa'), (0.5359112024307251, 'lte'), (0.5342647433280945, '3g')]\n"
     ]
    }
   ],
   "source": [
    "print('Analogy Example for PS1, PS2, 4G: ', fastText_model.get_analogies(\"PS1\", \"PS2\", \"4G\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk_-IVUVMxV3"
   },
   "source": [
    "Create a subset of data-/task-specific fastText embeddings by iterating through the vocabulary. Account for bigrams and trigrams by applying fastText's get_sentence_vector():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1609145883900,
     "user": {
      "displayName": "M. T.",
      "photoUrl": "",
      "userId": "17315554739213314162"
     },
     "user_tz": -60
    },
    "id": "LdQLY9aZDJwy",
    "outputId": "60b6fa66-42d4-41a1-c388-51c799f493df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words for which no fastText embedding could not be received: 0\n"
     ]
    }
   ],
   "source": [
    "words_no_ft_emb = []\n",
    "fasttext_embeddings = {}\n",
    "\n",
    "for word in vocab:\n",
    "    try:  \n",
    "      # Bigrams, Trigrams:\n",
    "        if '_' in word:\n",
    "            fasttext_embeddings[word] = fastText_model.get_sentence_vector(word.replace('_',' '))\n",
    "        else:\n",
    "            fasttext_embeddings[word] = fastText_model.get_word_vector(word)\n",
    "\n",
    "    except Exception as e:\n",
    "        words_no_ft_emb.append(word)\n",
    "\n",
    "print('Number of words for which no fastText embedding could not be received:', len(words_no_ft_emb))\n",
    "if len(words_no_ft_emb)<15:\n",
    "    print('Corresponding words:', words_no_ft_emb)\n",
    "del fastText_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dLlppKyMl5-"
   },
   "outputs": [],
   "source": [
    "fasttext_filename = 'Data/Embeddings/fastText/fastText_{}.txt'.format(emb_size)\n",
    "with open(fasttext_filename, 'w') as f:\n",
    "    for word in fasttext_embeddings.keys():\n",
    "        vec = ['%.9f' % val for val in fasttext_embeddings[word]]\n",
    "        vec_str = \" \".join(vec)\n",
    "        emb_line = word + \" \" + vec_str + '\\n'\n",
    "        f.write(emb_line)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cI1TV-V11epO",
    "PwvEDisjmaHt",
    "RL4X-ngkDJwT",
    "uqF8iAQ5maHu",
    "BXxCiBATwLmH",
    "_-qJKsGtDJwm"
   ],
   "machine_shape": "hm",
   "name": "05_Embeddings.ipynb",
   "provenance": [
    {
     "file_id": "1bma2onLFmQj0Bd1FKfsvF5OlRnpGBmhe",
     "timestamp": 1600866105301
    },
    {
     "file_id": "155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9",
     "timestamp": 1600866030281
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
